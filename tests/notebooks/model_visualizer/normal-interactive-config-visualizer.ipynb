{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:00:49.882786Z",
     "iopub.status.busy": "2025-05-26T20:00:49.882336Z",
     "iopub.status.idle": "2025-05-26T20:00:50.046192Z",
     "shell.execute_reply": "2025-05-26T20:00:50.045200Z",
     "shell.execute_reply.started": "2025-05-26T20:00:49.882738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "token = user_secrets.get_secret(\"github_repos_wildcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:00:50.047887Z",
     "iopub.status.busy": "2025-05-26T20:00:50.047573Z",
     "iopub.status.idle": "2025-05-26T20:00:50.053685Z",
     "shell.execute_reply": "2025-05-26T20:00:50.051874Z",
     "shell.execute_reply.started": "2025-05-26T20:00:50.047861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "repo_url = f\"https://{token}@github.com/gaserSami/panther.git\"\n",
    "branch = \"autotuner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:00:50.055985Z",
     "iopub.status.busy": "2025-05-26T20:00:50.055298Z",
     "iopub.status.idle": "2025-05-26T20:00:54.294111Z",
     "shell.execute_reply": "2025-05-26T20:00:54.292915Z",
     "shell.execute_reply.started": "2025-05-26T20:00:50.055944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Cloning into 'panther'...\nremote: Enumerating objects: 1657, done.\u001b[K\nremote: Counting objects: 100% (329/329), done.\u001b[K\nremote: Compressing objects: 100% (87/87), done.\u001b[K\nremote: Total 1657 (delta 264), reused 277 (delta 241), pack-reused 1328 (from 1)\u001b[K\nReceiving objects: 100% (1657/1657), 31.58 MiB | 18.14 MiB/s, done.\nResolving deltas: 100% (1099/1099), done.\nUpdating files: 100% (133/133), done.\n"
    }
   ],
   "source": [
    "!git clone -b {branch} {repo_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:00:54.297382Z",
     "iopub.status.busy": "2025-05-26T20:00:54.296482Z",
     "iopub.status.idle": "2025-05-26T20:03:56.445704Z",
     "shell.execute_reply": "2025-05-26T20:03:56.444005Z",
     "shell.execute_reply.started": "2025-05-26T20:00:54.297343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found existing installation: torch 2.6.0+cu124\nUninstalling torch-2.6.0+cu124:\n  Successfully uninstalled torch-2.6.0+cu124\nFound existing installation: torchvision 0.21.0+cu124\nUninstalling torchvision-0.21.0+cu124:\n  Successfully uninstalled torchvision-0.21.0+cu124\nFound existing installation: torchaudio 2.6.0+cu124\nUninstalling torchaudio-2.6.0+cu124:\n  Successfully uninstalled torchaudio-2.6.0+cu124\nLooking in indexes: https://download.pytorch.org/whl/cu124\nCollecting torch==2.6.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\nCollecting torchvision==0.21.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\nCollecting torchaudio==2.6.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (11.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cu124) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cu124) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.21.0+cu124) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nDownloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, torchvision\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n"
    }
   ],
   "source": [
    "# First uninstall existing torch, torchvision, torchaudio\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# Install the specified versions from PyTorch's official CUDA 12.4 wheels\n",
    "!pip install torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:03:56.447964Z",
     "iopub.status.busy": "2025-05-26T20:03:56.447511Z",
     "iopub.status.idle": "2025-05-26T20:03:56.582026Z",
     "shell.execute_reply": "2025-05-26T20:03:56.580820Z",
     "shell.execute_reply.started": "2025-05-26T20:03:56.447916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mv panther Panther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:03:56.583780Z",
     "iopub.status.busy": "2025-05-26T20:03:56.583437Z",
     "iopub.status.idle": "2025-05-26T20:03:56.592599Z",
     "shell.execute_reply": "2025-05-26T20:03:56.591423Z",
     "shell.execute_reply.started": "2025-05-26T20:03:56.583748Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Overwriting /kaggle/working/Panther/pawX/setup.py\n"
    }
   ],
   "source": "%%writefile /kaggle/working/Panther/pawX/setup.py\nfrom setuptools import setup\nfrom torch.utils.cpp_extension import BuildExtension, CUDAExtension\n\nsetup(\n    name=\"pawX\",\n    ext_modules=[\n        CUDAExtension(\n            name=\"pawX\",\n            sources=[\n                \"skops.cpp\",\n                \"bindings.cpp\",\n                \"linear.cpp\",\n                \"linear_cuda.cu\",\n                \"cqrrpt.cpp\",\n                \"rsvd.cpp\",\n                \"attention.cpp\",\n                \"conv2d.cpp\"\n            ],\n            # Use system includes and libraries\n            include_dirs=[\"/usr/include/x86_64-linux-gnu\"],\n            library_dirs=[],\n            libraries=[\"openblas\"],\n            extra_compile_args={\"cxx\": [\"-O2\", \"-fopenmp\"], \"nvcc\": [\"-O2\"]},\n            extra_link_args=[\"-llapacke\", \"-lopenblas\"]\n        )\n    ],\n    cmdclass={\"build_ext\": BuildExtension},\n)"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:03:56.595055Z",
     "iopub.status.busy": "2025-05-26T20:03:56.593890Z",
     "iopub.status.idle": "2025-05-26T20:04:07.887669Z",
     "shell.execute_reply": "2025-05-26T20:04:07.886424Z",
     "shell.execute_reply.started": "2025-05-26T20:03:56.595014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  liblapacke libtmglib-dev libtmglib3\nSuggested packages:\n  liblapack-doc\nThe following NEW packages will be installed:\n  liblapacke liblapacke-dev libtmglib-dev libtmglib3\n0 upgraded, 4 newly installed, 0 to remove and 87 not upgraded.\nNeed to get 1,071 kB of archives.\nAfter this operation, 12.3 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtmglib3 amd64 3.10.0-2ubuntu1 [144 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblapacke amd64 3.10.0-2ubuntu1 [435 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtmglib-dev amd64 3.10.0-2ubuntu1 [134 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblapacke-dev amd64 3.10.0-2ubuntu1 [358 kB]\nFetched 1,071 kB in 0s (7,645 kB/s)     \ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\ndebconf: falling back to frontend: Readline\nSelecting previously unselected package libtmglib3:amd64.\n(Reading database ... 129184 files and directories currently installed.)\nPreparing to unpack .../libtmglib3_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking libtmglib3:amd64 (3.10.0-2ubuntu1) ...\nSelecting previously unselected package liblapacke:amd64.\nPreparing to unpack .../liblapacke_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking liblapacke:amd64 (3.10.0-2ubuntu1) ...\nSelecting previously unselected package libtmglib-dev:amd64.\nPreparing to unpack .../libtmglib-dev_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking libtmglib-dev:amd64 (3.10.0-2ubuntu1) ...\nSelecting previously unselected package liblapacke-dev:amd64.\nPreparing to unpack .../liblapacke-dev_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking liblapacke-dev:amd64 (3.10.0-2ubuntu1) ...\nSetting up libtmglib3:amd64 (3.10.0-2ubuntu1) ...\nSetting up liblapacke:amd64 (3.10.0-2ubuntu1) ...\nSetting up libtmglib-dev:amd64 (3.10.0-2ubuntu1) ...\nSetting up liblapacke-dev:amd64 (3.10.0-2ubuntu1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n"
    }
   ],
   "source": [
    "!sudo apt-get install liblapacke-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:07.889948Z",
     "iopub.status.busy": "2025-05-26T20:04:07.889074Z",
     "iopub.status.idle": "2025-05-26T20:04:31.587926Z",
     "shell.execute_reply": "2025-05-26T20:04:31.586813Z",
     "shell.execute_reply.started": "2025-05-26T20:04:07.889884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` and ``easy_install``.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://github.com/pypa/setuptools/issues/917 for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nTraceback (most recent call last):\n  File \"/kaggle/working/Panther/pawX/setup.py\", line 4, in <module>\n    setup(\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/__init__.py\", line 117, in setup\n    return distutils.core.setup(**attrs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/core.py\", line 183, in setup\n    return run_commands(dist)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/core.py\", line 199, in run_commands\n    dist.run_commands()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 954, in run_commands\n    self.run_command(cmd)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 991, in run_command\n    super().run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n    cmd_obj.run()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/install.py\", line 97, in run\n    self.do_egg_install()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/install.py\", line 149, in do_egg_install\n    self.run_command('bdist_egg')\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 991, in run_command\n    super().run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n    cmd_obj.run()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/bdist_egg.py\", line 168, in run\n    cmd = self.call_command('install_lib', warn_dir=False)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/bdist_egg.py\", line 154, in call_command\n    self.run_command(cmdname)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 991, in run_command\n    super().run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n    cmd_obj.run()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/install_lib.py\", line 19, in run\n    self.build()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/install_lib.py\", line 110, in build\n    self.run_command('build_ext')\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 991, in run_command\n    super().run_command(command)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n    cmd_obj.run()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/build_ext.py\", line 98, in run\n    _build_ext.run(self)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\n    self.build_extensions()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\", line 900, in build_extensions\n    build_ext.build_extensions(self)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/build_ext.py\", line 476, in build_extensions\n    self._build_extensions_serial()\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/build_ext.py\", line 502, in _build_extensions_serial\n    self.build_extension(ext)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/build_ext.py\", line 263, in build_extension\n    _build_ext.build_extension(self, ext)\n  File \"/usr/local/lib/python3.11/dist-packages/Cython/Distutils/build_ext.py\", line 135, in build_extension\n    super(build_ext, self).build_extension(ext)\n  File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/build_ext.py\", line 557, in build_extension\n    objects = self.compiler.compile(\n              ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\", line 704, in unix_wrap_ninja_compile\n    cuda_post_cflags = unix_cuda_flags(cuda_post_cflags)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\", line 603, in unix_cuda_flags\n    cflags + _get_cuda_arch_flags(cflags))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\", line 2079, in _get_cuda_arch_flags\n    arch_list[-1] += '+PTX'\n    ~~~~~~~~~^^^^\nIndexError: list index out of range\nObtaining file:///kaggle/working/Panther/pawX\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nInstalling collected packages: pawX\n  Running setup.py develop for pawX\n    \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n    \n    \u001b[31m×\u001b[0m \u001b[32mpython setup.py develop\u001b[0m did not run successfully.\n    \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n    \u001b[31m╰─>\u001b[0m See above for output.\n    \n    \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n\n\u001b[31m×\u001b[0m \u001b[32mpython setup.py develop\u001b[0m did not run successfully.\n\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
    }
   ],
   "source": [
    "!cd /kaggle/working/Panther/pawX; python setup.py install\n",
    "!cd /kaggle/working/Panther/pawX; pip install --no-build-isolation -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:31.590591Z",
     "iopub.status.busy": "2025-05-26T20:04:31.590250Z",
     "iopub.status.idle": "2025-05-26T20:04:34.321548Z",
     "shell.execute_reply": "2025-05-26T20:04:34.320449Z",
     "shell.execute_reply.started": "2025-05-26T20:04:31.590559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.6.0+cu124\n3.2.0\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "import triton\n",
    "\n",
    "print(triton.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:34.324584Z",
     "iopub.status.busy": "2025-05-26T20:04:34.324128Z",
     "iopub.status.idle": "2025-05-26T20:04:34.329669Z",
     "shell.execute_reply": "2025-05-26T20:04:34.328497Z",
     "shell.execute_reply.started": "2025-05-26T20:04:34.324557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/kaggle/working/Panther\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:34.331132Z",
     "iopub.status.busy": "2025-05-26T20:04:34.330768Z",
     "iopub.status.idle": "2025-05-26T20:04:41.882347Z",
     "shell.execute_reply": "2025-05-26T20:04:41.880836Z",
     "shell.execute_reply.started": "2025-05-26T20:04:34.331104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Collecting botorch\n  Downloading botorch-0.14.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.13.2)\nCollecting pyre_extensions (from botorch)\n  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\nCollecting gpytorch==1.14 (from botorch)\n  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\nCollecting linear_operator==0.6 (from botorch)\n  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.6.0+cu124)\nCollecting pyro-ppl>=1.8.4 (from botorch)\n  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.15.2)\nRequirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\nRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.6.0)\nCollecting jaxtyping (from gpytorch==1.14->botorch)\n  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.2.2)\nRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\nCollecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\nRequirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyre_extensions->botorch) (0.9.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2.4.1)\nCollecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch==1.14->botorch)\n  Downloading wadler_lindig-0.1.6-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyre_extensions->botorch) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nDownloading botorch-0.14.0-py3-none-any.whl (738 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.3/738.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\nDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\nDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wadler_lindig-0.1.6-py3-none-any.whl (20 kB)\nInstalling collected packages: pyro-api, wadler-lindig, pyre_extensions, jaxtyping, linear_operator, pyro-ppl, gpytorch, botorch\nSuccessfully installed botorch-0.14.0 gpytorch-1.14 jaxtyping-0.3.2 linear_operator-0.6 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 wadler-lindig-0.1.6\n"
    }
   ],
   "source": [
    "!pip install botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:41.885104Z",
     "iopub.status.busy": "2025-05-26T20:04:41.884048Z",
     "iopub.status.idle": "2025-05-26T20:04:44.360917Z",
     "shell.execute_reply": "2025-05-26T20:04:44.359571Z",
     "shell.execute_reply.started": "2025-05-26T20:04:41.885063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from panther.tuner.SkAutoTuner import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# testing normal tree visualizer"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:44.363076Z",
     "iopub.status.busy": "2025-05-26T20:04:44.362400Z",
     "iopub.status.idle": "2025-05-26T20:04:44.462147Z",
     "shell.execute_reply": "2025-05-26T20:04:44.460967Z",
     "shell.execute_reply.started": "2025-05-26T20:04:44.363049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model Tree with Types:\nmodel (SimpleModel)/\n└─ classifier (Sequential)/\n│   ├─ 0 (Linear)\n│   ├─ 1 (ReLU)\n│   ├─ 2 (Dropout)\n│   ├─ 3 (Linear)\n└─ features (Sequential)/\n    └─ 0 (Conv2d)\n    └─ 1 (ReLU)\n    └─ 2 (MaxPool2d)\n    └─ 3 (Conv2d)\n    └─ 4 (ReLU)\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Create a simple test model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        # Some layers to test the visualization\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 16 * 16, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model instance\n",
    "model = SimpleModel()\n",
    "\n",
    "# Test the fixed visualization\n",
    "print(\"Model Tree with Types:\")\n",
    "ModelVisualizer.print_module_tree(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# testing interactive model visualizer on the simple model"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:44.463581Z",
     "iopub.status.busy": "2025-05-26T20:04:44.463284Z",
     "iopub.status.idle": "2025-05-26T20:04:44.704034Z",
     "shell.execute_reply": "2025-05-26T20:04:44.702985Z",
     "shell.execute_reply.started": "2025-05-26T20:04:44.463557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model created. Opening configuration visualizer...\nInstructions:\n1. Ctrl+Click (or Cmd+Click on Mac) on layers in the visualization to select them\n2. Configure sketch parameters for the selected layers\n3. Choose whether to tune layers separately or together\n4. Generate and copy the configuration code\n5. Use the generated code with SKAutoTuner\n\nConfiguration visualization saved to: model_config_visualization.html\nIf the browser doesn't open automatically, open the HTML file manually.\n"
    }
   ],
   "source": [
    "def demonstrate_config_visualizer():\n",
    "    \"\"\"\n",
    "    Demonstrates how to use the ConfigVisualizer to generate layer configurations\n",
    "    for the SKAutoTuner.\n",
    "    \"\"\"\n",
    "    # Create a simple model\n",
    "    model = SimpleModel()\n",
    "\n",
    "    print(\"Model created. Opening configuration visualizer...\")\n",
    "    print(\"Instructions:\")\n",
    "    print(\n",
    "        \"1. Ctrl+Click (or Cmd+Click on Mac) on layers in the visualization to select them\"\n",
    "    )\n",
    "    print(\"2. Configure sketch parameters for the selected layers\")\n",
    "    print(\"3. Choose whether to tune layers separately or together\")\n",
    "    print(\"4. Generate and copy the configuration code\")\n",
    "    print(\"5. Use the generated code with SKAutoTuner\")\n",
    "\n",
    "    # Use the ConfigVisualizer to create an interactive visualization with configuration options\n",
    "    output_path = ConfigVisualizer.create_config_visualization(\n",
    "        model,\n",
    "        output_path=\"model_config_visualization.html\",  # Will be saved in the current directory\n",
    "        open_browser=True,  # Set to True to automatically open in browser\n",
    "    )\n",
    "\n",
    "    print(f\"\\nConfiguration visualization saved to: {output_path}\")\n",
    "    print(\"If the browser doesn't open automatically, open the HTML file manually.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_config_visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# testing interactive model"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:44.705439Z",
     "iopub.status.busy": "2025-05-26T20:04:44.705150Z",
     "iopub.status.idle": "2025-05-26T20:04:44.774737Z",
     "shell.execute_reply": "2025-05-26T20:04:44.773444Z",
     "shell.execute_reply.started": "2025-05-26T20:04:44.705409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model created successfully.\n\nModel structure (text representation):\nmodel (CustomModel)/\n└─ attention (MultiheadAttention)/\n│   ├─ out_proj (NonDynamicallyQuantizableLinear)\n└─ classifier (Sequential)/\n│   ├─ 0 (AdaptiveAvgPool2d)\n│   ├─ 1 (Flatten)\n│   ├─ 2 (Linear)\n│   ├─ 3 (ReLU)\n│   ├─ 4 (Dropout)\n│   ├─ 5 (Linear)\n└─ decoder (Sequential)/\n│   ├─ 0 (CustomBlock)/\n│   │   ├─ bn1 (BatchNorm2d)\n│   │   ├─ bn2 (BatchNorm2d)\n│   │   ├─ conv1 (Conv2d)\n│   │   ├─ conv2 (Conv2d)\n│   ├─ 1 (Upsample)\n│   ├─ 2 (CustomBlock)/\n│   │   ├─ bn1 (BatchNorm2d)\n│   │   ├─ bn2 (BatchNorm2d)\n│   │   ├─ conv1 (Conv2d)\n│   │   ├─ conv2 (Conv2d)\n│   ├─ 3 (Upsample)\n│   ├─ 4 (Conv2d)\n└─ encoder (Sequential)/\n    └─ 0 (CustomBlock)/\n    │   ├─ bn1 (BatchNorm2d)\n    │   ├─ bn2 (BatchNorm2d)\n    │   ├─ conv1 (Conv2d)\n    │   ├─ conv2 (Conv2d)\n    └─ 1 (MaxPool2d)\n    └─ 2 (CustomBlock)/\n    │   ├─ bn1 (BatchNorm2d)\n    │   ├─ bn2 (BatchNorm2d)\n    │   ├─ conv1 (Conv2d)\n    │   ├─ conv2 (Conv2d)\n    └─ 3 (MaxPool2d)\n\nCreating interactive visualization...\n\nVisualization saved to: model_visualization.html\nOpen the HTML file in a web browser to explore the interactive visualization.\nFeatures of the visualization:\n- Click on nodes to see detailed information about each layer\n- Use the search bar to find specific layers\n- Double-click on nodes to collapse/expand sections\n- Mouse wheel or zoom buttons for zooming in/out\n- Right-click on nodes for additional options\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define a custom block with multiple layers\n",
    "class CustomBlock(nn.Module):\n",
    "    \"\"\"A custom block with multiple layers\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(CustomBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define a custom model architecture that combines different types of layers\n",
    "class CustomModel(nn.Module):\n",
    "    \"\"\"A custom model architecture that combines different types of layers\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        # Encoder part with convolutional blocks\n",
    "        self.encoder = nn.Sequential(\n",
    "            CustomBlock(3, 64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            CustomBlock(64, 128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Decoder for reconstruction with upsampling\n",
    "        self.decoder = nn.Sequential(\n",
    "            CustomBlock(128, 64),\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "            CustomBlock(64, 32),\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        # Classifier with attention mechanism\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=128, num_heads=4, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode input\n",
    "        features = self.encoder(x)\n",
    "\n",
    "        # Reconstruct input using decoder\n",
    "        reconstruction = self.decoder(features)\n",
    "\n",
    "        # Apply self-attention to features\n",
    "        batch_size, C, H, W = features.shape\n",
    "        features_flat = features.view(batch_size, C, -1).permute(0, 2, 1)  # [B, HW, C]\n",
    "        attn_output, _ = self.attention(features_flat, features_flat, features_flat)\n",
    "        attn_output = attn_output.permute(0, 2, 1).view(batch_size, C, H, W)\n",
    "\n",
    "        # Combine features and attention output\n",
    "        features_combined = features + attn_output\n",
    "\n",
    "        # Classify\n",
    "        classification = self.classifier(features_combined)\n",
    "\n",
    "        return classification, reconstruction\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create a model instance\n",
    "    model = CustomModel(num_classes=10)\n",
    "\n",
    "    print(\"Model created successfully.\")\n",
    "    print(\"\\nModel structure (text representation):\")\n",
    "    # Print the model structure in text format\n",
    "    ModelVisualizer.print_module_tree(model)\n",
    "\n",
    "    print(\"\\nCreating interactive visualization...\")\n",
    "    # Generate an interactive HTML visualization of the model\n",
    "    output_path = ModelVisualizer.create_interactive_visualization(\n",
    "        model,\n",
    "        output_path=\"model_visualization.html\",  # Will be saved in the current directory\n",
    "        open_browser=True,  # Set to True to automatically open in browser\n",
    "    )\n",
    "\n",
    "    print(f\"\\nVisualization saved to: {output_path}\")\n",
    "    print(\n",
    "        \"Open the HTML file in a web browser to explore the interactive visualization.\"\n",
    "    )\n",
    "    print(\"Features of the visualization:\")\n",
    "    print(\"- Click on nodes to see detailed information about each layer\")\n",
    "    print(\"- Use the search bar to find specific layers\")\n",
    "    print(\"- Double-click on nodes to collapse/expand sections\")\n",
    "    print(\"- Mouse wheel or zoom buttons for zooming in/out\")\n",
    "    print(\"- Right-click on nodes for additional options\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# more complex interactive visualizer testing"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T20:04:44.776376Z",
     "iopub.status.busy": "2025-05-26T20:04:44.775952Z",
     "iopub.status.idle": "2025-05-26T20:06:26.904455Z",
     "shell.execute_reply": "2025-05-26T20:06:26.903309Z",
     "shell.execute_reply.started": "2025-05-26T20:04:44.776324Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Which model would you like to visualize?\n1. Convolutional Neural Network\n2. Transformer Model\n"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": "Enter your choice (1 or 2):  1\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nModel created. Opening configuration visualizer for cnn model...\nInstructions:\n1. Ctrl+Click (or Cmd+Click on Mac) on layers in the visualization to select them\n2. Configure sketch parameters for the selected layers\n3. Choose whether to tune layers separately or together\n4. Generate and copy the configuration code\n5. Use the generated code with SKAutoTuner\n\nConfiguration visualization saved to: cnn_config_visualization.html\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple convolutional network for demonstrating the ConfigVisualizer\n",
    "    with Conv2d layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "\n",
    "        # Encoder blocks\n",
    "        self.encoder = nn.Sequential(\n",
    "            ConvBlock(in_channels, 32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ConvBlock(32, 64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            ConvBlock(64, 128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple transformer-based model for demonstrating the ConfigVisualizer\n",
    "    with attention layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=5000,\n",
    "        d_model=256,\n",
    "        nhead=8,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=1024,\n",
    "        max_seq_length=100,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(max_seq_length, d_model))\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layers, num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(d_model, nhead)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model // 2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add position encoding\n",
    "        seq_length = x.size(1)\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.pos_encoder[:seq_length, :]\n",
    "\n",
    "        # Reshape for transformer: [seq_len, batch, dim]\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Apply transformer\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Self-attention on the output sequence\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Average pooling across sequence dimension\n",
    "        x = attn_output.mean(dim=0)\n",
    "\n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def demonstrate_complex_models():\n",
    "    \"\"\"\n",
    "    Demonstrates the ConfigVisualizer with both convolutional and transformer models\n",
    "    \"\"\"\n",
    "    # Ask which model to visualize\n",
    "    print(\"Which model would you like to visualize?\")\n",
    "    print(\"1. Convolutional Neural Network\")\n",
    "    print(\"2. Transformer Model\")\n",
    "\n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # Create a CNN model\n",
    "        model = SimpleConvNet()\n",
    "        model_name = \"cnn\"\n",
    "    else:\n",
    "        # Create a Transformer model\n",
    "        model = TransformerModel()\n",
    "        model_name = \"transformer\"\n",
    "\n",
    "    print(\n",
    "        f\"\\nModel created. Opening configuration visualizer for {model_name} model...\"\n",
    "    )\n",
    "    print(\"Instructions:\")\n",
    "    print(\n",
    "        \"1. Ctrl+Click (or Cmd+Click on Mac) on layers in the visualization to select them\"\n",
    "    )\n",
    "    print(\"2. Configure sketch parameters for the selected layers\")\n",
    "    print(\"3. Choose whether to tune layers separately or together\")\n",
    "    print(\"4. Generate and copy the configuration code\")\n",
    "    print(\"5. Use the generated code with SKAutoTuner\")\n",
    "\n",
    "    # Use the ConfigVisualizer\n",
    "    output_path = ConfigVisualizer.create_config_visualization(\n",
    "        model, output_path=f\"{model_name}_config_visualization.html\", open_browser=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nConfiguration visualization saved to: {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_complex_models()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}