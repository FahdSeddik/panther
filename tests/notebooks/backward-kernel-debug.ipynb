{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9a1d97",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T21:41:23.186589Z",
     "iopub.status.busy": "2025-03-23T21:41:23.186288Z",
     "iopub.status.idle": "2025-03-23T21:41:23.190221Z",
     "shell.execute_reply": "2025-03-23T21:41:23.189626Z"
    },
    "papermill": {
     "duration": 0.009238,
     "end_time": "2025-03-23T21:41:23.191349",
     "exception": false,
     "start_time": "2025-03-23T21:41:23.182111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\n",
    "# !pip uninstall -y pytorch-triton\n",
    "\n",
    "# !pip install -U --pre triton --index-url https://download.pytorch.org/whl/nightly/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5066ae20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:41:23.198233Z",
     "iopub.status.busy": "2025-03-23T21:41:23.198024Z",
     "iopub.status.idle": "2025-03-23T21:43:45.077949Z",
     "shell.execute_reply": "2025-03-23T21:43:45.076833Z"
    },
    "papermill": {
     "duration": 141.884977,
     "end_time": "2025-03-23T21:43:45.079632",
     "exception": false,
     "start_time": "2025-03-23T21:41:23.194655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Collecting torch\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp310-cp310-linux_x86_64.whl.metadata (27 kB)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp310-cp310-linux_x86_64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Collecting torchaudio\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp310-cp310-linux_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m204.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting triton==3.2.0 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp310-cp310-linux_x86_64.whl (848.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m872.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchaudio, torchvision\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.5.1+cu121\r\n",
      "    Uninstalling torch-2.5.1+cu121:\r\n",
      "      Successfully uninstalled torch-2.5.1+cu121\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.5.1+cu121\r\n",
      "    Uninstalling torchaudio-2.5.1+cu121:\r\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu121\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.20.1+cu121\r\n",
      "    Uninstalling torchvision-0.20.1+cu121:\r\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu118 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118 torchaudio-2.6.0+cu118 torchvision-0.21.0+cu118 triton-3.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \\\n",
    "  torch torchvision torchaudio \\\n",
    "  --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ee62be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:45.166799Z",
     "iopub.status.busy": "2025-03-23T21:43:45.166531Z",
     "iopub.status.idle": "2025-03-23T21:43:47.236640Z",
     "shell.execute_reply": "2025-03-23T21:43:47.235632Z"
    },
    "papermill": {
     "duration": 2.115201,
     "end_time": "2025-03-23T21:43:47.238173",
     "exception": false,
     "start_time": "2025-03-23T21:43:45.122972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\n",
      "2.6.0+cu118\n",
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TRITON_INTERPRET\"] = \"1\"\n",
    "print(os.environ[\"TRITON_INTERPRET\"], \"\\n\")\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import triton\n",
    "import triton.language as tl\n",
    "print(triton.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d145eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:47.323980Z",
     "iopub.status.busy": "2025-03-23T21:43:47.323624Z",
     "iopub.status.idle": "2025-03-23T21:43:51.176007Z",
     "shell.execute_reply": "2025-03-23T21:43:51.174975Z"
    },
    "papermill": {
     "duration": 3.896687,
     "end_time": "2025-03-23T21:43:51.177639",
     "exception": false,
     "start_time": "2025-03-23T21:43:47.280952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!export LC_ALL=\"en_US.UTF-8\"\n",
    "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "!ldconfig /usr/lib64-nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be86d92",
   "metadata": {
    "papermill": {
     "duration": 0.042432,
     "end_time": "2025-03-23T21:43:51.264103",
     "exception": false,
     "start_time": "2025-03-23T21:43:51.221671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "stable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32233006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:51.350229Z",
     "iopub.status.busy": "2025-03-23T21:43:51.349920Z",
     "iopub.status.idle": "2025-03-23T21:43:52.055991Z",
     "shell.execute_reply": "2025-03-23T21:43:52.055033Z"
    },
    "papermill": {
     "duration": 0.750792,
     "end_time": "2025-03-23T21:43:52.057460",
     "exception": false,
     "start_time": "2025-03-23T21:43:51.306668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match 1\n",
      "✅ Triton and Torch match 2\n"
     ]
    }
   ],
   "source": [
    "def get_cuda_autotune_config():\n",
    "    return [\n",
    "        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=1,\n",
    "                      num_warps=4)\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'eBLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n",
    "        #               num_warps=2),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n",
    "        #               num_warps=2),\n",
    "        # # Good config for fp8 inputs.\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n",
    "        #               num_warps=8),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n",
    "        #               num_warps=8),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4)\n",
    "    ]\n",
    "\n",
    "# @triton.autotune(\n",
    "#     configs=[triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 2})],\n",
    "#     key=['BSIZE', 'K', 'd1'],\n",
    "# )\n",
    "@triton.jit\n",
    "def first_pass_gU1s_g_S2s_kernel(\n",
    "        g_ptr, U1s_ptr, S2s_ptr, g_U1s_ptr, g_S2s_ptr,\n",
    "        BSIZE, K, d1, L,\n",
    "        stride_g_bsize, stride_g_d1,\n",
    "        stride_su_l, stride_su_d1, stride_su_k,\n",
    "        stride_out_l, stride_out_bsize, stride_out_k,\n",
    "        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_d1: tl.constexpr,\n",
    "        GROUP_SIZE_BSIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=1)\n",
    "    batch_id = tl.program_id(axis=0)\n",
    "    \n",
    "    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n",
    "    num_pid_k = tl.cdiv(K, BLOCK_SIZE_K)\n",
    "    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_k\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n",
    "    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n",
    "    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n",
    "    pid_k = (pid % num_pid_in_group) // group_size_bsize\n",
    "\n",
    "    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n",
    "    offs_k = pid_k *  BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_d1 = tl.arange(0, BLOCK_SIZE_d1)\n",
    "\n",
    "    g_ptrs = g_ptr + (offs_bsize[:, None] * stride_g_bsize + offs_d1[None, :] * stride_g_d1)\n",
    "\n",
    "    su_tmp = batch_id * stride_su_l + (offs_d1[:, None] * stride_su_d1 + offs_k[None, :] * stride_su_k)\n",
    "    U1s_ptrs = U1s_ptr + su_tmp\n",
    "    S2s_ptrs = S2s_ptr + su_tmp\n",
    "\n",
    "    accumulator1 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n",
    "    accumulator2 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n",
    "    \n",
    "    \n",
    "    for d1_i in range(0, tl.cdiv(d1, BLOCK_SIZE_d1)):\n",
    "        g = tl.load(g_ptrs, mask=(offs_d1[None, :] < d1 - d1_i * BLOCK_SIZE_d1), other=0.0)\n",
    "        \n",
    "        su_mask = (offs_d1[:, None] < d1 - d1_i * BLOCK_SIZE_d1)\n",
    "        U1s = tl.load(U1s_ptrs, mask=su_mask, other=0.0)\n",
    "        S2s = tl.load(S2s_ptrs, mask=su_mask, other=0.0)\n",
    "        \n",
    "        accumulator1 += tl.dot(g, U1s)\n",
    "        accumulator2 += tl.dot(g, S2s)\n",
    "        \n",
    "        g_ptrs += BLOCK_SIZE_d1 * stride_g_d1\n",
    "        U1s_ptrs += BLOCK_SIZE_d1 * stride_su_d1\n",
    "        S2s_ptrs += BLOCK_SIZE_d1 * stride_su_d1\n",
    "\n",
    "    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n",
    "    g_U1s_ptrs = g_U1s_ptr + out_tmp\n",
    "    g_S2s_ptrs = g_S2s_ptr + out_tmp\n",
    "    \n",
    "    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_k[None, :] < K)\n",
    "    \n",
    "    tl.store(g_U1s_ptrs, accumulator1, mask=out_mask)\n",
    "    tl.store(g_S2s_ptrs, accumulator2, mask=out_mask)\n",
    "\n",
    "def first_pass_gU1s_g_S2s(g, U1s, S2s):\n",
    "    assert g.shape[1] == U1s.shape[1], \"Incompatible dimensions\"\n",
    "    assert g.shape[1] == S2s.shape[1], \"Incompatible dimensions\"\n",
    "    assert g.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert U1s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert S2s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert U1s.stride() == S2s.stride(), \"Matrix A must be contiguous\"\n",
    "    \n",
    "    BSIZE, d1 = g.shape\n",
    "    L, _, K = U1s.shape\n",
    "    \n",
    "    BLOCK_SIZE_BSIZE, BLOCK_SIZE_K, BLOCK_SIZE_d1 = 32, 64, 16\n",
    "    GROUP_SIZE_BSIZE = 2\n",
    "    \n",
    "    g_U1s = torch.empty((L, BSIZE, K), dtype=torch.float32)\n",
    "    g_S2s = torch.empty((L, BSIZE, K), dtype=torch.float32)\n",
    "\n",
    "    stride_g_bsize, stride_g_d1 = g.stride()\n",
    "    stride_su_l, stride_su_d1, stride_su_k = U1s.stride()\n",
    "    stride_out_l, stride_out_bsize, stride_out_k = g_U1s.stride()\n",
    "    \n",
    "    assert g_U1s.stride() == g_S2s.stride(), \"Matrix A must be contiguous\"\n",
    "    \n",
    "    grid = lambda META: (L, triton.cdiv(BSIZE, BLOCK_SIZE_BSIZE) * triton.cdiv(K, BLOCK_SIZE_K), )\n",
    "    \n",
    "    first_pass_gU1s_g_S2s_kernel[grid](\n",
    "        g, U1s, S2s, g_U1s, g_S2s,\n",
    "        BSIZE, K, d1, L,\n",
    "        stride_g_bsize, stride_g_d1,\n",
    "        stride_su_l, stride_su_d1, stride_su_k,\n",
    "        stride_out_l, stride_out_bsize, stride_out_k,\n",
    "        BLOCK_SIZE_BSIZE, BLOCK_SIZE_K, BLOCK_SIZE_d1,\n",
    "        GROUP_SIZE_BSIZE\n",
    "    )\n",
    "    \n",
    "    return g_U1s, g_S2s\n",
    "\n",
    "L = 4\n",
    "BSIZE, d1 = 128, 16\n",
    "K = 256\n",
    "\n",
    "torch.manual_seed(0)\n",
    "g = torch.randn((BSIZE, d1), dtype=torch.float32)\n",
    "U1s = torch.randn((L, d1, K), dtype=torch.float32)\n",
    "S2s = torch.randn((L, d1, K), dtype=torch.float32)\n",
    "\n",
    "g_U1s, g_S2s = first_pass_gU1s_g_S2s(g, U1s, S2s)\n",
    "torch_output1 = (g.unsqueeze(0).expand(L, BSIZE, d1)).bmm(U1s)\n",
    "torch_output2 = (g.unsqueeze(0).expand(L, BSIZE, d1)).bmm(S2s)\n",
    "\n",
    "rtol = 1e-2\n",
    "if torch.allclose(g_U1s, torch_output1, atol=1e-2, rtol=rtol):\n",
    "    print(\"✅ Triton and Torch match 1\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ 1\")\n",
    "\n",
    "if torch.allclose(g_S2s, torch_output2, atol=1e-2, rtol=rtol):\n",
    "    print(\"✅ Triton and Torch match 2\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e503893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:52.142743Z",
     "iopub.status.busy": "2025-03-23T21:43:52.142506Z",
     "iopub.status.idle": "2025-03-23T21:43:53.175553Z",
     "shell.execute_reply": "2025-03-23T21:43:53.174588Z"
    },
    "papermill": {
     "duration": 1.077607,
     "end_time": "2025-03-23T21:43:53.177392",
     "exception": false,
     "start_time": "2025-03-23T21:43:52.099785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match\n"
     ]
    }
   ],
   "source": [
    "def get_cuda_autotune_config():\n",
    "    return [\n",
    "        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=1,\n",
    "                      num_warps=4)\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n",
    "        #               num_warps=2),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n",
    "        #               num_warps=2),\n",
    "        # # Good config for fp8 inputs.\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n",
    "        #               num_warps=8),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n",
    "        #               num_warps=8),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4),\n",
    "        # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n",
    "        #               num_warps=4)\n",
    "    ]\n",
    "\n",
    "# @triton.autotune(\n",
    "#     configs=[triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 2})],\n",
    "#     key=['BSIZE', 'K', 'K'],\n",
    "# )\n",
    "@triton.jit\n",
    "def second_pass_gUS11_22_kernel(\n",
    "        g_U1s_ptr, g_S2s_ptr, S1s_ptr, U2s_ptr, out_ptr,\n",
    "        BSIZE, d2, K, L,\n",
    "        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n",
    "        stride_us_l, stride_us_k, stride_us_d2,\n",
    "        stride_out_bsize, stride_out_d2,\n",
    "        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_d2: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "        GROUP_SIZE_BSIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    \n",
    "    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n",
    "    num_pid_d2 = tl.cdiv(d2, BLOCK_SIZE_d2)\n",
    "    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_d2\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n",
    "    GROUP_SIZE_BSIZE = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n",
    "    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % GROUP_SIZE_BSIZE)\n",
    "    pid_d2 = (pid % num_pid_in_group) // GROUP_SIZE_BSIZE\n",
    "\n",
    "    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n",
    "    offs_d2 = pid_d2 *  BLOCK_SIZE_d2 + tl.arange(0, BLOCK_SIZE_d2)\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "\n",
    "    in_tmp = offs_bsize[:, None] * stride_g_U1s2_bsize + offs_k[None, :] * stride_g_U1s2_k\n",
    "    us_tmp = offs_k[:, None] * stride_us_k + offs_d2[None, :] * stride_us_d2\n",
    "\n",
    "    accumulator = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2), value=0.0, dtype=tl.float32)\n",
    "    \n",
    "    for l in range(0, L):\n",
    "        l_tmp_stride = l * stride_g_U1s2_l\n",
    "        \n",
    "        g_U1s_ptrs = l_tmp_stride + g_U1s_ptr + in_tmp\n",
    "        g_S2s_ptrs = l_tmp_stride + g_S2s_ptr + in_tmp\n",
    "\n",
    "        S1s_ptrs = l_tmp_stride + S1s_ptr + us_tmp\n",
    "        U2s_ptrs = l_tmp_stride + U2s_ptr + us_tmp\n",
    "        \n",
    "        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "            in_mask = offs_k[None, :] < K - k * BLOCK_SIZE_K\n",
    "            g_U1s = tl.load(g_U1s_ptrs, mask=in_mask, other=0.0)\n",
    "            g_S2s = tl.load(g_S2s_ptrs, mask=in_mask, other=0.0)\n",
    "            \n",
    "            us_mask = offs_k[:, None] < K - k * BLOCK_SIZE_K\n",
    "            S1s = tl.load(S1s_ptrs, mask=us_mask, other=0.0)\n",
    "            U2s = tl.load(U2s_ptrs, mask=us_mask, other=0.0)\n",
    "            \n",
    "            accumulator += tl.dot(g_U1s, S1s)\n",
    "            accumulator += tl.dot(g_S2s, U2s)\n",
    "\n",
    "            in_inc = BLOCK_SIZE_K * stride_g_U1s2_k\n",
    "            g_U1s_ptrs += in_inc\n",
    "            g_S2s_ptrs += in_inc\n",
    "            \n",
    "            us_inc = BLOCK_SIZE_K * stride_us_k\n",
    "            S1s_ptrs += us_inc\n",
    "            U2s_ptrs += us_inc\n",
    "    \n",
    "    accumulator *= (1.0/ (2.0 * L))\n",
    "\n",
    "    out_ptrs = out_ptr + stride_out_bsize * offs_bsize[:, None] + stride_out_d2 * offs_d2[None, :]\n",
    "    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_d2[None, :] < d2)\n",
    "    \n",
    "    tl.store(out_ptrs, accumulator, mask=out_mask)\n",
    "\n",
    "def second_pass_gUS11_22(g_U1s, g_S2s, S1s, U2s):\n",
    "    assert g_U1s.shape[2] == S1s.shape[1], \"Incompatible dimensions\"\n",
    "    assert g_S2s.shape[2] == U2s.shape[1], \"Incompatible dimensions\"\n",
    "    assert g_U1s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert g_S2s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert S1s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert U2s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert S1s.stride() == U2s.stride(), \"Matrix A must be contiguous\"\n",
    "    assert g_U1s.stride() == g_S2s.stride(), \"Matrix A must be contiguous\"\n",
    "    \n",
    "    L, BSIZE, K = g_U1s.shape\n",
    "    _, _, d2 = S1s.shape\n",
    "    \n",
    "    BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2, BLOCK_SIZE_K = 32, 64, 16\n",
    "    GROUP_SIZE_BSIZE = 2\n",
    "    \n",
    "    out = torch.empty((BSIZE, d2), dtype=torch.float32)\n",
    "\n",
    "    stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k = g_U1s.stride()\n",
    "    stride_us_l, stride_us_k, stride_us_d2 = S1s.stride()\n",
    "    stride_out_bsize, stride_out_d2 = out.stride()\n",
    "    \n",
    "    grid = lambda META: (triton.cdiv(BSIZE, BLOCK_SIZE_BSIZE) * triton.cdiv(d2, BLOCK_SIZE_d2), )\n",
    "    \n",
    "    second_pass_gUS11_22_kernel[grid](\n",
    "        g_U1s, g_S2s, S1s, U2s, out,\n",
    "        BSIZE, d2, K, L,\n",
    "        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n",
    "        stride_us_l, stride_us_k, stride_us_d2,\n",
    "        stride_out_bsize, stride_out_d2,\n",
    "        BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2, BLOCK_SIZE_K,\n",
    "        GROUP_SIZE_BSIZE\n",
    "    )\n",
    "    \n",
    "    return out\n",
    "\n",
    "########################################################\n",
    "scale = 1\n",
    "g_U1s = g_U1s * scale  # g_U1s -> l * bsize * k\n",
    "g_S2s = g_S2s * scale # g_S2s -> l * bsize * k\n",
    "\n",
    "d2 = 128\n",
    "\n",
    "S1s = torch.randn((L, K, d2), dtype=torch.float32) * scale\n",
    "U2s = torch.randn((L, K, d2), dtype=torch.float32) * scale\n",
    "\n",
    "grad = second_pass_gUS11_22(g_U1s, g_S2s, S1s, U2s) # grad\n",
    "\n",
    "torch_output = (g_U1s.bmm(S1s).mean(0) / 2) + (g_S2s.bmm(U2s).mean(0) / 2)\n",
    "\n",
    "rtol = 1e-2\n",
    "if torch.allclose(grad, torch_output, atol=1e-2, rtol=rtol):\n",
    "    print(\"✅ Triton and Torch match\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525669c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:53.275083Z",
     "iopub.status.busy": "2025-03-23T21:43:53.274829Z",
     "iopub.status.idle": "2025-03-23T21:43:54.182960Z",
     "shell.execute_reply": "2025-03-23T21:43:54.182129Z"
    },
    "papermill": {
     "duration": 0.952961,
     "end_time": "2025-03-23T21:43:54.184273",
     "exception": false,
     "start_time": "2025-03-23T21:43:53.231312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match 1\n"
     ]
    }
   ],
   "source": [
    "# @triton.autotune(\n",
    "#     configs=[\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=1, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=5, num_warps=2),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=5, num_warps=2),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=3, num_warps=8),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=3, num_warps=8),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4)\n",
    "# ],\n",
    "#     key=['d2', 'k', 'BSIZE', 'L'],\n",
    "# )\n",
    "@triton.jit\n",
    "def calc_grad_S1s_kernel(\n",
    "        hin_ptr, g_U1s_ptr, grad_g_S1s_ptr,\n",
    "        d2, k, BSIZE, L,\n",
    "        stride_hin_bsize, stride_hin_BSIZE,\n",
    "        stride_su_l, stride_su_BSIZE, stride_su_k,\n",
    "        stride_out_l, stride_out_bsize, stride_out_k,\n",
    "        BLOCK_SIZE_d2: tl.constexpr, BLOCK_SIZE_k: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr,\n",
    "        GROUP_SIZE_d2: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=1)\n",
    "    batch_id = tl.program_id(axis=0)\n",
    "    \n",
    "    num_pid_bsize = tl.cdiv(d2, BLOCK_SIZE_d2)\n",
    "    num_pid_k = tl.cdiv(k, BLOCK_SIZE_k)\n",
    "    num_pid_in_group = GROUP_SIZE_d2 * num_pid_k\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_bsize = group_id * GROUP_SIZE_d2\n",
    "    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_d2)\n",
    "    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n",
    "    pid_k = (pid % num_pid_in_group) // group_size_bsize\n",
    "\n",
    "    offs_bsize = pid_bsize * BLOCK_SIZE_d2 + tl.arange(0, BLOCK_SIZE_d2)\n",
    "    offs_k = pid_k *  BLOCK_SIZE_k + tl.arange(0, BLOCK_SIZE_k)\n",
    "    offs_BSIZE = tl.arange(0, BLOCK_SIZE_BSIZE)\n",
    "\n",
    "    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_d2), BLOCK_SIZE_d2)\n",
    "    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_k), BLOCK_SIZE_k)\n",
    "    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n",
    "    \n",
    "    hin_ptrs = hin_ptr + (offs_bsize[:, None] * stride_hin_bsize + offs_BSIZE[None, :] * stride_hin_BSIZE)\n",
    "\n",
    "    su_tmp = batch_id * stride_su_l + (offs_BSIZE[:, None] * stride_su_BSIZE + offs_k[None, :] * stride_su_k)\n",
    "    g_U1s_ptrs = g_U1s_ptr + su_tmp\n",
    "\n",
    "    accumulator1 = tl.full(shape=(BLOCK_SIZE_d2, BLOCK_SIZE_k), value=0.0, dtype=tl.float32)\n",
    "    accumulator2 = tl.full(shape=(BLOCK_SIZE_d2, BLOCK_SIZE_k), value=0.0, dtype=tl.float32)\n",
    "    \n",
    "    for BSIZE_i in range(0, tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)):\n",
    "        hin_mask = (offs_bsize[:, None] < d2) & (offs_BSIZE[None, :] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE)\n",
    "        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n",
    "        \n",
    "        su_mask = (offs_BSIZE[:, None] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE) & (offs_k[None, :] < k)\n",
    "        g_U1s = tl.load(g_U1s_ptrs, mask=su_mask, other=0.0)\n",
    "        \n",
    "        accumulator1 += tl.dot(hin, g_U1s)\n",
    "        \n",
    "        hin_ptrs += BLOCK_SIZE_BSIZE * stride_hin_BSIZE\n",
    "        g_U1s_ptrs += BLOCK_SIZE_BSIZE * stride_su_BSIZE\n",
    "\n",
    "    accumulator1 = accumulator1.to(tl.float16)\n",
    "    accumulator2 = accumulator2.to(tl.float16)\n",
    "\n",
    "    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n",
    "    grad_g_S1s_ptrs = grad_g_S1s_ptr + out_tmp\n",
    "    \n",
    "    out_mask = (offs_bsize[:, None] < d2) & (offs_k[None, :] < k)\n",
    "    \n",
    "    tl.store(grad_g_S1s_ptrs, accumulator1, mask=out_mask)\n",
    "\n",
    "def calc_grad_S1s(hin, g_U1s):\n",
    "    device = 'cuda'\n",
    "    assert hin.shape[1] == g_U1s.shape[1], \"Incompatible dimensions\"\n",
    "    assert hin.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert g_U1s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    \n",
    "    d2, BSIZE = hin.shape\n",
    "    L, _, k = g_U1s.shape\n",
    "    \n",
    "    grad_g_S1s = torch.empty((L, d2, k), dtype=torch.float16, device=device)\n",
    "\n",
    "    stride_hin_bsize, stride_hin_BSIZE = hin.stride()\n",
    "    stride_su_l, stride_su_BSIZE, stride_su_k = g_U1s.stride()\n",
    "    stride_out_l, stride_out_bsize, stride_out_k = grad_g_S1s.stride()\n",
    "\n",
    "    BLOCK_SIZE_d2, BLOCK_SIZE_k, BLOCK_SIZE_BSIZE = 128, 256, 64\n",
    "    GROUP_SIZE_d2 = 8\n",
    "    \n",
    "    grid = lambda META: (L, triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]) * triton.cdiv(k, META[\"BLOCK_SIZE_k\"]), )\n",
    "    \n",
    "    calc_grad_S1s_kernel[grid](\n",
    "        hin, g_U1s, grad_g_S1s,\n",
    "        d2, k, BSIZE, L,\n",
    "        stride_hin_bsize, stride_hin_BSIZE,\n",
    "        stride_su_l, stride_su_BSIZE, stride_su_k,\n",
    "        stride_out_l, stride_out_bsize, stride_out_k,\n",
    "        BLOCK_SIZE_d2, BLOCK_SIZE_k, BLOCK_SIZE_BSIZE,\n",
    "        GROUP_SIZE_d2\n",
    "    )\n",
    "    \n",
    "    return grad_g_S1s\n",
    "\n",
    "device = 'cuda'\n",
    "k = K\n",
    "d2 = 1024\n",
    "\n",
    "torch.manual_seed(0)\n",
    "hin = torch.randn((d2, BSIZE), dtype=torch.float16, device=device)\n",
    "g_U1s = torch.randn((L, BSIZE, k), dtype=torch.float16, device=device)\n",
    "\n",
    "grad_g_S1s = calc_grad_S1s(hin, g_U1s)\n",
    "\n",
    "torch_output1 = (hin.unsqueeze(0).expand(L, d2, BSIZE)).bmm(g_U1s)\n",
    "\n",
    "rtol = 1e-2\n",
    "if torch.allclose(grad_g_S1s, torch_output1, atol=1e-2, rtol=rtol):\n",
    "    print(\"✅ Triton and Torch match 1\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec1075e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:54.310023Z",
     "iopub.status.busy": "2025-03-23T21:43:54.309721Z",
     "iopub.status.idle": "2025-03-23T21:43:54.737028Z",
     "shell.execute_reply": "2025-03-23T21:43:54.735871Z"
    },
    "papermill": {
     "duration": 0.510384,
     "end_time": "2025-03-23T21:43:54.738521",
     "exception": false,
     "start_time": "2025-03-23T21:43:54.228137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match 1\n"
     ]
    }
   ],
   "source": [
    "# @triton.autotune(\n",
    "#     configs=[\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=1, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4)\n",
    "# ],\n",
    "#     key=['K', 'd2', 'BSIZE', 'L'],\n",
    "# )\n",
    "@triton.jit\n",
    "def first_pass_U2s_hin_d2ernel(\n",
    "        hin_ptr, U2s_ptr, U2s_h_in_ptr,\n",
    "        K, d2, BSIZE, L,\n",
    "        stride_hin_d2, stride_hin_BSIZE,\n",
    "        stride_su_l, stride_su_K, stride_su_d2,\n",
    "        stride_out_l, stride_out_K, stride_out_BSIZE,\n",
    "        BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_d2: tl.constexpr,\n",
    "        GROUP_SIZE_K: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=1)\n",
    "    batch_id = tl.program_id(axis=0)\n",
    "    \n",
    "    num_pid_K = tl.cdiv(K, BLOCK_SIZE_K)\n",
    "    num_pid_BSIZE = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n",
    "    num_pid_in_group = GROUP_SIZE_K * num_pid_BSIZE\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_K = group_id * GROUP_SIZE_K\n",
    "    group_size_BSIZE = min(num_pid_K - first_pid_K, GROUP_SIZE_K)\n",
    "    pid_K = first_pid_K + ((pid % num_pid_in_group) % group_size_BSIZE)\n",
    "    pid_BSIZE = (pid % num_pid_in_group) // group_size_BSIZE\n",
    "\n",
    "    offs_K = pid_K * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_BSIZE = pid_BSIZE *  BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n",
    "    offs_d2 = tl.arange(0, BLOCK_SIZE_d2)\n",
    "\n",
    "    offs_K = tl.max_contiguous(tl.multiple_of(offs_K, BLOCK_SIZE_K), BLOCK_SIZE_K)\n",
    "    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n",
    "    offs_d2 = tl.max_contiguous(tl.multiple_of(offs_d2, BLOCK_SIZE_d2), BLOCK_SIZE_d2)\n",
    "    \n",
    "    hin_ptrs = hin_ptr + (offs_d2[:, None] * stride_hin_d2 + offs_BSIZE[None, :] * stride_hin_BSIZE)\n",
    "\n",
    "    su_tmp = batch_id * stride_su_l + (offs_K[:, None] * stride_su_K + offs_d2[None, :] * stride_su_d2)\n",
    "    U2s_ptrs = U2s_ptr + su_tmp\n",
    "\n",
    "    accumulator1 = tl.full(shape=(BLOCK_SIZE_K, BLOCK_SIZE_BSIZE), value=0.0, dtype=tl.float32)\n",
    "    \n",
    "    for d2_i in range(0, tl.cdiv(d2, BLOCK_SIZE_d2)):\n",
    "        hin_mask = (offs_d2[:, None] < d2 - d2_i * BLOCK_SIZE_d2) & (offs_BSIZE[None, :] < BSIZE)\n",
    "        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n",
    "        \n",
    "        su_mask = (offs_K[:, None] < K) & (offs_d2[None, :] < d2 - d2_i * BLOCK_SIZE_d2)\n",
    "        U2s = tl.load(U2s_ptrs, mask=su_mask, other=0.0)\n",
    "        \n",
    "        accumulator1 += tl.dot(U2s, hin)\n",
    "        \n",
    "        hin_ptrs += BLOCK_SIZE_d2 * stride_hin_d2\n",
    "        U2s_ptrs += BLOCK_SIZE_d2 * stride_su_d2\n",
    "\n",
    "    accumulator1 = accumulator1.to(tl.float16)\n",
    "\n",
    "    out_tmp = batch_id * stride_out_l + stride_out_K * offs_K[:, None] + stride_out_BSIZE * offs_BSIZE[None, :]\n",
    "    U2s_h_in_ptrs = U2s_h_in_ptr + out_tmp\n",
    "    \n",
    "    out_mask = (offs_K[:, None] < K) & (offs_BSIZE[None, :] < BSIZE)\n",
    "    \n",
    "    tl.store(U2s_h_in_ptrs, accumulator1, mask=out_mask)\n",
    "\n",
    "def first_pass_U2s_hin(U2s, hin):\n",
    "    device = 'cuda'\n",
    "    assert U2s.shape[2] == hin.shape[0], \"Incompatible dimensions\"\n",
    "    assert hin.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert U2s.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    \n",
    "    L, K, d2 = U2s.shape\n",
    "    _, BSIZE = hin.shape\n",
    "    \n",
    "    U2s_h_in = torch.empty((L, K, BSIZE), dtype=torch.float16, device=device)\n",
    "\n",
    "    stride_hin_d2, stride_hin_BSIZE = hin.stride()\n",
    "    stride_su_l, stride_su_K, stride_su_d2 = U2s.stride()\n",
    "    stride_out_l, stride_out_K, stride_out_BSIZE = U2s_h_in.stride()\n",
    "\n",
    "    BLOCK_SIZE_K, BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2 = 128, 256, 64\n",
    "    GROUP_SIZE_K = 8\n",
    "    \n",
    "    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]), )\n",
    "    \n",
    "    first_pass_U2s_hin_d2ernel[grid](\n",
    "        hin, U2s, U2s_h_in,\n",
    "        K, d2, BSIZE, L,\n",
    "        stride_hin_d2, stride_hin_BSIZE,\n",
    "        stride_su_l, stride_su_K, stride_su_d2,\n",
    "        stride_out_l, stride_out_K, stride_out_BSIZE,\n",
    "        BLOCK_SIZE_K, BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2,\n",
    "        GROUP_SIZE_K\n",
    "    )\n",
    "    \n",
    "    return U2s_h_in\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "d2 = 1024\n",
    "\n",
    "torch.manual_seed(0)\n",
    "U2s = torch.randn((L, K, d2), dtype=torch.float16, device=device)\n",
    "hin = torch.randn((d2, BSIZE), dtype=torch.float16, device=device)\n",
    "\n",
    "U2s_h_in = first_pass_U2s_hin(U2s, hin)\n",
    "\n",
    "torch_output1 = U2s.bmm(hin.unsqueeze(0).expand(L, d2, BSIZE))\n",
    "\n",
    "rtol = 1e-2\n",
    "if torch.allclose(U2s_h_in, torch_output1, atol=1e-2, rtol=rtol):\n",
    "    print(\"✅ Triton and Torch match 1\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c674ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T21:43:54.825432Z",
     "iopub.status.busy": "2025-03-23T21:43:54.825180Z",
     "iopub.status.idle": "2025-03-23T21:43:55.251742Z",
     "shell.execute_reply": "2025-03-23T21:43:55.250844Z"
    },
    "papermill": {
     "duration": 0.470933,
     "end_time": "2025-03-23T21:43:55.253098",
     "exception": false,
     "start_time": "2025-03-23T21:43:54.782165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match 1\n"
     ]
    }
   ],
   "source": [
    "# @triton.autotune(\n",
    "#     configs=[\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_K': 8}, num_stages=1, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n",
    "#     triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4)\n",
    "# ],\n",
    "#     key=['K', 'BSIZE', 'd1', 'L'],\n",
    "# )\n",
    "@triton.jit\n",
    "def calc_grad_S2s_BSIZEernel(\n",
    "        g_ptr, U2s_hin_ptr, grad_S2s_ptr,\n",
    "        K, BSIZE, d1, L,\n",
    "        stride_g_BSIZE, stride_g_d1,\n",
    "        stride_su_l, stride_su_K, stride_su_BSIZE,\n",
    "        stride_out_l, stride_out_K, stride_out_d1,\n",
    "        BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_d1: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr,\n",
    "        GROUP_SIZE_K: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(axis=1)\n",
    "    batch_id = tl.program_id(axis=0)\n",
    "    \n",
    "    num_pid_K = tl.cdiv(K, BLOCK_SIZE_K)\n",
    "    num_pid_d1 = tl.cdiv(d1, BLOCK_SIZE_d1)\n",
    "    num_pid_in_group = GROUP_SIZE_K * num_pid_d1\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_K = group_id * GROUP_SIZE_K\n",
    "    group_size_d1 = min(num_pid_K - first_pid_K, GROUP_SIZE_K)\n",
    "    pid_K = first_pid_K + ((pid % num_pid_in_group) % group_size_d1)\n",
    "    pid_d1 = (pid % num_pid_in_group) // group_size_d1\n",
    "\n",
    "    offs_K = pid_K * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_d1 = pid_d1 *  BLOCK_SIZE_d1 + tl.arange(0, BLOCK_SIZE_d1)\n",
    "    offs_BSIZE = tl.arange(0, BLOCK_SIZE_BSIZE)\n",
    "\n",
    "    offs_K = tl.max_contiguous(tl.multiple_of(offs_K, BLOCK_SIZE_K), BLOCK_SIZE_K)\n",
    "    offs_d1 = tl.max_contiguous(tl.multiple_of(offs_d1, BLOCK_SIZE_d1), BLOCK_SIZE_d1)\n",
    "    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n",
    "    \n",
    "    g_ptrs = g_ptr + (offs_BSIZE[:, None] * stride_g_BSIZE + offs_d1[None, :] * stride_g_d1)\n",
    "\n",
    "    su_tmp = batch_id * stride_su_l + (offs_K[:, None] * stride_su_K + offs_BSIZE[None, :] * stride_su_BSIZE)\n",
    "    U2s_hin_ptrs = U2s_hin_ptr + su_tmp\n",
    "\n",
    "    accumulator1 = tl.full(shape=(BLOCK_SIZE_K, BLOCK_SIZE_d1), value=0.0, dtype=tl.float32)\n",
    "    \n",
    "    for BSIZE_i in range(0, tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)):\n",
    "        g_mask = (offs_BSIZE[:, None] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE) & (offs_d1[None, :] < d1)\n",
    "        g = tl.load(g_ptrs, mask=g_mask, other=0.0)\n",
    "        \n",
    "        su_mask = (offs_K[:, None] < K) & (offs_BSIZE[None, :] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE)\n",
    "        U2s_hin = tl.load(U2s_hin_ptrs, mask=su_mask, other=0.0)\n",
    "        \n",
    "        accumulator1 += tl.dot(U2s_hin, g)\n",
    "        \n",
    "        g_ptrs += BLOCK_SIZE_BSIZE * stride_g_BSIZE\n",
    "        U2s_hin_ptrs += BLOCK_SIZE_BSIZE * stride_su_BSIZE\n",
    "\n",
    "    accumulator1 = accumulator1.to(tl.float16)\n",
    "\n",
    "    out_tmp = batch_id * stride_out_l + stride_out_K * offs_K[:, None] + stride_out_d1 * offs_d1[None, :]\n",
    "    grad_S2s_ptrs = grad_S2s_ptr + out_tmp\n",
    "    \n",
    "    out_mask = (offs_K[:, None] < K) & (offs_d1[None, :] < d1)\n",
    "    \n",
    "    tl.store(grad_S2s_ptrs, accumulator1, mask=out_mask)\n",
    "\n",
    "def calc_grad_S2s(U2s_hin, g):\n",
    "    device = 'cuda'\n",
    "    assert U2s_hin.shape[2] == g.shape[0], \"Incompatible dimensions\"\n",
    "    assert g.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    assert U2s_hin.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    \n",
    "    L, K, BSIZE = U2s_hin.shape\n",
    "    _, d1 = g.shape\n",
    "    \n",
    "    grad_S2s = torch.empty((L, K, d1), dtype=torch.float16, device=device)\n",
    "\n",
    "    stride_g_BSIZE, stride_g_d1 = g.stride()\n",
    "    stride_su_l, stride_su_K, stride_su_BSIZE = U2s_hin.stride()\n",
    "    stride_out_l, stride_out_K, stride_out_d1 = grad_S2s.stride()\n",
    "\n",
    "    BLOCK_SIZE_K, BLOCK_SIZE_d1, BLOCK_SIZE_BSIZE = 128, 256, 64\n",
    "    GROUP_SIZE_K = 8\n",
    "    \n",
    "    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_d1\"]), )\n",
    "    \n",
    "    calc_grad_S2s_BSIZEernel[grid](\n",
    "        g, U2s_hin, grad_S2s,\n",
    "        K, BSIZE, d1, L,\n",
    "        stride_g_BSIZE, stride_g_d1,\n",
    "        stride_su_l, stride_su_K, stride_su_BSIZE,\n",
    "        stride_out_l, stride_out_K, stride_out_d1,\n",
    "        BLOCK_SIZE_K, BLOCK_SIZE_d1, BLOCK_SIZE_BSIZE,\n",
    "        GROUP_SIZE_K\n",
    "    )\n",
    "    \n",
    "    return grad_S2s\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "BSIZE = 1024\n",
    "\n",
    "torch.manual_seed(0)\n",
    "U2s_hin = torch.randn((L, K, BSIZE), dtype=torch.float16, device=device)\n",
    "g = torch.randn((BSIZE, d1), dtype=torch.float16, device=device)\n",
    "\n",
    "grad_S2s = calc_grad_S2s(U2s_hin, g)\n",
    "\n",
    "torch_output1 = U2s_hin.bmm(g.unsqueeze(0).expand(L, BSIZE, d1))\n",
    "\n",
    "rtol = 1e-2\n",
    "if torch.allclose(grad_S2s, torch_output1, atol=1e-2, rtol=rtol):\n",
    "    print(\"✅ Triton and Torch match 1\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ 1\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 155.509651,
   "end_time": "2025-03-23T21:43:56.113736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-23T21:41:20.604085",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
