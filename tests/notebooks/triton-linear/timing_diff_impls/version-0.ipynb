{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:20.685909Z",
     "iopub.status.busy": "2025-05-01T02:26:20.685622Z",
     "iopub.status.idle": "2025-05-01T02:26:20.813526Z",
     "shell.execute_reply": "2025-05-01T02:26:20.812988Z",
     "shell.execute_reply.started": "2025-05-01T02:26:20.685886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"github_repos_wildcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:20.814917Z",
     "iopub.status.busy": "2025-05-01T02:26:20.814681Z",
     "iopub.status.idle": "2025-05-01T02:26:23.110443Z",
     "shell.execute_reply": "2025-05-01T02:26:23.109565Z",
     "shell.execute_reply.started": "2025-05-01T02:26:20.814899Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Cloning into 'panther'...\nremote: Enumerating objects: 773, done.\u001b[K\nremote: Counting objects: 100% (251/251), done.\u001b[K\nremote: Compressing objects: 100% (143/143), done.\u001b[K\nremote: Total 773 (delta 174), reused 172 (delta 108), pack-reused 522 (from 1)\u001b[K\nReceiving objects: 100% (773/773), 27.55 MiB | 19.07 MiB/s, done.\nResolving deltas: 100% (434/434), done.\n"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Check if the directory exists before removing\n",
    "if os.path.exists(\"panther\"):\n",
    "    shutil.rmtree(\"panther\")\n",
    "\n",
    "GITHUB_TOKEN = secret_value_0\n",
    "USER = \"gaserSami\"\n",
    "CLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/panther.git\"\n",
    "get_ipython().system(f\"git clone --branch torch_compile {CLONE_URL}\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"panther\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:23.111590Z",
     "iopub.status.busy": "2025-05-01T02:26:23.111363Z",
     "iopub.status.idle": "2025-05-01T02:26:26.300415Z",
     "shell.execute_reply": "2025-05-01T02:26:26.299498Z",
     "shell.execute_reply.started": "2025-05-01T02:26:23.111566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Looking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu118)\nRequirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (0.21.0+cu118)\nRequirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu118)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.8.86)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0) (11.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.21.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.21.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.21.0) (2024.2.0)\n"
    }
   ],
   "source": [
    "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:26.302994Z",
     "iopub.status.busy": "2025-05-01T02:26:26.302693Z",
     "iopub.status.idle": "2025-05-01T02:26:28.035942Z",
     "shell.execute_reply": "2025-05-01T02:26:28.034922Z",
     "shell.execute_reply.started": "2025-05-01T02:26:26.302971Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.6.0+cu118\n3.2.0\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "import triton\n",
    "\n",
    "print(triton.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:28.037320Z",
     "iopub.status.busy": "2025-05-01T02:26:28.036897Z",
     "iopub.status.idle": "2025-05-01T02:26:28.048322Z",
     "shell.execute_reply": "2025-05-01T02:26:28.047530Z",
     "shell.execute_reply.started": "2025-05-01T02:26:28.037292Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Overwriting /kaggle/working/panther/panther/nn/linear_kernels/forward.py\n"
    }
   ],
   "source": "%%writefile /kaggle/working/panther/panther/nn/linear_kernels/forward.py\nimport torch\nimport triton\nimport triton.language as tl\n\n# def getConfigs(names, ranges, num_stages_range, num_warps_range):\n#     configs = [\n#         triton.Config({f'{names[0]}': x0, f'{names[1]}': x1, f'{names[2]}': x2, f'{names[3]}': x3}, num_stages=s, num_warps=w) \\\n#         for x0 in ranges[0]\\\n#         for x1 in ranges[1]\\\n#         for x2 in ranges[2]\\\n#         for x3 in ranges[3]\\\n#         for s in num_stages_range\\\n#         for w in num_warps_range\\\n#     ]  \n#     return configs\n\n# ranges = [[32, 64, 128, 256, 512, 1024], [32, 64, 128, 256, 512, 1024], [32, 64, 128, 256, 512, 1024], [2,4,8]]\n# num_stages_range = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n# num_warps_range = [2, 4, 8, 16, 32]\n\n@triton.autotune(\n    configs=[\n    triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=1, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n],\n    # configs=getConfigs(['BLOCK_SIZE_BSIZE', 'BLOCK_SIZE_K', 'BLOCK_SIZE_D2', 'GROUP_SIZE_BSIZE'], ranges, num_stages_range, num_warps_range),\n    key=['BSIZE', 'K', 'd2', 'L'],\n)\n@triton.jit\ndef first_pass_kernel(\n        hin_ptr, S1s_ptr, U2s_ptr, out1_ptr, out2_ptr,\n        BSIZE, K, d2, L,\n        stride_hin_bsize, stride_hin_d2,\n        stride_su_l, stride_su_d2, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_D2: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_k = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_k\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n    pid_k = (pid % num_pid_in_group) // group_size_bsize\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_k = pid_k *  BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_d2 = tl.arange(0, BLOCK_SIZE_D2)\n\n    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_K), BLOCK_SIZE_K)\n    offs_d2 = tl.max_contiguous(tl.multiple_of(offs_d2, BLOCK_SIZE_D2), BLOCK_SIZE_D2)\n    \n    hin_ptrs = hin_ptr + (offs_bsize[:, None] * stride_hin_bsize + offs_d2[None, :] * stride_hin_d2)\n\n    su_tmp = batch_id * stride_su_l + (offs_d2[:, None] * stride_su_d2 + offs_k[None, :] * stride_su_k)\n    S1s_ptrs = S1s_ptr + su_tmp\n    U2s_ptrs = U2s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    accumulator2 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    \n    for d2_i in range(0, tl.cdiv(d2, BLOCK_SIZE_D2)):\n        hin_mask = (offs_bsize[:, None] < BSIZE) & (offs_d2[None, :] < d2 - d2_i * BLOCK_SIZE_D2)\n        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n        \n        su_mask = (offs_d2[:, None] < d2 - d2_i * BLOCK_SIZE_D2) & (offs_k[None, :] < K)\n        S1s = tl.load(S1s_ptrs, mask=su_mask, other=0.0)\n        U2s = tl.load(U2s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(hin, S1s, input_precision=\"ieee\")\n        accumulator2 += tl.dot(hin, U2s, input_precision=\"ieee\")\n        \n        hin_ptrs += BLOCK_SIZE_D2 * stride_hin_d2\n        S1s_ptrs += BLOCK_SIZE_D2 * stride_su_d2\n        U2s_ptrs += BLOCK_SIZE_D2 * stride_su_d2\n\n    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n    out1_ptrs = out1_ptr + out_tmp\n    out2_ptrs = out2_ptr + out_tmp\n    \n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_k[None, :] < K)\n    \n    tl.store(out1_ptrs, accumulator1, mask=out_mask)\n    tl.store(out2_ptrs, accumulator2, mask=out_mask)\n\ndef first_pass(hin, S1s, U2s):\n    device = 'cuda'\n    # assert hin.shape[1] == S1s.shape[1], \"Incompatible dimensions\"\n    # assert hin.shape[1] == U2s.shape[1], \"Incompatible dimensions\"\n    # assert hin.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert S1s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U2s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert S1s.stride() == U2s.stride(), \"Matrix A must be contiguous\"\n    \n    BSIZE, d2 = hin.shape\n    L, _, K = S1s.shape\n    \n    out1 = torch.empty((L, BSIZE, K), dtype=torch.float32, device=device)\n    out2 = torch.empty((L, BSIZE, K), dtype=torch.float32, device=device)\n\n    # stride_hin_bsize, stride_hin_d2 = hin.stride()\n    # stride_su_l, stride_su_d2, stride_su_k = S1s.stride()\n    # stride_out_l, stride_out_bsize, stride_out_k = out1.stride()\n    stride_hin_bsize, stride_hin_d2 = hin.shape[1] , 1\n    stride_su_l, stride_su_d2, stride_su_k = S1s.shape[1] * S1s.shape[2], S1s.shape[2], 1\n    stride_out_l, stride_out_bsize, stride_out_k = out1.shape[1] * out1.shape[2], out1.shape[2], 1\n    \n    # assert out1.stride() == out2.stride(), \"Matrix A must be contiguous\"\n    \n    grid = lambda META: (L, triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(K, META[\"BLOCK_SIZE_K\"]), )\n    \n    first_pass_kernel[grid](\n        hin, S1s, U2s, out1, out2,\n        BSIZE, K, d2, L,\n        stride_hin_bsize, stride_hin_d2,\n        stride_su_l, stride_su_d2, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n    )\n    \n    return out1, out2\n  \n@triton.autotune(\n    configs = [\n    triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=1, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n],\n    key=['BSIZE', 'd1', 'K', 'L'],\n)\n@triton.jit\ndef second_pass_kernel(\n        in1_ptr, in2_ptr, U1s_ptr, S2s_ptr, bias_ptr, out_ptr,\n        BSIZE, d1, K, L,\n        stride_in12_l, stride_in12_bsize, stride_in12_k,\n        stride_us_l, stride_us_k, stride_us_d1,\n        stride_bias_bsize, stride_bias_d1,\n        stride_out_bsize, stride_out_d1,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_D1: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_d1 = tl.cdiv(d1, BLOCK_SIZE_D1)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_d1\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    GROUP_SIZE_BSIZE = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % GROUP_SIZE_BSIZE)\n    pid_d1 = (pid % num_pid_in_group) // GROUP_SIZE_BSIZE\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_d1 = pid_d1 *  BLOCK_SIZE_D1 + tl.arange(0, BLOCK_SIZE_D1)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    offs_d1 = tl.max_contiguous(tl.multiple_of(offs_d1, BLOCK_SIZE_D1), BLOCK_SIZE_D1)\n    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_K), BLOCK_SIZE_K)\n\n    in_tmp = offs_bsize[:, None] * stride_in12_bsize + offs_k[None, :] * stride_in12_k\n    us_tmp = offs_k[:, None] * stride_us_k + offs_d1[None, :] * stride_us_d1\n\n    accumulator = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_D1), value=0.0, dtype=tl.float32)\n    \n    for l in range(0, L):\n        l_in_offset = l * stride_in12_l\n        l_us_offset = l * stride_us_l\n        \n        in1_ptrs = in1_ptr + l_in_offset + in_tmp\n        in2_ptrs = in2_ptr + l_in_offset + in_tmp\n    \n        U1s_ptrs = U1s_ptr + l_us_offset + us_tmp\n        S2s_ptrs = S2s_ptr + l_us_offset + us_tmp\n        \n        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n            in_mask = offs_k[None, :] < K - k * BLOCK_SIZE_K\n            in1 = tl.load(in1_ptrs, mask=in_mask, other=0.0)\n            in2 = tl.load(in2_ptrs, mask=in_mask, other=0.0)\n            \n            us_mask = offs_k[:, None] < K - k * BLOCK_SIZE_K\n            U1s = tl.load(U1s_ptrs, mask=us_mask, other=0.0)\n            S2s = tl.load(S2s_ptrs, mask=us_mask, other=0.0)\n            \n            accumulator += tl.dot(in1, U1s, input_precision=\"ieee\")\n            accumulator += tl.dot(in2, S2s, input_precision=\"ieee\")\n\n            in_inc = BLOCK_SIZE_K * stride_in12_k\n            in1_ptrs += in_inc\n            in2_ptrs += in_inc\n            \n            us_inc = BLOCK_SIZE_K * stride_us_k\n            U1s_ptrs += us_inc\n            S2s_ptrs += us_inc\n    \n    bias_ptrs = bias_ptr + offs_d1[None, :] * stride_bias_d1\n    bias_mask = (offs_d1[None, :] < d1)\n    bias = tl.load(bias_ptrs, mask=bias_mask, other=0.0)\n\n    accumulator *= (1.0/ (2.0 * L))\n    accumulator += bias\n\n    out_ptrs = out_ptr + stride_out_bsize * offs_bsize[:, None] + stride_out_d1 * offs_d1[None, :]\n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_d1[None, :] < d1)\n    \n    tl.store(out_ptrs, accumulator, mask=out_mask)\n\ndef second_pass(in1, in2, U1s, S2s, bias):\n    # assert in1.shape[2] == U1s.shape[1], \"Incompatible dimensions\"\n    # assert in2.shape[2] == S2s.shape[1], \"Incompatible dimensions\"\n    # assert in1.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert in2.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U1s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert S2s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert bias.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U1s.stride() == S2s.stride(), \"Matrix A must be contiguous\"\n    # assert in1.stride() == in2.stride(), \"Matrix A must be contiguous\"\n    \n    L, BSIZE, K = in1.shape\n    _, _, d1 = U1s.shape\n    \n    out = torch.empty((BSIZE, d1), dtype=torch.float32, device=device)\n\n    # stride_in12_l, stride_in12_bsize, stride_in12_k = in1.stride()\n    # stride_us_l, stride_us_k, stride_us_d1 = U1s.stride()\n    # stride_bias_bsize, stride_bias_d1 = bias.stride()\n    # stride_out_bsize, stride_out_d1 = out.stride()\n    stride_in12_l, stride_in12_bsize, stride_in12_k = in1.shape[1] * in1.shape[2], in1.shape[2], 1\n    stride_us_l, stride_us_k, stride_us_d1 = U1s.shape[1] * U1s.shape[2], U1s.shape[2], 1\n    stride_bias_bsize, stride_bias_d1 = bias.shape[1], 1\n    stride_out_bsize, stride_out_d1 = out.shape[1], 1\n    \n    grid = lambda META: (triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_D1\"]), )\n    \n    second_pass_kernel[grid](\n        in1, in2, U1s, S2s, bias, out,\n        BSIZE, d1, K, L,\n        stride_in12_l, stride_in12_bsize, stride_in12_k,\n        stride_us_l, stride_us_k, stride_us_d1,\n        stride_bias_bsize, stride_bias_d1,\n        stride_out_bsize, stride_out_d1,\n    )\n    \n    return out"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:28.049668Z",
     "iopub.status.busy": "2025-05-01T02:26:28.049304Z",
     "iopub.status.idle": "2025-05-01T02:26:28.079871Z",
     "shell.execute_reply": "2025-05-01T02:26:28.079367Z",
     "shell.execute_reply.started": "2025-05-01T02:26:28.049646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Overwriting /kaggle/working/panther/panther/nn/linear_kernels/backward.py\n"
    }
   ],
   "source": "%%writefile /kaggle/working/panther/panther/nn/linear_kernels/backward.py\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=1,\n                      num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n        #                num_warps=2),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n        #                num_warps=2),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n        #                num_warps=8),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n        #                num_warps=8),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['BSIZE', 'K', 'd1', 'L'],\n)\n@triton.jit\ndef first_pass_gU1s_g_S2s_kernel(\n        g_ptr, U1s_ptr, S2s_ptr, g_U1s_ptr, g_S2s_ptr,\n        BSIZE, K, d1, L,\n        stride_g_bsize, stride_g_d1,\n        stride_su_l, stride_su_d1, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_d1: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_k = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_k\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n    pid_k = (pid % num_pid_in_group) // group_size_bsize\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_k = pid_k *  BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_d1 = tl.arange(0, BLOCK_SIZE_d1)\n\n    g_ptrs = g_ptr + (offs_bsize[:, None] * stride_g_bsize + offs_d1[None, :] * stride_g_d1)\n\n    su_tmp = batch_id * stride_su_l + (offs_d1[:, None] * stride_su_d1 + offs_k[None, :] * stride_su_k)\n    U1s_ptrs = U1s_ptr + su_tmp\n    S2s_ptrs = S2s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    accumulator2 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    \n    \n    for d1_i in range(0, tl.cdiv(d1, BLOCK_SIZE_d1)):\n        g = tl.load(g_ptrs, mask=(offs_d1[None, :] < d1 - d1_i * BLOCK_SIZE_d1), other=0.0)\n        \n        su_mask = (offs_d1[:, None] < d1 - d1_i * BLOCK_SIZE_d1)\n        U1s = tl.load(U1s_ptrs, mask=su_mask, other=0.0)\n        S2s = tl.load(S2s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(g, U1s, input_precision=\"ieee\")\n        accumulator2 += tl.dot(g, S2s, input_precision=\"ieee\")\n        \n        g_ptrs += BLOCK_SIZE_d1 * stride_g_d1\n        U1s_ptrs += BLOCK_SIZE_d1 * stride_su_d1\n        S2s_ptrs += BLOCK_SIZE_d1 * stride_su_d1\n\n    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n    g_U1s_ptrs = g_U1s_ptr + out_tmp\n    g_S2s_ptrs = g_S2s_ptr + out_tmp\n    \n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_k[None, :] < K)\n    \n    tl.store(g_U1s_ptrs, accumulator1, mask=out_mask)\n    tl.store(g_S2s_ptrs, accumulator2, mask=out_mask)\n\ndef first_pass_gU1s_g_S2s(g, U1s, S2s):\n    # assert g.shape[1] == U1s.shape[1], \"Incompatible dimensions\"\n    # assert g.shape[1] == S2s.shape[1], \"Incompatible dimensions\"\n    # assert g.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U1s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert S2s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U1s.stride() == S2s.stride(), \"Matrix A must be contiguous\"\n    \n    BSIZE, d1 = g.shape\n    L, _, K = U1s.shape\n    \n    g_U1s = torch.empty((L, BSIZE, K), dtype=torch.float32, device='cuda')\n    g_S2s = torch.empty((L, BSIZE, K), dtype=torch.float32, device='cuda')\n\n    # stride_g_bsize, stride_g_d1 = g.stride()\n    # stride_su_l, stride_su_d1, stride_su_k = U1s.stride()\n    # stride_out_l, stride_out_bsize, stride_out_k = g_U1s.stride()\n    stride_g_bsize, stride_g_d1 = g.shape[1], 1\n    stride_su_l, stride_su_d1, stride_su_k = U1s.shape[1] * U1s.shape[2], U1s.shape[2], 1\n    stride_out_l, stride_out_bsize, stride_out_k = g_U1s.shape[1] * g_U1s.shape[2], g_U1s.shape[2], 1\n    \n    # assert g_U1s.stride() == g_S2s.stride(), \"Matrix A must be contiguous\"\n    \n    grid = lambda META: (L, triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(K, META[\"BLOCK_SIZE_K\"]), )\n    \n    first_pass_gU1s_g_S2s_kernel[grid](\n        g, U1s, S2s, g_U1s, g_S2s,\n        BSIZE, K, d1, L,\n        stride_g_bsize, stride_g_d1,\n        stride_su_l, stride_su_d1, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k\n    )\n    \n    return g_U1s, g_S2s\n  \n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=1,\n                      num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n        #                num_warps=2),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5,\n        #                num_warps=2),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n        #                num_warps=8),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3,\n        #                num_warps=8),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4),\n        #  triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4,\n        #                num_warps=4)\n    ],\n    key=['BSIZE', 'd2', 'K', 'L'],\n)\n@triton.jit\ndef second_pass_gUS11_22_kernel(\n        g_U1s_ptr, g_S2s_ptr, S1s_ptr, U2s_ptr, out_ptr,\n        BSIZE, d2, K, L,\n        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n        stride_us_l, stride_us_k, stride_us_d2,\n        stride_out_bsize, stride_out_d2,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_d2: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_d2 = tl.cdiv(d2, BLOCK_SIZE_d2)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_d2\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    GROUP_SIZE_BSIZE = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % GROUP_SIZE_BSIZE)\n    pid_d2 = (pid % num_pid_in_group) // GROUP_SIZE_BSIZE\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_d2 = pid_d2 *  BLOCK_SIZE_d2 + tl.arange(0, BLOCK_SIZE_d2)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    in_tmp = offs_bsize[:, None] * stride_g_U1s2_bsize + offs_k[None, :] * stride_g_U1s2_k\n    us_tmp = offs_k[:, None] * stride_us_k + offs_d2[None, :] * stride_us_d2\n\n    accumulator = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2), value=0.0, dtype=tl.float32)\n    \n    for l in range(0, L):\n        g_l_offset = l * stride_g_U1s2_l  # Offset for g_U1s and g_S2s\n        s_l_offset = l * stride_us_l      # Offset for S1s and U2s\n\n        g_U1s_ptrs = g_U1s_ptr + g_l_offset + in_tmp\n        g_S2s_ptrs = g_S2s_ptr + g_l_offset + in_tmp\n\n        S1s_ptrs = S1s_ptr + s_l_offset + us_tmp\n        U2s_ptrs = U2s_ptr + s_l_offset + us_tmp\n        \n        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n            in_mask = offs_k[None, :] < K - k * BLOCK_SIZE_K\n            g_U1s = tl.load(g_U1s_ptrs, mask=in_mask, other=0.0)\n            g_S2s = tl.load(g_S2s_ptrs, mask=in_mask, other=0.0)\n            \n            us_mask = offs_k[:, None] < K - k * BLOCK_SIZE_K\n            S1s = tl.load(S1s_ptrs, mask=us_mask, other=0.0)\n            U2s = tl.load(U2s_ptrs, mask=us_mask, other=0.0)\n            \n            accumulator += tl.dot(g_U1s, S1s, input_precision=\"ieee\")\n            accumulator += tl.dot(g_S2s, U2s, input_precision=\"ieee\")\n\n            in_inc = BLOCK_SIZE_K * stride_g_U1s2_k\n            g_U1s_ptrs += in_inc\n            g_S2s_ptrs += in_inc\n            \n            us_inc = BLOCK_SIZE_K * stride_us_k\n            S1s_ptrs += us_inc\n            U2s_ptrs += us_inc\n    \n    # accumulator *= (1.0/ (2.0 * L))\n\n    out_ptrs = out_ptr + stride_out_bsize * offs_bsize[:, None] + stride_out_d2 * offs_d2[None, :]\n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_d2[None, :] < d2)\n    \n    tl.store(out_ptrs, accumulator, mask=out_mask)\n\ndef second_pass_gUS11_22(g_U1s, g_S2s, S1s, U2s):\n    # assert g_U1s.shape[2] == S1s.shape[1], \"Incompatible dimensions\"\n    # assert g_S2s.shape[2] == U2s.shape[1], \"Incompatible dimensions\"\n    # assert g_U1s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert g_S2s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert S1s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U2s.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert S1s.stride() == U2s.stride(), \"Matrix A must be contiguous\"\n    # assert g_U1s.stride() == g_S2s.stride(), \"Matrix A must be contiguous\"\n    \n    L, BSIZE, K = g_U1s.shape\n    _, _, d2 = S1s.shape\n    \n    out = torch.empty((BSIZE, d2), dtype=torch.float32, device='cuda')\n\n    # stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k = g_U1s.stride()\n    # stride_us_l, stride_us_k, stride_us_d2 = S1s.stride()\n    # stride_out_bsize, stride_out_d2 = out.stride()\n    stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k = g_U1s.shape[1] * g_U1s.shape[2], g_U1s.shape[2], 1\n    stride_us_l, stride_us_k, stride_us_d2 = S1s.shape[1] * S1s.shape[2], S1s.shape[2], 1\n    stride_out_bsize, stride_out_d2 = out.shape[1], 1\n    \n    grid = lambda META: (triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]), )\n    \n    second_pass_gUS11_22_kernel[grid](\n        g_U1s, g_S2s, S1s, U2s, out,\n        BSIZE, d2, K, L,\n        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n        stride_us_l, stride_us_k, stride_us_d2,\n        stride_out_bsize, stride_out_d2,\n    )\n    \n    return out # grad\n  \n@triton.autotune(\n    configs=[\n    triton.Config({'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=1, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4)\n],\n    key=['d2', 'k', 'BSIZE', 'L'],\n)\n@triton.jit\ndef calc_grad_S1s_kernel(\n        hin_ptr, g_U1s_ptr, grad_g_S1s_ptr,\n        d2, k, BSIZE, L,\n        stride_hin_bsize, stride_hin_BSIZE,\n        stride_su_l, stride_su_BSIZE, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n        BLOCK_SIZE_d2: tl.constexpr, BLOCK_SIZE_k: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr,\n        GROUP_SIZE_d2: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(d2, BLOCK_SIZE_d2)\n    num_pid_k = tl.cdiv(k, BLOCK_SIZE_k)\n    num_pid_in_group = GROUP_SIZE_d2 * num_pid_k\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_d2\n    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_d2)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n    pid_k = (pid % num_pid_in_group) // group_size_bsize\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_d2 + tl.arange(0, BLOCK_SIZE_d2)\n    offs_k = pid_k *  BLOCK_SIZE_k + tl.arange(0, BLOCK_SIZE_k)\n    offs_BSIZE = tl.arange(0, BLOCK_SIZE_BSIZE)\n\n    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_d2), BLOCK_SIZE_d2)\n    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_k), BLOCK_SIZE_k)\n    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    \n    hin_ptrs = hin_ptr + (offs_bsize[:, None] * stride_hin_bsize + offs_BSIZE[None, :] * stride_hin_BSIZE)\n\n    su_tmp = batch_id * stride_su_l + (offs_BSIZE[:, None] * stride_su_BSIZE + offs_k[None, :] * stride_su_k)\n    g_U1s_ptrs = g_U1s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_d2, BLOCK_SIZE_k), value=0.0, dtype=tl.float32)\n    accumulator2 = tl.full(shape=(BLOCK_SIZE_d2, BLOCK_SIZE_k), value=0.0, dtype=tl.float32)\n    \n    for BSIZE_i in range(0, tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)):\n        hin_mask = (offs_bsize[:, None] < d2) & (offs_BSIZE[None, :] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE)\n        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n        \n        su_mask = (offs_BSIZE[:, None] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE) & (offs_k[None, :] < k)\n        g_U1s = tl.load(g_U1s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(hin, g_U1s, input_precision=\"ieee\")\n        \n        hin_ptrs += BLOCK_SIZE_BSIZE * stride_hin_BSIZE\n        g_U1s_ptrs += BLOCK_SIZE_BSIZE * stride_su_BSIZE\n\n    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n    grad_g_S1s_ptrs = grad_g_S1s_ptr + out_tmp\n    \n    out_mask = (offs_bsize[:, None] < d2) & (offs_k[None, :] < k)\n    \n    tl.store(grad_g_S1s_ptrs, accumulator1, mask=out_mask)\n\ndef calc_grad_S1s(hin, g_U1s):\n    device = 'cuda'\n    # assert hin.shape[1] == g_U1s.shape[1], \"Incompatible dimensions\"\n    # assert hin.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert g_U1s.is_contiguous(), \"Matrix A must be contiguous\"\n    \n    d2, BSIZE = hin.shape\n    L, _, k = g_U1s.shape\n    \n    grad_g_S1s = torch.empty((L, d2, k), dtype=torch.float32, device=device)\n\n    # stride_hin_bsize, stride_hin_BSIZE = hin.stride()\n    # stride_su_l, stride_su_BSIZE, stride_su_k = g_U1s.stride()\n    # stride_out_l, stride_out_bsize, stride_out_k = grad_g_S1s.stride()\n    stride_hin_bsize, stride_hin_BSIZE = hin.shape[1], 1\n    stride_su_l, stride_su_BSIZE, stride_su_k = g_U1s.shape[1] * g_U1s.shape[2], g_U1s.shape[2], 1\n    stride_out_l, stride_out_bsize, stride_out_k = grad_g_S1s.shape[1] * grad_g_S1s.shape[2], grad_g_S1s.shape[2], 1\n    \n    grid = lambda META: (L, triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]) * triton.cdiv(k, META[\"BLOCK_SIZE_k\"]), )\n    \n    calc_grad_S1s_kernel[grid](\n        hin, g_U1s, grad_g_S1s,\n        d2, k, BSIZE, L,\n        stride_hin_bsize, stride_hin_BSIZE,\n        stride_su_l, stride_su_BSIZE, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k\n    )\n    \n    return grad_g_S1s\n  \n@triton.autotune(\n    configs=[\n    triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=1, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4)\n],\n    key=['K', 'd2', 'BSIZE', 'L'],\n)\n@triton.jit\ndef first_pass_U2s_hin_kernel(\n        hin_ptr, U2s_ptr, U2s_h_in_ptr,\n        K, d2, BSIZE, L,\n        stride_hin_d2, stride_hin_BSIZE,\n        stride_su_l, stride_su_K, stride_su_d2,\n        stride_out_l, stride_out_K, stride_out_BSIZE,\n        BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_d2: tl.constexpr,\n        GROUP_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_K = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_BSIZE = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_in_group = GROUP_SIZE_K * num_pid_BSIZE\n    group_id = pid // num_pid_in_group\n    first_pid_K = group_id * GROUP_SIZE_K\n    group_size_BSIZE = min(num_pid_K - first_pid_K, GROUP_SIZE_K)\n    pid_K = first_pid_K + ((pid % num_pid_in_group) % group_size_BSIZE)\n    pid_BSIZE = (pid % num_pid_in_group) // group_size_BSIZE\n\n    offs_K = pid_K * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_BSIZE = pid_BSIZE *  BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_d2 = tl.arange(0, BLOCK_SIZE_d2)\n\n    offs_K = tl.max_contiguous(tl.multiple_of(offs_K, BLOCK_SIZE_K), BLOCK_SIZE_K)\n    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    offs_d2 = tl.max_contiguous(tl.multiple_of(offs_d2, BLOCK_SIZE_d2), BLOCK_SIZE_d2)\n    \n    hin_ptrs = hin_ptr + (offs_d2[:, None] * stride_hin_d2 + offs_BSIZE[None, :] * stride_hin_BSIZE)\n\n    su_tmp = batch_id * stride_su_l + (offs_K[:, None] * stride_su_K + offs_d2[None, :] * stride_su_d2)\n    U2s_ptrs = U2s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_K, BLOCK_SIZE_BSIZE), value=0.0, dtype=tl.float32)\n    \n    for d2_i in range(0, tl.cdiv(d2, BLOCK_SIZE_d2)):\n        hin_mask = (offs_d2[:, None] < d2 - d2_i * BLOCK_SIZE_d2) & (offs_BSIZE[None, :] < BSIZE)\n        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n        \n        su_mask = (offs_K[:, None] < K) & (offs_d2[None, :] < d2 - d2_i * BLOCK_SIZE_d2)\n        U2s = tl.load(U2s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(U2s, hin, input_precision=\"ieee\")\n        \n        hin_ptrs += BLOCK_SIZE_d2 * stride_hin_d2\n        U2s_ptrs += BLOCK_SIZE_d2 * stride_su_d2\n\n    out_tmp = batch_id * stride_out_l + stride_out_K * offs_K[:, None] + stride_out_BSIZE * offs_BSIZE[None, :]\n    U2s_h_in_ptrs = U2s_h_in_ptr + out_tmp\n    \n    out_mask = (offs_K[:, None] < K) & (offs_BSIZE[None, :] < BSIZE)\n    \n    tl.store(U2s_h_in_ptrs, accumulator1, mask=out_mask)\n\ndef first_pass_U2s_hin(U2s, hin):\n    device = 'cuda'\n    # assert U2s.shape[2] == hin.shape[0], \"Incompatible dimensions\"\n    # assert hin.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U2s.is_contiguous(), \"Matrix A must be contiguous\"\n    \n    L, K, d2 = U2s.shape\n    _, BSIZE = hin.shape\n    \n    U2s_h_in = torch.empty((L, K, BSIZE), dtype=torch.float32, device=device)\n\n    # stride_hin_d2, stride_hin_BSIZE = hin.stride()\n    # stride_su_l, stride_su_K, stride_su_d2 = U2s.stride()\n    # stride_out_l, stride_out_K, stride_out_BSIZE = U2s_h_in.stride()\n    stride_hin_d2, stride_hin_BSIZE = hin.shape[1], 1\n    stride_su_l, stride_su_K, stride_su_d2 = U2s.shape[1] * U2s.shape[2], U2s.shape[2], 1\n    stride_out_l, stride_out_K, stride_out_BSIZE = U2s_h_in.shape[1] * U2s_h_in.shape[2], U2s_h_in.shape[2], 1\n\n    BLOCK_SIZE_K, BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2 = 128, 256, 64\n    GROUP_SIZE_K = 8\n    \n    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]), )\n    \n    first_pass_U2s_hin_kernel[grid](\n        hin, U2s, U2s_h_in,\n        K, d2, BSIZE, L,\n        stride_hin_d2, stride_hin_BSIZE,\n        stride_su_l, stride_su_K, stride_su_d2,\n        stride_out_l, stride_out_K, stride_out_BSIZE\n    )\n    \n    return U2s_h_in\n  \n@triton.autotune(\n    configs=[\n    triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=1, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 256, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n    # triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n    # triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4)\n],\n    key=['K', 'BSIZE', 'd1', 'L'],\n)\n@triton.jit\ndef calc_grad_S2s_kernel(\n        g_ptr, U2s_hin_ptr, grad_S2s_ptr,\n        K, BSIZE, d1, L,\n        stride_g_BSIZE, stride_g_d1,\n        stride_su_l, stride_su_K, stride_su_BSIZE,\n        stride_out_l, stride_out_K, stride_out_d1,\n        BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_d1: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr,\n        GROUP_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_K = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_d1 = tl.cdiv(d1, BLOCK_SIZE_d1)\n    num_pid_in_group = GROUP_SIZE_K * num_pid_d1\n    group_id = pid // num_pid_in_group\n    first_pid_K = group_id * GROUP_SIZE_K\n    group_size_d1 = min(num_pid_K - first_pid_K, GROUP_SIZE_K)\n    pid_K = first_pid_K + ((pid % num_pid_in_group) % group_size_d1)\n    pid_d1 = (pid % num_pid_in_group) // group_size_d1\n\n    offs_K = pid_K * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_d1 = pid_d1 *  BLOCK_SIZE_d1 + tl.arange(0, BLOCK_SIZE_d1)\n    offs_BSIZE = tl.arange(0, BLOCK_SIZE_BSIZE)\n\n    offs_K = tl.max_contiguous(tl.multiple_of(offs_K, BLOCK_SIZE_K), BLOCK_SIZE_K)\n    offs_d1 = tl.max_contiguous(tl.multiple_of(offs_d1, BLOCK_SIZE_d1), BLOCK_SIZE_d1)\n    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    \n    g_ptrs = g_ptr + (offs_BSIZE[:, None] * stride_g_BSIZE + offs_d1[None, :] * stride_g_d1)\n\n    su_tmp = batch_id * stride_su_l + (offs_K[:, None] * stride_su_K + offs_BSIZE[None, :] * stride_su_BSIZE)\n    U2s_hin_ptrs = U2s_hin_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_K, BLOCK_SIZE_d1), value=0.0, dtype=tl.float32)\n    \n    for BSIZE_i in range(0, tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)):\n        g_mask = (offs_BSIZE[:, None] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE) & (offs_d1[None, :] < d1)\n        g = tl.load(g_ptrs, mask=g_mask, other=0.0)\n        \n        su_mask = (offs_K[:, None] < K) & (offs_BSIZE[None, :] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE)\n        U2s_hin = tl.load(U2s_hin_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(U2s_hin, g, input_precision=\"ieee\")\n        \n        g_ptrs += BLOCK_SIZE_BSIZE * stride_g_BSIZE\n        U2s_hin_ptrs += BLOCK_SIZE_BSIZE * stride_su_BSIZE\n\n    out_tmp = batch_id * stride_out_l + stride_out_K * offs_K[:, None] + stride_out_d1 * offs_d1[None, :]\n    grad_S2s_ptrs = grad_S2s_ptr + out_tmp\n    \n    out_mask = (offs_K[:, None] < K) & (offs_d1[None, :] < d1)\n    \n    tl.store(grad_S2s_ptrs, accumulator1, mask=out_mask)\n\ndef calc_grad_S2s(U2s_hin, g):\n    device = 'cuda'\n    # assert U2s_hin.shape[2] == g.shape[0], \"Incompatible dimensions\"\n    # assert g.is_contiguous(), \"Matrix A must be contiguous\"\n    # assert U2s_hin.is_contiguous(), \"Matrix A must be contiguous\"\n    \n    L, K, BSIZE = U2s_hin.shape\n    _, d1 = g.shape\n    \n    grad_S2s = torch.empty((L, K, d1), dtype=torch.float32, device=device)\n\n    # stride_g_BSIZE, stride_g_d1 = g.stride()\n    # stride_su_l, stride_su_K, stride_su_BSIZE = U2s_hin.stride()\n    # stride_out_l, stride_out_K, stride_out_d1 = grad_S2s.stride()\n    stride_g_BSIZE, stride_g_d1 = g.shape[1], 1\n    stride_su_l, stride_su_K, stride_su_BSIZE = U2s_hin.shape[1] * U2s_hin.shape[2], U2s_hin.shape[2], 1\n    stride_out_l, stride_out_K, stride_out_d1 = grad_S2s.shape[1] * grad_S2s.shape[2], grad_S2s.shape[2], 1\n\n    BLOCK_SIZE_K, BLOCK_SIZE_d1, BLOCK_SIZE_BSIZE = 128, 256, 64\n    GROUP_SIZE_K = 8\n    \n    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_d1\"]), )\n    \n    calc_grad_S2s_kernel[grid](\n        g, U2s_hin, grad_S2s,\n        K, BSIZE, d1, L,\n        stride_g_BSIZE, stride_g_d1,\n        stride_su_l, stride_su_K, stride_su_BSIZE,\n        stride_out_l, stride_out_K, stride_out_d1\n    )\n    \n    return grad_S2s"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:28.080888Z",
     "iopub.status.busy": "2025-05-01T02:26:28.080662Z",
     "iopub.status.idle": "2025-05-01T02:26:28.108742Z",
     "shell.execute_reply": "2025-05-01T02:26:28.108009Z",
     "shell.execute_reply.started": "2025-05-01T02:26:28.080871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Overwriting /kaggle/working/panther/panther/nn/linear_tr.py\n"
    }
   ],
   "source": "%%writefile /kaggle/working/panther/panther/nn/linear_tr.py\nimport math\nfrom typing import Any, Tuple, List, Optional\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Function\nfrom torch.nn import init\nimport triton\nfrom panther.random import scaled_sign_sketch as gen_U\nfrom torch.library import triton_op, wrap_triton\nfrom .linear_kernels import (\n    first_pass_kernel,\n    second_pass_kernel,\n    first_pass_gU1s_g_S2s_kernel,\n    second_pass_gUS11_22_kernel,\n    calc_grad_S1s_kernel,\n    first_pass_U2s_hin_kernel,\n    calc_grad_S2s_kernel\n)\n\n@triton_op(\"panther::forward_op\", mutates_args={})\ndef forward_op(hin: torch.Tensor, S1s: torch.Tensor, S2s: torch.Tensor, U1s: torch.Tensor, U2s: torch.Tensor, bias: torch.Tensor) -> torch.Tensor:\n    device = 'cuda'\n    \n    # first pass\n    ############\n    L = S2s.shape[0]\n    BSIZE, d2 = hin.shape\n    L, _, K = S1s.shape\n    \n    in1 = torch.empty((L, BSIZE, K), dtype=torch.float32, device=device)\n    in2 = torch.empty((L, BSIZE, K), dtype=torch.float32, device=device)\n    \n    stride_hin_bsize, stride_hin_d2 = hin.stride(0), hin.stride(1)\n    stride_su_l, stride_su_d2, stride_su_k = S1s.stride(0), S1s.stride(1), S1s.stride(2)\n    stride_out_l, stride_out_bsize, stride_out_k = in1.stride(0), in1.stride(1), in1.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(K, META[\"BLOCK_SIZE_K\"]), )\n    \n    wrap_triton(first_pass_kernel)[grid](\n        hin, S1s, U2s, in1, in2,\n        BSIZE, K, d2, L,\n        stride_hin_bsize, stride_hin_d2,\n        stride_su_l, stride_su_d2, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n    )\n\n    # torch equivlant\n    # num_terms = S2s.shape[0]\n    # input_torch = hin.unsqueeze(0).expand(num_terms, hin.shape[0], hin.shape[1])\n    # in1_torch = input_torch.bmm(S1s)\n    # in2_torch = input_torch.bmm(U2s)\n\n    # compare using torch allclose\n    # outputs_match = torch.allclose(in1_torch, in1)\n    # print(f\"forward in1 and in1_torch Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(in1_torch - in1))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"out_triton: {in1_torch}\")\n    #     print(f\"out_normal: {in1}\")\n\n    # outputs_match = torch.allclose(in2_torch, in2)\n    # print(f\"forward in2 and in2_torch Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(in2_torch - in2))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"out_triton: {in2_torch}\")\n    #     print(f\"out_normal: {in2}\")\n    \n    # second pass\n    #############\n    bias_unsqueezed = bias.unsqueeze(0)\n    L, BSIZE, K = in1.shape\n    _, _, d1 = U1s.shape\n    \n    out = torch.empty((BSIZE, d1), dtype=torch.float32, device=device)\n\n    stride_in12_l, stride_in12_bsize, stride_in12_k = in1.stride(0), in1.stride(1), in1.stride(2)\n    stride_us_l, stride_us_k, stride_us_d1 = U1s.stride(0), U1s.stride(1), U1s.stride(2)\n    stride_bias_bsize, stride_bias_d1 = bias_unsqueezed.stride(0), bias_unsqueezed.stride(1)\n    stride_out_bsize, stride_out_d1 = out.stride(0), out.stride(1)\n    \n    grid = lambda META: (triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_D1\"]), )\n    \n    wrap_triton(second_pass_kernel)[grid](\n        in1, in2, U1s, S2s, bias_unsqueezed, out,\n        BSIZE, d1, K, L,\n        stride_in12_l, stride_in12_bsize, stride_in12_k,\n        stride_us_l, stride_us_k, stride_us_d1,\n        stride_bias_bsize, stride_bias_d1,\n        stride_out_bsize, stride_out_d1,\n    )\n\n    # torch_out = (\n    #                 ((input_torch.bmm(S1s)).bmm(U1s)).mean(0) / 2\n    #                 + ((input_torch.bmm(U2s)).bmm(S2s)).mean(0) / 2\n    #                 + bias\n    #         )\n    # compare using torch allclose\n    # outputs_match = torch.allclose(torch_out, out)\n    # print(f\"forward out and torch_out Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(torch_out - out))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"torch_out: {torch_out}\")\n    #     print(f\"out: {out}\")\n    \n    return out\n\n@forward_op.register_kernel(\"cpu\")\ndef _(input, S1s, S2s, U1s, U2s, bias):\n    num_terms = S2s.shape[0]\n    # Efficiently perform the sum over all l terms\n    input = input.unsqueeze(0).expand(num_terms, input.shape[0], input.shape[1])\n    return (\n        ((input.bmm(S1s)).bmm(U1s)).mean(0) / 2\n        + ((input.bmm(U2s)).bmm(S2s)).mean(0) / 2\n        + bias\n    )\n    \n@triton_op(\"panther::backward_op\", mutates_args={})\ndef backward_op(hin: torch.Tensor, S1s: torch.Tensor, S2s: torch.Tensor, U1s: torch.Tensor, U2s: torch.Tensor, g: torch.Tensor) -> List[torch.Tensor]:\n    device = 'cuda'\n    num_terms = S2s.shape[0]\n        \n    hin = hin.transpose(0, 1)\n    U1s = U1s.transpose(1, 2)\n    S1s = S1s.transpose(1, 2)\n    U2s = U2s.transpose(1, 2)\n    S2s = S2s.transpose(1, 2)\n\n    g = g / (2 * num_terms)\n    \n    # first_pass_gU1s_g_S2s\n    #######################\n    BSIZE, d1 = g.shape\n    L, _, K = U1s.shape\n    \n    g_U1s = torch.empty((L, BSIZE, K), dtype=torch.float32, device='cuda')\n    g_S2s = torch.empty((L, BSIZE, K), dtype=torch.float32, device='cuda')\n\n    stride_g_bsize, stride_g_d1 = g.stride(0), g.stride(1)\n    stride_su_l, stride_su_d1, stride_su_k = U1s.stride(0), U1s.stride(1), U1s.stride(2)\n    stride_out_l, stride_out_bsize, stride_out_k = g_U1s.stride(0), g_U1s.stride(1), g_U1s.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(K, META[\"BLOCK_SIZE_K\"]), )\n    \n    wrap_triton(first_pass_gU1s_g_S2s_kernel)[grid](\n        g, U1s, S2s, g_U1s, g_S2s,\n        BSIZE, K, d1, L,\n        stride_g_bsize, stride_g_d1,\n        stride_su_l, stride_su_d1, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k\n    )\n\n    num_terms = S2s.shape[0]\n    # g_torch_unsqueezed = g.unsqueeze(0).expand(num_terms, g.shape[0], g.shape[1])\n    # g_U1s_torch = g_torch_unsqueezed.bmm(U1s)\n    # g_S2s_torch = g_torch_unsqueezed.bmm(S2s)\n\n    # check if the outputs match\n    # outputs_match = torch.allclose(g_U1s_torch, g_U1s)\n    # print(f\"backward g_U1s and g_U1s_torch Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(g_U1s_torch - g_U1s))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"g_U1s_torch: {g_U1s_torch}\")\n    #     print(f\"g_U1s: {g_U1s}\")\n\n    # outputs_match = torch.allclose(g_S2s_torch, g_S2s)\n    # print(f\"backward g_S2s and g_S2s_torch Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(g_S2s_torch - g_S2s))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"g_S2s_torch: {g_S2s_torch}\")\n    #     print(f\"g_S2s: {g_S2s}\")\n\n    # second_pass_gUS11_22\n    #######################\n    L, BSIZE, K = g_U1s.shape\n    _, _, d2 = S1s.shape\n    \n    grad = torch.empty((BSIZE, d2), dtype=torch.float32, device='cuda')\n\n    stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k = g_U1s.stride(0), g_U1s.stride(1), g_U1s.stride(2)\n    stride_us_l, stride_us_k, stride_us_d2 = S1s.stride(0), S1s.stride(1), S1s.stride(2)\n    stride_out_bsize, stride_out_d2 = grad.stride(0), grad.stride(1)\n    \n    grid = lambda META: (triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]), )\n    \n    wrap_triton(second_pass_gUS11_22_kernel)[grid](\n        g_U1s, g_S2s, S1s, U2s, grad,\n        BSIZE, d2, K, L,\n        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n        stride_us_l, stride_us_k, stride_us_d2,\n        stride_out_bsize, stride_out_d2,\n    )\n\n    # grad_torch = (g_torch_unsqueezed.bmm(U1s).bmm(S1s).sum(0) + g_torch_unsqueezed.bmm(S2s).bmm(U2s).sum(0)) / (2 * num_terms)\n    \n    # outputs_match = torch.allclose(grad_torch, grad)\n    # print(f\"backward grad and grad_torch Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(grad_torch - grad))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"grad_torch: {grad_torch}\")\n    #     print(f\"grad: {grad}\")\n        \n    # calc_grad_S1s\n    ################\n    d2, BSIZE = hin.shape\n    L, _, k = g_U1s.shape\n    \n    grad_S1s = torch.empty((L, d2, k), dtype=torch.float32, device=device)\n\n    stride_hin_bsize, stride_hin_BSIZE = hin.stride(0), hin.stride(1)\n    stride_su_l, stride_su_BSIZE, stride_su_k = g_U1s.stride(0), g_U1s.stride(1), g_U1s.stride(2)\n    stride_out_l, stride_out_bsize, stride_out_k = grad_S1s.stride(0), grad_S1s.stride(1), grad_S1s.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]) * triton.cdiv(k, META[\"BLOCK_SIZE_k\"]), )\n    \n    wrap_triton(calc_grad_S1s_kernel)[grid](\n        hin, g_U1s, grad_S1s,\n        d2, k, BSIZE, L,\n        stride_hin_bsize, stride_hin_BSIZE,\n        stride_su_l, stride_su_BSIZE, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k\n    )\n\n    # input_torch = (\n    #         hin.unsqueeze(0)\n    #         .expand(num_terms, hin.shape[0], hin.shape[1])\n    #     )\n    # grad_S1s_torch = input_torch.bmm(g_torch_unsqueezed.bmm(U1s))\n\n    # # check if the outputs match\n    # outputs_match = torch.allclose(grad_S1s_torch, grad_S1s)\n    # print(f\"backward grad_S1s and grad_S1s_torch Outputs match: {outputs_match}\")\n    \n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(grad_S1s_torch - grad_S1s))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"grad_S1s_torch: {grad_S1s_torch}\")\n    #     print(f\"grad_S1s: {grad_S1s}\")\n    \n    # first_pass_U2s_hin\n    ####################\n    L, K, d2 = U2s.shape\n    _, BSIZE = hin.shape\n    \n    U2s_hin = torch.empty((L, K, BSIZE), dtype=torch.float32, device=device)\n\n    stride_hin_d2, stride_hin_BSIZE = hin.stride(0), hin.stride(1)\n    stride_su_l, stride_su_K, stride_su_d2 = U2s.stride(0), U2s.stride(1), U2s.stride(2)\n    stride_out_l, stride_out_K, stride_out_BSIZE = U2s_hin.stride(0), U2s_hin.stride(1), U2s_hin.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]), )\n    \n    wrap_triton(first_pass_U2s_hin_kernel)[grid](\n        hin, U2s, U2s_hin,\n        K, d2, BSIZE, L,\n        stride_hin_d2, stride_hin_BSIZE,\n        stride_su_l, stride_su_K, stride_su_d2,\n        stride_out_l, stride_out_K, stride_out_BSIZE\n    )\n\n    # U2s_hin_torch = (U2s.bmm(input_torch))\n\n    # check if the outputs match\n    # outputs_match = torch.allclose(U2s_hin_torch, U2s_hin)\n    # print(f\"backward U2s_hin and U2s_hin_torch Outputs match: {outputs_match}\")\n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(U2s_hin_torch - U2s_hin))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"U2s_hin_torch: {U2s_hin_torch}\")\n    #     print(f\"U2s_hin: {U2s_hin}\")\n    \n    # calc_grad_S2s\n    ###############\n    L, K, BSIZE = U2s_hin.shape\n    _, d1 = g.shape\n    \n    grad_S2s = torch.empty((L, K, d1), dtype=torch.float32, device=device)\n\n    stride_g_BSIZE, stride_g_d1 = g.stride(0), g.stride(1)\n    stride_su_l, stride_su_K, stride_su_BSIZE = U2s_hin.stride(0), U2s_hin.stride(1), U2s_hin.stride(2)\n    stride_out_l, stride_out_K, stride_out_d1 = grad_S2s.stride(0), grad_S2s.stride(1), grad_S2s.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_d1\"]), )\n    \n    wrap_triton(calc_grad_S2s_kernel)[grid](\n        g, U2s_hin, grad_S2s,\n        K, BSIZE, d1, L,\n        stride_g_BSIZE, stride_g_d1,\n        stride_su_l, stride_su_K, stride_su_BSIZE,\n        stride_out_l, stride_out_K, stride_out_d1\n    )\n\n    # grad_S2s_torch = (U2s.bmm(input_torch)).bmm(g_torch_unsqueezed)\n\n    # outputs_match = torch.allclose(grad_S2s_torch, grad_S2s)\n    # print(f\"backward grad_S2s and grad_S2s_torch Outputs match: {outputs_match}\")\n    \n    # if not outputs_match:\n    #     max_diff = torch.max(torch.abs(grad_S2s_torch - grad_S2s))\n    #     print(f\"Max difference: {max_diff.item()}\")\n    #     print(f\"grad_S2s_torch: {grad_S2s_torch}\")\n    #     print(f\"grad_S2s: {grad_S2s}\")\n\n    return [\n        grad,\n        grad_S1s,\n        grad_S2s,\n        g.sum(0)\n    ]\n    \n@backward_op.register_kernel(\"cpu\")\ndef _(input, S1s, S2s, U1s, U2s, grad_output):\n    num_terms = S2s.shape[0]\n    g = grad_output / (2 * num_terms)\n    g = g.unsqueeze(0).expand(num_terms, g.shape[0], g.shape[1])\n    input = (\n        input.unsqueeze(0)\n        .expand(num_terms, input.shape[0], input.shape[1])\n        .transpose(1, 2)\n    )\n    U1s = U1s.transpose(1, 2)\n    S1s = S1s.transpose(1, 2)\n    U2s = U2s.transpose(1, 2)\n    S2s = S2s.transpose(1, 2)\n    t1 = g.bmm(U1s)\n    grad = t1.bmm(S1s).sum(0) + g.bmm(S2s).bmm(U2s).sum(0)\n    grad_S2s = (U2s.bmm(input)).bmm(g)\n    grad_S1s = input.bmm(g.bmm(U1s))\n\n    g = g[0]\n    return [\n        grad,\n        grad_S1s,\n        grad_S2s,\n        # sum g on batch dimension input.shape[0]\n        g.reshape(input.shape[2], -1).sum(0)\n    ]\n    \nclass SketchedLinearFunction_triton(Function):\n    # Note that forward, setup_context, and backward are @staticmethods\n    @staticmethod\n    def forward(\n        input: torch.Tensor,\n        S1s: torch.Tensor,\n        S2s: torch.Tensor,\n        U1s: torch.Tensor,\n        U2s: torch.Tensor,\n        bias: torch.Tensor,\n    ): \n        return forward_op(input, S1s, S2s, U1s, U2s, bias)\n\n    @staticmethod\n    # inputs is a Tuple of all of the inputs passed to forward.\n    # output is the output of the forward().\n    def setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any):\n        input, S1s, S2s, U1s, U2s, bias = inputs\n        ctx.save_for_backward(input, S1s, S2s, U1s, U2s, bias)\n\n    @staticmethod\n    def backward(ctx: Any, *grad_output: Any) -> Any:\n        # dl/dS2_i = U1_i g h_in^T / 2 * l\n        # dl/dS1_i = g h_in^T U2_i^T / 2 * l\n        # dl/dh_in = 1/(2*l) * (sum_{i=1}^{l} (S1_i^T U1_i g) + sum_{i=1}^{l} (U2_i^T S2_i g))\n        # dl/db = g\n        hin, S1s, S2s, U1s, U2s, _ = ctx.saved_tensors\n        grad_input, grad_S1s, grad_S2s, grad_bias = backward_op(hin, S1s, S2s, U1s, U2s, grad_output[0])\n        return grad_input, grad_S1s, grad_S2s, None, None, grad_bias\n        \n\n\nclass SKLinear_triton(nn.Module):\n    __constants__ = [\"in_features\", \"out_features\", \"num_terms\", \"low_rank\"]\n    in_features: int\n    out_features: int\n    num_terms: int\n    low_rank: int\n    S1s: torch.Tensor\n    S2s: torch.Tensor\n    U1s: torch.Tensor\n    U2s: torch.Tensor\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        num_terms: int,\n        low_rank: int,\n        W_init=None,\n        bias: bool = True,\n        dtype=None,\n        device=None,\n    ):\n        factory_kwargs = {\"dtype\": dtype, \"device\": device}\n        super(SKLinear_triton, self).__init__()\n\n        # if (\n        #     2 * num_terms * low_rank * (out_features + in_features)\n        #     > out_features * in_features\n        # ):\n        #     raise ValueError(\n        #         \"The number of parameters in the sketching layer is larger \"\n        #         + \"than the number of parameters in the fully connected layer.\"\n        #     )\n\n        self.num_terms = num_terms # l\n        self.low_rank = low_rank # k\n        self.out_features = out_features\n        self.in_features = in_features\n\n        # Register U1s and U2s as buffers since they are not learnable\n        self.register_buffer(\n            \"U1s\",\n            torch.stack(\n                [\n                    gen_U(low_rank, out_features, **factory_kwargs)\n                    for _ in range(num_terms)\n                ]\n            ),\n        )  # k(low rank)xd1(out) stacked along the zeros dimension (l) -> l x k x d1\n        self.register_buffer(\n            \"U2s\",\n            torch.stack(\n                [\n                    gen_U(in_features, low_rank, **factory_kwargs)\n                    for _ in range(num_terms)\n                ]\n            ),\n        )  # d2xk stacked along the zeros dimension (l) -> l x d2 x k\n\n        # W is used to only initialize S\n        if W_init is None:\n            W = torch.empty(in_features, out_features, **factory_kwargs) # d2 * d1\n            init.kaiming_uniform_(W, a=math.sqrt(5))\n        else:\n            W = W_init.T.detach().clone()\n\n        # S1s and S2s are precomputed but not updated in the backward pass\n        self.S1s = nn.Parameter(\n            torch.stack([torch.matmul(W, self.U1s[i].T) for i in range(num_terms)])\n        )  # d2xk stacked along the zeros dimension (l) -> l x d2 x k\n        self.S2s = nn.Parameter(\n            torch.stack([torch.matmul(self.U2s[i].T, W) for i in range(num_terms)])\n        )  # kxd1 stacked along the zeros dimension (l) -> l x k x d1\n\n        # Bias term initialized with a small standard deviation\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs)) #1 * d1\n            fan_in, _ = init._calculate_fan_in_and_fan_out(W)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n        else:\n            self.register_parameter(\"bias\", None)\n\n    def forward(self, h_in):\n        # TODO: Make sure all the things are contiguos\n        return SketchedLinearFunction_triton.apply(\n            h_in, self.S1s, self.S2s, self.U1s, self.U2s, self.bias\n        )"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:28.109700Z",
     "iopub.status.busy": "2025-05-01T02:26:28.109484Z",
     "iopub.status.idle": "2025-05-01T02:26:28.663117Z",
     "shell.execute_reply": "2025-05-01T02:26:28.662425Z",
     "shell.execute_reply.started": "2025-05-01T02:26:28.109675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n"
    }
   ],
   "source": [
    "!export LC_ALL=\"en_US.UTF-8\"\n",
    "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "!ldconfig /usr/lib64-nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# checking "
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:31:58.458372Z",
     "iopub.status.busy": "2025-05-01T02:31:58.457672Z",
     "iopub.status.idle": "2025-05-01T02:31:58.499886Z",
     "shell.execute_reply": "2025-05-01T02:31:58.499168Z",
     "shell.execute_reply.started": "2025-05-01T02:31:58.458346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Comparing SKLinear and SKLinear_triton implementations...\nForward outputs match: True\nInput gradients match: True\nS1s gradients match: True\nS2s gradients match: True\nU1s gradients not available - skipping comparison\nU2s gradients not available - skipping comparison\nBias gradients match: True\nAll checks passed: True\nForward outputs match: True\nInput gradients match: True\nS1s gradients match: True\nS2s gradients match: True\nU1s gradients not available - skipping comparison\nU2s gradients not available - skipping comparison\nBias gradients match: True\nSmall model checks passed: True\nForward outputs match: True\nInput gradients match: True\nS1s gradients match: True\nS2s gradients match: True\nU1s gradients not available - skipping comparison\nU2s gradients not available - skipping comparison\nBias gradients match: True\nLarge model checks passed: True\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from panther.nn.linear import SKLinear\n",
    "from panther.nn.linear_tr import SKLinear_triton\n",
    "\n",
    "\n",
    "def compare_linear_implementations(\n",
    "    batch_size=64,\n",
    "    in_features=128,\n",
    "    out_features=64,\n",
    "    num_terms=4,\n",
    "    low_rank=8,\n",
    "    raise_error=True,\n",
    "):\n",
    "    """\n",
    "    Compare the outputs of the forward pass and gradients between regular SKLinear and Triton-accelerated SKLinear_triton.\n",
    "\n",
    "    Args:\n",
    "        batch_size: Batch size for the input tensor\n",
    "        in_features: Number of input features\n",
    "        out_features: Number of output features\n",
    "        num_terms: Number of terms (l) in the sketched linear layer\n",
    "        low_rank: The low-rank dimension (k) in the sketched linear layer\n",
    "        raise_error: If True, raise AssertionError when comparisons fail\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all comparisons pass, False otherwise\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any comparison fails and raise_error is True\n",
    "    """\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Create identical layers\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Generate the same initialization for both layers\n",
    "    W_init = torch.randn(out_features, in_features, device=device)\n",
    "\n",
    "    # Create both layer implementations with identical parameters\n",
    "    sk_linear = SKLinear(\n",
    "        in_features, out_features, num_terms, low_rank, W_init=W_init, device=device\n",
    "    )\n",
    "    sk_linear_triton = SKLinear_triton(\n",
    "        in_features, out_features, num_terms, low_rank, W_init=W_init, device=device\n",
    "    )\n",
    "\n",
    "    # Ensure parameters match exactly by copying from sk_linear to sk_linear_triton\n",
    "    with torch.no_grad():\n",
    "        sk_linear_triton.S1s.copy_(sk_linear.S1s)\n",
    "        sk_linear_triton.S2s.copy_(sk_linear.S2s)\n",
    "        sk_linear_triton.U1s.copy_(sk_linear.U1s)\n",
    "        sk_linear_triton.U2s.copy_(sk_linear.U2s)\n",
    "        sk_linear_triton.bias.copy_(sk_linear.bias)\n",
    "\n",
    "    # Create identical input\n",
    "    input_data = torch.randn(batch_size, in_features, device=device, requires_grad=True)\n",
    "    input_data_triton = input_data.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Forward pass\n",
    "    output = sk_linear(input_data)\n",
    "    output_triton = sk_linear_triton(input_data_triton)\n",
    "\n",
    "    # Check if forward outputs match\n",
    "    forward_match = torch.allclose(output, output_triton, rtol=1e-4, atol=1e-5)\n",
    "    print(f\"Forward outputs match: {forward_match}\")\n",
    "    if not forward_match:\n",
    "        max_diff = torch.max(torch.abs(output - output_triton))\n",
    "        error_msg = f\"Forward outputs don't match. Max difference: {max_diff.item()}\"\n",
    "        print(error_msg)\n",
    "        if raise_error:\n",
    "            assert forward_match, error_msg\n",
    "\n",
    "    # Create identical gradients\n",
    "    grad_output = torch.randn_like(output)\n",
    "    grad_output_triton = grad_output.clone()\n",
    "\n",
    "    # Backward pass\n",
    "    output.backward(grad_output)\n",
    "    output_triton.backward(grad_output_triton)\n",
    "\n",
    "    # Check if input gradients match\n",
    "    input_grad_match = torch.allclose(\n",
    "        input_data.grad, input_data_triton.grad, rtol=1e-4, atol=1e-5\n",
    "    )\n",
    "    print(f\"Input gradients match: {input_grad_match}\")\n",
    "    if not input_grad_match:\n",
    "        max_diff = torch.max(torch.abs(input_data.grad - input_data_triton.grad))\n",
    "        error_msg = f\"Input gradients don't match. Max difference: {max_diff.item()}\"\n",
    "        print(error_msg)\n",
    "        if raise_error:\n",
    "            assert input_grad_match, error_msg\n",
    "\n",
    "    # Check if S1s gradients match\n",
    "    S1s_grad_match = torch.allclose(\n",
    "        sk_linear.S1s.grad, sk_linear_triton.S1s.grad, rtol=1e-4, atol=1e-5\n",
    "    )\n",
    "    print(f\"S1s gradients match: {S1s_grad_match}\")\n",
    "    if not S1s_grad_match:\n",
    "        max_diff = torch.max(torch.abs(sk_linear.S1s.grad - sk_linear_triton.S1s.grad))\n",
    "        error_msg = f\"S1s gradients don't match. Max difference: {max_diff.item()}\"\n",
    "        print(error_msg)\n",
    "        if raise_error:\n",
    "            assert S1s_grad_match, error_msg\n",
    "\n",
    "    # Check if S2s gradients match\n",
    "    S2s_grad_match = torch.allclose(\n",
    "        sk_linear.S2s.grad, sk_linear_triton.S2s.grad, rtol=1e-4, atol=1e-5\n",
    "    )\n",
    "    print(f\"S2s gradients match: {S2s_grad_match}\")\n",
    "    if not S2s_grad_match:\n",
    "        max_diff = torch.max(torch.abs(sk_linear.S2s.grad - sk_linear_triton.S2s.grad))\n",
    "        error_msg = f\"S2s gradients don't match. Max difference: {max_diff.item()}\"\n",
    "        print(error_msg)\n",
    "        if raise_error:\n",
    "            assert S2s_grad_match, error_msg\n",
    "\n",
    "    # U1s and U2s are buffers, not parameters, so they may not have gradients\n",
    "    # Only check if both gradients exist\n",
    "    if (\n",
    "        hasattr(sk_linear.U1s, \"grad\")\n",
    "        and hasattr(sk_linear_triton.U1s, \"grad\")\n",
    "        and sk_linear.U1s.grad is not None\n",
    "        and sk_linear_triton.U1s.grad is not None\n",
    "    ):\n",
    "        U1s_grad_match = torch.allclose(\n",
    "            sk_linear.U1s.grad, sk_linear_triton.U1s.grad, rtol=1e-4, atol=1e-5\n",
    "        )\n",
    "        print(f\"U1s gradients match: {U1s_grad_match}\")\n",
    "        if not U1s_grad_match:\n",
    "            max_diff = torch.max(\n",
    "                torch.abs(sk_linear.U1s.grad - sk_linear_triton.U1s.grad)\n",
    "            )\n",
    "            error_msg = f\"U1s gradients don't match. Max difference: {max_diff.item()}\"\n",
    "            print(error_msg)\n",
    "            if raise_error:\n",
    "                assert U1s_grad_match, error_msg\n",
    "    else:\n",
    "        print(\"U1s gradients not available - skipping comparison\")\n",
    "        U1s_grad_match = True  # Skip this comparison\n",
    "\n",
    "    # Check if U2s gradients match - only if both exist\n",
    "    if (\n",
    "        hasattr(sk_linear.U2s, \"grad\")\n",
    "        and hasattr(sk_linear_triton.U2s, \"grad\")\n",
    "        and sk_linear.U2s.grad is not None\n",
    "        and sk_linear_triton.U2s.grad is not None\n",
    "    ):\n",
    "        U2s_grad_match = torch.allclose(\n",
    "            sk_linear.U2s.grad, sk_linear_triton.U2s.grad, rtol=1e-4, atol=1e-5\n",
    "        )\n",
    "        print(f\"U2s gradients match: {U2s_grad_match}\")\n",
    "        if not U2s_grad_match:\n",
    "            max_diff = torch.max(\n",
    "                torch.abs(sk_linear.U2s.grad - sk_linear_triton.U2s.grad)\n",
    "            )\n",
    "            error_msg = f\"U2s gradients don't match. Max difference: {max_diff.item()}\"\n",
    "            print(error_msg)\n",
    "            if raise_error:\n",
    "                assert U2s_grad_match, error_msg\n",
    "    else:\n",
    "        print(\"U2s gradients not available - skipping comparison\")\n",
    "        U2s_grad_match = True  # Skip this comparison\n",
    "\n",
    "    # Check if bias gradients match\n",
    "    bias_grad_match = torch.allclose(\n",
    "        sk_linear.bias.grad, sk_linear_triton.bias.grad, rtol=1e-4, atol=1e-5\n",
    "    )\n",
    "    print(f\"Bias gradients match: {bias_grad_match}\")\n",
    "    if not bias_grad_match:\n",
    "        max_diff = torch.max(\n",
    "            torch.abs(sk_linear.bias.grad - sk_linear_triton.bias.grad)\n",
    "        )\n",
    "        error_msg = f\"Bias gradients don't match. Max difference: {max_diff.item()}\"\n",
    "        print(error_msg)\n",
    "        if raise_error:\n",
    "            assert bias_grad_match, error_msg\n",
    "\n",
    "    # Return overall result\n",
    "    all_matches = all(\n",
    "        [\n",
    "            forward_match,\n",
    "            input_grad_match,\n",
    "            S1s_grad_match,\n",
    "            S2s_grad_match,\n",
    "            U1s_grad_match,\n",
    "            U2s_grad_match,\n",
    "            bias_grad_match,\n",
    "        ]\n",
    "    )\n",
    "    if raise_error:\n",
    "        assert all_matches, \"At least one comparison failed. See detailed errors above.\"\n",
    "    return all_matches\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Comparing SKLinear and SKLinear_triton implementations...\")\n",
    "\n",
    "    # Test with default parameters\n",
    "    try:\n",
    "        result = compare_linear_implementations()\n",
    "        print(f\"All checks passed: {result}\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Default test failed: {e}\")\n",
    "\n",
    "    # Test with different parameters\n",
    "    try:\n",
    "        result_small = compare_linear_implementations(\n",
    "            batch_size=32, in_features=64, out_features=32, num_terms=2, low_rank=4\n",
    "        )\n",
    "        print(f\"Small model checks passed: {result_small}\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Small model test failed: {e}\")\n",
    "\n",
    "    try:\n",
    "        result_large = compare_linear_implementations(\n",
    "            batch_size=128, in_features=256, out_features=128, num_terms=8, low_rank=16\n",
    "        )\n",
    "        print(f\"Large model checks passed: {result_large}\")\n",
    "    except AssertionError as e:\n",
    "        print(f\"Large model test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T02:26:32.039043Z",
     "iopub.status.busy": "2025-05-01T02:26:32.038497Z",
     "iopub.status.idle": "2025-05-01T02:26:32.164458Z",
     "shell.execute_reply": "2025-05-01T02:26:32.163697Z",
     "shell.execute_reply.started": "2025-05-01T02:26:32.039024Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch._dynamo\n",
    "# import torch._inductor.config as config\n",
    "# import itertools\n",
    "# import pandas as pd\n",
    "\n",
    "# # Configure torch\n",
    "# config.max_autotune_gemm = False\n",
    "# torch._dynamo.config.cache_size_limit = 2**16\n",
    "# torch._dynamo.config.accumulated_cache_size_limit = 2**16\n",
    "\n",
    "# def is_valid_params(in_features, out_features, num_terms, low_rank):\n",
    "#     """\n",
    "#     Check if parameter combination is valid:\n",
    "#     A combination is invalid if 2 * num_terms * low_rank * (out_features + in_features) >= out_features * in_features\n",
    "#     """\n",
    "#     return 2 * num_terms * low_rank * (out_features + in_features) < out_features * in_features\n",
    "\n",
    "# class BenchmarkParams:\n",
    "#     def __init__(self,\n",
    "#                  in_features=256,\n",
    "#                  out_features=256,\n",
    "#                  num_terms=3,\n",
    "#                  low_rank=8,\n",
    "#                  batch_size=64,\n",
    "#                  num_runs=200,\n",
    "#                  warmup=15,\n",
    "#                  device='cuda',\n",
    "#                  dtype=torch.float16):\n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.num_terms = num_terms\n",
    "#         self.low_rank = low_rank\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_runs = num_runs\n",
    "#         self.warmup = warmup\n",
    "#         self.device = device\n",
    "#         self.dtype = dtype\n",
    "\n",
    "# def benchmark_model(model, x, model_name, params):\n",
    "#     """\n",
    "#     Generic benchmarking function for any PyTorch model.\n",
    "\n",
    "#     Args:\n",
    "#         model: The PyTorch model to benchmark\n",
    "#         x: Input tensor\n",
    "#         model_name: Name of the model for logging\n",
    "#         params: Benchmark parameters\n",
    "\n",
    "#     Returns:\n",
    "#         Dictionary with benchmark results\n",
    "#     """\n",
    "#     # Compile the model\n",
    "#     model_compiled = torch.compile(\n",
    "#         model,\n",
    "#         backend=\"inductor\",\n",
    "#         fullgraph=True,\n",
    "#         dynamic=False\n",
    "#     )\n",
    "\n",
    "#     # Benchmark forward pass\n",
    "#     print(f\"\\n=== {model_name} FORWARD PASS BENCHMARK ===\")\n",
    "\n",
    "#     # Warmup runs for forward pass\n",
    "#     model_compiled.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for _ in range(params.warmup):\n",
    "#             _ = model_compiled(x)\n",
    "\n",
    "#     torch.cuda.synchronize()\n",
    "\n",
    "#     # Actual timed runs for forward\n",
    "#     forward_times = []\n",
    "#     with torch.no_grad():\n",
    "#         for _ in range(params.num_runs):\n",
    "#             torch.cuda.synchronize()\n",
    "#             start = time.perf_counter()\n",
    "#             _ = model_compiled(x)\n",
    "#             torch.cuda.synchronize()\n",
    "#             end = time.perf_counter()\n",
    "\n",
    "#             forward_times.append((end - start) * 1000)  # Convert to ms\n",
    "\n",
    "#     mean_forward = np.mean(forward_times)\n",
    "#     std_forward = np.std(forward_times)\n",
    "#     print(f\"{model_name} forward: {mean_forward:.3f}  {std_forward:.3f} ms\")\n",
    "\n",
    "#     # Benchmark backward pass\n",
    "#     print(f\"\\n=== {model_name} BACKWARD PASS BENCHMARK ===\")\n",
    "\n",
    "#     # Warmup runs for backward pass\n",
    "#     model_compiled.train()\n",
    "#     for _ in range(params.warmup):\n",
    "#         out = model_compiled(x)\n",
    "#         loss = out.sum()\n",
    "#         loss.backward()\n",
    "#         x.grad.zero_()\n",
    "\n",
    "#     torch.cuda.synchronize()\n",
    "\n",
    "#     # Actual timed runs for backward\n",
    "#     backward_times = []\n",
    "#     for _ in range(params.num_runs):\n",
    "#         out = model_compiled(x)\n",
    "#         loss = out.sum()\n",
    "\n",
    "#         torch.cuda.synchronize()\n",
    "#         start = time.perf_counter()\n",
    "#         loss.backward()\n",
    "#         torch.cuda.synchronize()\n",
    "#         end = time.perf_counter()\n",
    "\n",
    "#         backward_times.append((end - start) * 1000)  # Convert to ms\n",
    "#         x.grad.zero_()\n",
    "\n",
    "#     mean_backward = np.mean(backward_times)\n",
    "#     std_backward = np.std(backward_times)\n",
    "#     print(f\"{model_name} backward: {mean_backward:.3f}  {std_backward:.3f} ms\")\n",
    "\n",
    "#     return {\n",
    "#         \"forward\": {\n",
    "#             \"mean\": mean_forward,\n",
    "#             \"std\": std_forward,\n",
    "#             \"times\": forward_times\n",
    "#         },\n",
    "#         \"backward\": {\n",
    "#             \"mean\": mean_backward,\n",
    "#             \"std\": std_backward,\n",
    "#             \"times\": backward_times\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# def benchmark_model_factory(model_factory, model_name, params):\n",
    "#     """\n",
    "#     Benchmark a model using a factory function.\n",
    "\n",
    "#     Args:\n",
    "#         model_factory: Function that creates the model\n",
    "#         model_name: Name of the model for logging\n",
    "#         params: Benchmark parameters\n",
    "\n",
    "#     Returns:\n",
    "#         Dictionary with benchmark results\n",
    "#     """\n",
    "#     # Create the model\n",
    "#     torch.manual_seed(42)\n",
    "#     model = model_factory(params)\n",
    "\n",
    "#     # Create input tensor for benchmarking\n",
    "#     x = torch.randn(params.batch_size, params.in_features,\n",
    "#                   dtype=params.dtype, device=params.device, requires_grad=True)\n",
    "\n",
    "#     return benchmark_model(model, x, model_name, params)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import torch.nn as nn\n",
    "#     from panther.nn import SKLinear, SKLinear_triton\n",
    "\n",
    "#     # Parameter combinations to test\n",
    "#     ratios = [(1, 128), (128, 1), (1, 1), (2, 1), (1, 2)]\n",
    "#     base_sizes = [256, 512, 1024, 8192, 16384]\n",
    "#     num_terms_options = [1, 2, 3]\n",
    "#     low_rank_options = [10, 15, 20, 50, 100, 150]\n",
    "\n",
    "#     # Define model factories\n",
    "#     def create_sklinear_triton(p):\n",
    "#         return SKLinear_triton(p.in_features, p.out_features,\n",
    "#                              p.num_terms, p.low_rank,\n",
    "#                              dtype=p.dtype, device=p.device)\n",
    "\n",
    "#     models_to_benchmark = [\n",
    "#         (create_sklinear_triton, \"SKLinear_triton\")\n",
    "#     ]\n",
    "\n",
    "#     # Prepare data structure to store all results\n",
    "#     results_data = []\n",
    "\n",
    "#     # Iterate through all parameter combinations\n",
    "#     total_combinations = len(ratios) * len(base_sizes) * len(num_terms_options) * len(low_rank_options)\n",
    "#     current_combo = 0\n",
    "\n",
    "#     for ratio, base_size in itertools.product(ratios, base_sizes):\n",
    "#         ratio_in, ratio_out = ratio\n",
    "\n",
    "#         # Calculate actual dimensions based on ratio and base size\n",
    "#         if ratio_in == 1:\n",
    "#             in_features = base_size\n",
    "#             out_features = base_size * ratio_out\n",
    "#         else:\n",
    "#             out_features = base_size\n",
    "#             in_features = base_size * ratio_in\n",
    "\n",
    "#         for num_terms, low_rank in itertools.product(num_terms_options, low_rank_options):\n",
    "#             current_combo += 1\n",
    "#             print(f\"\\n\\n{'='*20} COMBINATION {current_combo}/{total_combinations} {'='*20}\")\n",
    "#             print(f\"In features: {in_features}, Out features: {out_features}, Ratio: {ratio_in}:{ratio_out}\")\n",
    "#             print(f\"Base size: {base_size}, Num terms: {num_terms}, Low rank: {low_rank}\")\n",
    "\n",
    "#             # Check if parameters are valid\n",
    "#             is_valid = is_valid_params(in_features, out_features, num_terms, low_rank)\n",
    "\n",
    "#             if not is_valid:\n",
    "#                 print(f\"INVALID COMBINATION: 2 * {num_terms} * {low_rank} * ({out_features} + {in_features}) >= {out_features} * {in_features}\")\n",
    "#                 print(\"Skipping benchmarks for this invalid combination\")\n",
    "\n",
    "#                 # Add invalid entry to results data\n",
    "#                 for model_name in [m[1] for m in models_to_benchmark]:\n",
    "#                     results_data.append({\n",
    "#                         'model': model_name,\n",
    "#                         'in_features': in_features,\n",
    "#                         'out_features': out_features,\n",
    "#                         'ratio': f\"{ratio_in}:{ratio_out}\",\n",
    "#                         'base_size': base_size,\n",
    "#                         'num_terms': num_terms,\n",
    "#                         'low_rank': low_rank,\n",
    "#                         'forward_mean_ms': float('nan'),\n",
    "#                         'forward_std_ms': float('nan'),\n",
    "#                         'backward_mean_ms': float('nan'),\n",
    "#                         'backward_std_ms': float('nan'),\n",
    "#                         'is_valid': False,\n",
    "#                         'error': \"Invalid parameter combination\"\n",
    "#                     })\n",
    "#                 continue\n",
    "\n",
    "#             # Create parameter object for this combination\n",
    "#             params = BenchmarkParams(\n",
    "#                 in_features=in_features,\n",
    "#                 out_features=out_features,\n",
    "#                 num_terms=num_terms,\n",
    "#                 low_rank=low_rank\n",
    "#             )\n",
    "\n",
    "#             all_results = {}\n",
    "#             for model_factory, model_name in models_to_benchmark:\n",
    "#                 print(f\"\\n{'='*20} Benchmarking {model_name} {'='*20}\")\n",
    "#                 try:\n",
    "#                     results = benchmark_model_factory(model_factory, model_name, params)\n",
    "#                     all_results[model_name] = results\n",
    "\n",
    "#                     # Add result to our data collection\n",
    "#                     results_data.append({\n",
    "#                         'model': model_name,\n",
    "#                         'in_features': in_features,\n",
    "#                         'out_features': out_features,\n",
    "#                         'ratio': f\"{ratio_in}:{ratio_out}\",\n",
    "#                         'base_size': base_size,\n",
    "#                         'num_terms': num_terms,\n",
    "#                         'low_rank': low_rank,\n",
    "#                         'forward_mean_ms': results['forward']['mean'],\n",
    "#                         'forward_std_ms': results['forward']['std'],\n",
    "#                         'backward_mean_ms': results['backward']['mean'],\n",
    "#                         'backward_std_ms': results['backward']['std'],\n",
    "#                         'is_valid': True\n",
    "#                     })\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error benchmarking {model_name}: {e}\")\n",
    "#                     # Add error entry to data\n",
    "#                     results_data.append({\n",
    "#                         'model': model_name,\n",
    "#                         'in_features': in_features,\n",
    "#                         'out_features': out_features,\n",
    "#                         'ratio': f\"{ratio_in}:{ratio_out}\",\n",
    "#                         'base_size': base_size,\n",
    "#                         'num_terms': num_terms,\n",
    "#                         'low_rank': low_rank,\n",
    "#                         'forward_mean_ms': float('nan'),\n",
    "#                         'forward_std_ms': float('nan'),\n",
    "#                         'backward_mean_ms': float('nan'),\n",
    "#                         'backward_std_ms': float('nan'),\n",
    "#                         'is_valid': True,\n",
    "#                         'error': str(e)\n",
    "#                     })\n",
    "\n",
    "#             # Print comparative summary for this combination\n",
    "#             if all_results:\n",
    "#                 print(\"\\n\" + \"=\"*60)\n",
    "#                 print(f\"{'='*20} SUMMARY FOR CURRENT COMBINATION {'='*20}\")\n",
    "#                 print(\"=\"*60)\n",
    "#                 print(f\"{'Model':<20} {'Forward (ms)':<25} {'Backward (ms)':<25}\")\n",
    "#                 print(\"-\"*60)\n",
    "\n",
    "#                 for model_name, results in all_results.items():\n",
    "#                     fwd = f\"{results['forward']['mean']:.3f}  {results['forward']['std']:.3f}\"\n",
    "#                     bwd = f\"{results['backward']['mean']:.3f}  {results['backward']['std']:.3f}\"\n",
    "#                     print(f\"{model_name:<20} {fwd:<25} {bwd:<25}\")\n",
    "\n",
    "#     # Create a DataFrame with all results\n",
    "#     df = pd.DataFrame(results_data)\n",
    "\n",
    "#     # Save results to CSV\n",
    "#     results_file = \"benchmark_results.csv\"\n",
    "#     df.to_csv(results_file, index=False)\n",
    "#     print(f\"\\nAll benchmark results saved to {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}