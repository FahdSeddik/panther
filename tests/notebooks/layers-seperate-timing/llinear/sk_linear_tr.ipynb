{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"github_repos_wildcard\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\nGITHUB_TOKEN = secret_value_0\nUSER = \"gaserSami\"\nCLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/panther.git\"\nget_ipython().system(f\"git clone --branch torch_compile {CLONE_URL}\")\n\n# import sys\n# sys.path.append(\"panther\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nimport triton\nprint(triton.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!export LC_ALL=\"en_US.UTF-8\"\n!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n!ldconfig /usr/lib64-nvidia","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/panther/panther/nn/linear_kernels/forward.py\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_D2': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['BSIZE', 'K', 'd2', 'L'],\n)\n@triton.jit\ndef first_pass_kernel(\n        hin_ptr, S1s_ptr, U2s_ptr, out1_ptr, out2_ptr,\n        BSIZE, K, d2, L,\n        stride_hin_bsize, stride_hin_d2,\n        stride_su_l, stride_su_d2, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_D2: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_k = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_k\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n    pid_k = (pid % num_pid_in_group) // group_size_bsize\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_k = pid_k *  BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_d2 = tl.arange(0, BLOCK_SIZE_D2)\n\n    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_K), BLOCK_SIZE_K)\n    offs_d2 = tl.max_contiguous(tl.multiple_of(offs_d2, BLOCK_SIZE_D2), BLOCK_SIZE_D2)\n    \n    hin_ptrs = hin_ptr + (offs_bsize[:, None] * stride_hin_bsize + offs_d2[None, :] * stride_hin_d2)\n\n    su_tmp = batch_id * stride_su_l + (offs_d2[:, None] * stride_su_d2 + offs_k[None, :] * stride_su_k)\n    S1s_ptrs = S1s_ptr + su_tmp\n    U2s_ptrs = U2s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    accumulator2 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    \n    for d2_i in range(0, tl.cdiv(d2, BLOCK_SIZE_D2)):\n        hin_mask = (offs_bsize[:, None] < BSIZE) & (offs_d2[None, :] < d2 - d2_i * BLOCK_SIZE_D2)\n        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n        \n        su_mask = (offs_d2[:, None] < d2 - d2_i * BLOCK_SIZE_D2) & (offs_k[None, :] < K)\n        S1s = tl.load(S1s_ptrs, mask=su_mask, other=0.0)\n        U2s = tl.load(U2s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(hin, S1s, input_precision=\"ieee\")\n        accumulator2 += tl.dot(hin, U2s, input_precision=\"ieee\")\n        \n        hin_ptrs += BLOCK_SIZE_D2 * stride_hin_d2\n        S1s_ptrs += BLOCK_SIZE_D2 * stride_su_d2\n        U2s_ptrs += BLOCK_SIZE_D2 * stride_su_d2\n\n    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n    out1_ptrs = out1_ptr + out_tmp\n    out2_ptrs = out2_ptr + out_tmp\n    \n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_k[None, :] < K)\n    \n    tl.store(out1_ptrs, accumulator1, mask=out_mask)\n    tl.store(out2_ptrs, accumulator2, mask=out_mask)\n  \n@triton.autotune(\n    configs = [\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_D1': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_D1': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_D1': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['BSIZE', 'd1', 'K', 'L'],\n)\n@triton.jit\ndef second_pass_kernel(\n        in1_ptr, in2_ptr, U1s_ptr, S2s_ptr, bias_ptr, out_ptr,\n        BSIZE, d1, K, L,\n        stride_in12_l, stride_in12_bsize, stride_in12_k,\n        stride_us_l, stride_us_k, stride_us_d1,\n        stride_bias_bsize, stride_bias_d1,\n        stride_out_bsize, stride_out_d1,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_D1: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_d1 = tl.cdiv(d1, BLOCK_SIZE_D1)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_d1\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    GROUP_SIZE_BSIZE = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % GROUP_SIZE_BSIZE)\n    pid_d1 = (pid % num_pid_in_group) // GROUP_SIZE_BSIZE\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_d1 = pid_d1 *  BLOCK_SIZE_D1 + tl.arange(0, BLOCK_SIZE_D1)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    offs_d1 = tl.max_contiguous(tl.multiple_of(offs_d1, BLOCK_SIZE_D1), BLOCK_SIZE_D1)\n    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_K), BLOCK_SIZE_K)\n\n    in_tmp = offs_bsize[:, None] * stride_in12_bsize + offs_k[None, :] * stride_in12_k\n    us_tmp = offs_k[:, None] * stride_us_k + offs_d1[None, :] * stride_us_d1\n\n    accumulator = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_D1), value=0.0, dtype=tl.float32)\n    \n    for l in range(0, L):\n        l_in_offset = l * stride_in12_l\n        l_us_offset = l * stride_us_l\n        \n        in1_ptrs = in1_ptr + l_in_offset + in_tmp\n        in2_ptrs = in2_ptr + l_in_offset + in_tmp\n    \n        U1s_ptrs = U1s_ptr + l_us_offset + us_tmp\n        S2s_ptrs = S2s_ptr + l_us_offset + us_tmp\n        \n        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n            in_mask = offs_k[None, :] < K - k * BLOCK_SIZE_K\n            in1 = tl.load(in1_ptrs, mask=in_mask, other=0.0)\n            in2 = tl.load(in2_ptrs, mask=in_mask, other=0.0)\n            \n            us_mask = offs_k[:, None] < K - k * BLOCK_SIZE_K\n            U1s = tl.load(U1s_ptrs, mask=us_mask, other=0.0)\n            S2s = tl.load(S2s_ptrs, mask=us_mask, other=0.0)\n            \n            accumulator += tl.dot(in1, U1s, input_precision=\"ieee\")\n            accumulator += tl.dot(in2, S2s, input_precision=\"ieee\")\n\n            in_inc = BLOCK_SIZE_K * stride_in12_k\n            in1_ptrs += in_inc\n            in2_ptrs += in_inc\n            \n            us_inc = BLOCK_SIZE_K * stride_us_k\n            U1s_ptrs += us_inc\n            S2s_ptrs += us_inc\n    \n    bias_ptrs = bias_ptr + offs_d1[None, :] * stride_bias_d1\n    bias_mask = (offs_d1[None, :] < d1)\n    bias = tl.load(bias_ptrs, mask=bias_mask, other=0.0)\n\n    accumulator *= (1.0/ (2.0 * L))\n    accumulator += bias\n\n    out_ptrs = out_ptr + stride_out_bsize * offs_bsize[:, None] + stride_out_d1 * offs_d1[None, :]\n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_d1[None, :] < d1)\n    \n    tl.store(out_ptrs, accumulator, mask=out_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/panther/panther/nn/linear_kernels/backward.py\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['BSIZE', 'K', 'd1', 'L'],\n)\n@triton.jit\ndef first_pass_gU1s_g_S2s_kernel(\n        g_ptr, U1s_ptr, S2s_ptr, g_U1s_ptr, g_S2s_ptr,\n        BSIZE, K, d1, L,\n        stride_g_bsize, stride_g_d1,\n        stride_su_l, stride_su_d1, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_d1: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_k = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_k\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n    pid_k = (pid % num_pid_in_group) // group_size_bsize\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_k = pid_k *  BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_d1 = tl.arange(0, BLOCK_SIZE_d1)\n\n    g_ptrs = g_ptr + (offs_bsize[:, None] * stride_g_bsize + offs_d1[None, :] * stride_g_d1)\n\n    su_tmp = batch_id * stride_su_l + (offs_d1[:, None] * stride_su_d1 + offs_k[None, :] * stride_su_k)\n    U1s_ptrs = U1s_ptr + su_tmp\n    S2s_ptrs = S2s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    accumulator2 = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_K), value=0.0, dtype=tl.float32)\n    \n    \n    for d1_i in range(0, tl.cdiv(d1, BLOCK_SIZE_d1)):\n        g = tl.load(g_ptrs, mask=(offs_d1[None, :] < d1 - d1_i * BLOCK_SIZE_d1), other=0.0)\n        \n        su_mask = (offs_d1[:, None] < d1 - d1_i * BLOCK_SIZE_d1)\n        U1s = tl.load(U1s_ptrs, mask=su_mask, other=0.0)\n        S2s = tl.load(S2s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(g, U1s, input_precision=\"ieee\")\n        accumulator2 += tl.dot(g, S2s, input_precision=\"ieee\")\n        \n        g_ptrs += BLOCK_SIZE_d1 * stride_g_d1\n        U1s_ptrs += BLOCK_SIZE_d1 * stride_su_d1\n        S2s_ptrs += BLOCK_SIZE_d1 * stride_su_d1\n\n    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n    g_U1s_ptrs = g_U1s_ptr + out_tmp\n    g_S2s_ptrs = g_S2s_ptr + out_tmp\n    \n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_k[None, :] < K)\n    \n    tl.store(g_U1s_ptrs, accumulator1, mask=out_mask)\n    tl.store(g_S2s_ptrs, accumulator2, mask=out_mask)\n\n  \n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_BSIZE': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_BSIZE': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['BSIZE', 'd2', 'K', 'L'],\n)\n@triton.jit\ndef second_pass_gUS11_22_kernel(\n        g_U1s_ptr, g_S2s_ptr, S1s_ptr, U2s_ptr, out_ptr,\n        BSIZE, d2, K, L,\n        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n        stride_us_l, stride_us_k, stride_us_d2,\n        stride_out_bsize, stride_out_d2,\n        BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_d2: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n        GROUP_SIZE_BSIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_d2 = tl.cdiv(d2, BLOCK_SIZE_d2)\n    num_pid_in_group = GROUP_SIZE_BSIZE * num_pid_d2\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_BSIZE\n    GROUP_SIZE_BSIZE = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_BSIZE)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % GROUP_SIZE_BSIZE)\n    pid_d2 = (pid % num_pid_in_group) // GROUP_SIZE_BSIZE\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_d2 = pid_d2 *  BLOCK_SIZE_d2 + tl.arange(0, BLOCK_SIZE_d2)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    in_tmp = offs_bsize[:, None] * stride_g_U1s2_bsize + offs_k[None, :] * stride_g_U1s2_k\n    us_tmp = offs_k[:, None] * stride_us_k + offs_d2[None, :] * stride_us_d2\n\n    accumulator = tl.full(shape=(BLOCK_SIZE_BSIZE, BLOCK_SIZE_d2), value=0.0, dtype=tl.float32)\n    \n    for l in range(0, L):\n        g_l_offset = l * stride_g_U1s2_l  # Offset for g_U1s and g_S2s\n        s_l_offset = l * stride_us_l      # Offset for S1s and U2s\n\n        g_U1s_ptrs = g_U1s_ptr + g_l_offset + in_tmp\n        g_S2s_ptrs = g_S2s_ptr + g_l_offset + in_tmp\n\n        S1s_ptrs = S1s_ptr + s_l_offset + us_tmp\n        U2s_ptrs = U2s_ptr + s_l_offset + us_tmp\n        \n        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n            in_mask = offs_k[None, :] < K - k * BLOCK_SIZE_K\n            g_U1s = tl.load(g_U1s_ptrs, mask=in_mask, other=0.0)\n            g_S2s = tl.load(g_S2s_ptrs, mask=in_mask, other=0.0)\n            \n            us_mask = offs_k[:, None] < K - k * BLOCK_SIZE_K\n            S1s = tl.load(S1s_ptrs, mask=us_mask, other=0.0)\n            U2s = tl.load(U2s_ptrs, mask=us_mask, other=0.0)\n            \n            accumulator += tl.dot(g_U1s, S1s, input_precision=\"ieee\")\n            accumulator += tl.dot(g_S2s, U2s, input_precision=\"ieee\")\n\n            in_inc = BLOCK_SIZE_K * stride_g_U1s2_k\n            g_U1s_ptrs += in_inc\n            g_S2s_ptrs += in_inc\n            \n            us_inc = BLOCK_SIZE_K * stride_us_k\n            S1s_ptrs += us_inc\n            U2s_ptrs += us_inc\n    \n    # accumulator *= (1.0/ (2.0 * L))\n\n    out_ptrs = out_ptr + stride_out_bsize * offs_bsize[:, None] + stride_out_d2 * offs_d2[None, :]\n    out_mask = (offs_bsize[:, None] < BSIZE) & (offs_d2[None, :] < d2)\n    \n    tl.store(out_ptrs, accumulator, mask=out_mask)\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_d2': 32, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_d2': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_d2': 256, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 64, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 64, 'BLOCK_SIZE_k': 128, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_d2': 128, 'BLOCK_SIZE_k': 32, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_d2': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['d2', 'K', 'BSIZE', 'L'],\n)\n@triton.jit\ndef calc_grad_S1s_kernel(\n        hin_ptr, g_U1s_ptr, grad_g_S1s_ptr,\n        d2, k, BSIZE, L,\n        stride_hin_bsize, stride_hin_BSIZE,\n        stride_su_l, stride_su_BSIZE, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n        BLOCK_SIZE_d2: tl.constexpr, BLOCK_SIZE_k: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr,\n        GROUP_SIZE_d2: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_bsize = tl.cdiv(d2, BLOCK_SIZE_d2)\n    num_pid_k = tl.cdiv(k, BLOCK_SIZE_k)\n    num_pid_in_group = GROUP_SIZE_d2 * num_pid_k\n    group_id = pid // num_pid_in_group\n    first_pid_bsize = group_id * GROUP_SIZE_d2\n    group_size_bsize = min(num_pid_bsize - first_pid_bsize, GROUP_SIZE_d2)\n    pid_bsize = first_pid_bsize + ((pid % num_pid_in_group) % group_size_bsize)\n    pid_k = (pid % num_pid_in_group) // group_size_bsize\n\n    offs_bsize = pid_bsize * BLOCK_SIZE_d2 + tl.arange(0, BLOCK_SIZE_d2)\n    offs_k = pid_k *  BLOCK_SIZE_k + tl.arange(0, BLOCK_SIZE_k)\n    offs_BSIZE = tl.arange(0, BLOCK_SIZE_BSIZE)\n\n    offs_bsize = tl.max_contiguous(tl.multiple_of(offs_bsize, BLOCK_SIZE_d2), BLOCK_SIZE_d2)\n    offs_k = tl.max_contiguous(tl.multiple_of(offs_k, BLOCK_SIZE_k), BLOCK_SIZE_k)\n    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    \n    hin_ptrs = hin_ptr + (offs_bsize[:, None] * stride_hin_bsize + offs_BSIZE[None, :] * stride_hin_BSIZE)\n\n    su_tmp = batch_id * stride_su_l + (offs_BSIZE[:, None] * stride_su_BSIZE + offs_k[None, :] * stride_su_k)\n    g_U1s_ptrs = g_U1s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_d2, BLOCK_SIZE_k), value=0.0, dtype=tl.float32)\n    accumulator2 = tl.full(shape=(BLOCK_SIZE_d2, BLOCK_SIZE_k), value=0.0, dtype=tl.float32)\n    \n    for BSIZE_i in range(0, tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)):\n        hin_mask = (offs_bsize[:, None] < d2) & (offs_BSIZE[None, :] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE)\n        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n        \n        su_mask = (offs_BSIZE[:, None] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE) & (offs_k[None, :] < k)\n        g_U1s = tl.load(g_U1s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(hin, g_U1s, input_precision=\"ieee\")\n        \n        hin_ptrs += BLOCK_SIZE_BSIZE * stride_hin_BSIZE\n        g_U1s_ptrs += BLOCK_SIZE_BSIZE * stride_su_BSIZE\n\n    out_tmp = batch_id * stride_out_l + stride_out_bsize * offs_bsize[:, None] + stride_out_k * offs_k[None, :]\n    grad_g_S1s_ptrs = grad_g_S1s_ptr + out_tmp\n    \n    out_mask = (offs_bsize[:, None] < d2) & (offs_k[None, :] < k)\n    \n    tl.store(grad_g_S1s_ptrs, accumulator1, mask=out_mask)\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 256, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 64, 'BLOCK_SIZE_d2': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_BSIZE': 128, 'BLOCK_SIZE_d2': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_BSIZE': 32, 'BLOCK_SIZE_d2': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['K', 'd2', 'BSIZE', 'L'],\n)\n@triton.jit\ndef first_pass_U2s_hin_kernel(\n        hin_ptr, U2s_ptr, U2s_h_in_ptr,\n        K, d2, BSIZE, L,\n        stride_hin_d2, stride_hin_BSIZE,\n        stride_su_l, stride_su_K, stride_su_d2,\n        stride_out_l, stride_out_K, stride_out_BSIZE,\n        BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr, BLOCK_SIZE_d2: tl.constexpr,\n        GROUP_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_K = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_BSIZE = tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)\n    num_pid_in_group = GROUP_SIZE_K * num_pid_BSIZE\n    group_id = pid // num_pid_in_group\n    first_pid_K = group_id * GROUP_SIZE_K\n    group_size_BSIZE = min(num_pid_K - first_pid_K, GROUP_SIZE_K)\n    pid_K = first_pid_K + ((pid % num_pid_in_group) % group_size_BSIZE)\n    pid_BSIZE = (pid % num_pid_in_group) // group_size_BSIZE\n\n    offs_K = pid_K * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_BSIZE = pid_BSIZE *  BLOCK_SIZE_BSIZE + tl.arange(0, BLOCK_SIZE_BSIZE)\n    offs_d2 = tl.arange(0, BLOCK_SIZE_d2)\n\n    offs_K = tl.max_contiguous(tl.multiple_of(offs_K, BLOCK_SIZE_K), BLOCK_SIZE_K)\n    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    offs_d2 = tl.max_contiguous(tl.multiple_of(offs_d2, BLOCK_SIZE_d2), BLOCK_SIZE_d2)\n    \n    hin_ptrs = hin_ptr + (offs_d2[:, None] * stride_hin_d2 + offs_BSIZE[None, :] * stride_hin_BSIZE)\n\n    su_tmp = batch_id * stride_su_l + (offs_K[:, None] * stride_su_K + offs_d2[None, :] * stride_su_d2)\n    U2s_ptrs = U2s_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_K, BLOCK_SIZE_BSIZE), value=0.0, dtype=tl.float32)\n    \n    for d2_i in range(0, tl.cdiv(d2, BLOCK_SIZE_d2)):\n        hin_mask = (offs_d2[:, None] < d2 - d2_i * BLOCK_SIZE_d2) & (offs_BSIZE[None, :] < BSIZE)\n        hin = tl.load(hin_ptrs, mask=hin_mask, other=0.0)\n        \n        su_mask = (offs_K[:, None] < K) & (offs_d2[None, :] < d2 - d2_i * BLOCK_SIZE_d2)\n        U2s = tl.load(U2s_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(U2s, hin, input_precision=\"ieee\")\n        \n        hin_ptrs += BLOCK_SIZE_d2 * stride_hin_d2\n        U2s_ptrs += BLOCK_SIZE_d2 * stride_su_d2\n\n    out_tmp = batch_id * stride_out_l + stride_out_K * offs_K[:, None] + stride_out_BSIZE * offs_BSIZE[None, :]\n    U2s_h_in_ptrs = U2s_h_in_ptr + out_tmp\n    \n    out_mask = (offs_K[:, None] < K) & (offs_BSIZE[None, :] < BSIZE)\n    \n    tl.store(U2s_h_in_ptrs, accumulator1, mask=out_mask)\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=1, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 256, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_K': 32, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 32, 'GROUP_SIZE_K': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_K': 256, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 256, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 128, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 64, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 64, 'BLOCK_SIZE_d1': 128, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_K': 128, 'BLOCK_SIZE_d1': 32, 'BLOCK_SIZE_BSIZE': 64, 'GROUP_SIZE_K': 8}, num_stages=4, num_warps=4)\n    ],\n    key=['K', 'BSIZE', 'd1', 'L'],\n)\n@triton.jit\ndef calc_grad_S2s_kernel(\n        g_ptr, U2s_hin_ptr, grad_S2s_ptr,\n        K, BSIZE, d1, L,\n        stride_g_BSIZE, stride_g_d1,\n        stride_su_l, stride_su_K, stride_su_BSIZE,\n        stride_out_l, stride_out_K, stride_out_d1,\n        BLOCK_SIZE_K: tl.constexpr, BLOCK_SIZE_d1: tl.constexpr, BLOCK_SIZE_BSIZE: tl.constexpr,\n        GROUP_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(axis=1)\n    batch_id = tl.program_id(axis=0)\n    \n    num_pid_K = tl.cdiv(K, BLOCK_SIZE_K)\n    num_pid_d1 = tl.cdiv(d1, BLOCK_SIZE_d1)\n    num_pid_in_group = GROUP_SIZE_K * num_pid_d1\n    group_id = pid // num_pid_in_group\n    first_pid_K = group_id * GROUP_SIZE_K\n    group_size_d1 = min(num_pid_K - first_pid_K, GROUP_SIZE_K)\n    pid_K = first_pid_K + ((pid % num_pid_in_group) % group_size_d1)\n    pid_d1 = (pid % num_pid_in_group) // group_size_d1\n\n    offs_K = pid_K * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n    offs_d1 = pid_d1 *  BLOCK_SIZE_d1 + tl.arange(0, BLOCK_SIZE_d1)\n    offs_BSIZE = tl.arange(0, BLOCK_SIZE_BSIZE)\n\n    offs_K = tl.max_contiguous(tl.multiple_of(offs_K, BLOCK_SIZE_K), BLOCK_SIZE_K)\n    offs_d1 = tl.max_contiguous(tl.multiple_of(offs_d1, BLOCK_SIZE_d1), BLOCK_SIZE_d1)\n    offs_BSIZE = tl.max_contiguous(tl.multiple_of(offs_BSIZE, BLOCK_SIZE_BSIZE), BLOCK_SIZE_BSIZE)\n    \n    g_ptrs = g_ptr + (offs_BSIZE[:, None] * stride_g_BSIZE + offs_d1[None, :] * stride_g_d1)\n\n    su_tmp = batch_id * stride_su_l + (offs_K[:, None] * stride_su_K + offs_BSIZE[None, :] * stride_su_BSIZE)\n    U2s_hin_ptrs = U2s_hin_ptr + su_tmp\n\n    accumulator1 = tl.full(shape=(BLOCK_SIZE_K, BLOCK_SIZE_d1), value=0.0, dtype=tl.float32)\n    \n    for BSIZE_i in range(0, tl.cdiv(BSIZE, BLOCK_SIZE_BSIZE)):\n        g_mask = (offs_BSIZE[:, None] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE) & (offs_d1[None, :] < d1)\n        g = tl.load(g_ptrs, mask=g_mask, other=0.0)\n        \n        su_mask = (offs_K[:, None] < K) & (offs_BSIZE[None, :] < BSIZE - BSIZE_i * BLOCK_SIZE_BSIZE)\n        U2s_hin = tl.load(U2s_hin_ptrs, mask=su_mask, other=0.0)\n        \n        accumulator1 += tl.dot(U2s_hin, g, input_precision=\"ieee\")\n        \n        g_ptrs += BLOCK_SIZE_BSIZE * stride_g_BSIZE\n        U2s_hin_ptrs += BLOCK_SIZE_BSIZE * stride_su_BSIZE\n\n    out_tmp = batch_id * stride_out_l + stride_out_K * offs_K[:, None] + stride_out_d1 * offs_d1[None, :]\n    grad_S2s_ptrs = grad_S2s_ptr + out_tmp\n    \n    out_mask = (offs_K[:, None] < K) & (offs_d1[None, :] < d1)\n    \n    tl.store(grad_S2s_ptrs, accumulator1, mask=out_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/panther/panther/nn/linear_tr.py\nimport math\nfrom typing import Any, Tuple, List, Optional\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Function\nfrom torch.nn import init\nimport triton\nfrom panther.random import scaled_sign_sketch as gen_U\nfrom torch.library import triton_op, wrap_triton\nfrom .linear_kernels import (\n    first_pass_kernel,\n    second_pass_kernel,\n    first_pass_gU1s_g_S2s_kernel,\n    second_pass_gUS11_22_kernel,\n    calc_grad_S1s_kernel,\n    first_pass_U2s_hin_kernel,\n    calc_grad_S2s_kernel\n)\n\n@triton_op(\"panther::forward_op\", mutates_args={})\ndef forward_op(hin: torch.Tensor, S1s: torch.Tensor, S2s: torch.Tensor, U1s: torch.Tensor, U2s: torch.Tensor, bias: torch.Tensor) -> torch.Tensor:\n    device = 'cuda'\n    \n    # first pass\n    ############\n    L = S2s.shape[0]\n    BSIZE, d2 = hin.shape\n    L, _, K = S1s.shape\n    \n    in1 = torch.empty((L, BSIZE, K), dtype=torch.float32, device=device)\n    in2 = torch.empty((L, BSIZE, K), dtype=torch.float32, device=device)\n    \n    stride_hin_bsize, stride_hin_d2 = hin.stride(0), hin.stride(1)\n    stride_su_l, stride_su_d2, stride_su_k = S1s.stride(0), S1s.stride(1), S1s.stride(2)\n    stride_out_l, stride_out_bsize, stride_out_k = in1.stride(0), in1.stride(1), in1.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(K, META[\"BLOCK_SIZE_K\"]), )\n    \n    wrap_triton(first_pass_kernel)[grid](\n        hin, S1s, U2s, in1, in2,\n        BSIZE, K, d2, L,\n        stride_hin_bsize, stride_hin_d2,\n        stride_su_l, stride_su_d2, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k,\n    )\n\n    in1 = in1.contiguous()\n    in2 = in2.contiguous()\n\n    # second pass\n    #############\n    bias_unsqueezed = bias.unsqueeze(0)\n    L, BSIZE, K = in1.shape\n    _, _, d1 = U1s.shape\n    \n    out = torch.empty((BSIZE, d1), dtype=torch.float32, device=device)\n\n    stride_in12_l, stride_in12_bsize, stride_in12_k = in1.stride(0), in1.stride(1), in1.stride(2)\n    stride_us_l, stride_us_k, stride_us_d1 = U1s.stride(0), U1s.stride(1), U1s.stride(2)\n    stride_bias_bsize, stride_bias_d1 = bias_unsqueezed.stride(0), bias_unsqueezed.stride(1)\n    stride_out_bsize, stride_out_d1 = out.stride(0), out.stride(1)\n    \n    grid = lambda META: (triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_D1\"]), )\n    \n    wrap_triton(second_pass_kernel)[grid](\n        in1, in2, U1s, S2s, bias_unsqueezed, out,\n        BSIZE, d1, K, L,\n        stride_in12_l, stride_in12_bsize, stride_in12_k,\n        stride_us_l, stride_us_k, stride_us_d1,\n        stride_bias_bsize, stride_bias_d1,\n        stride_out_bsize, stride_out_d1,\n    )\n    \n    return out.contiguous()\n\n@forward_op.register_kernel(\"cpu\")\ndef _(input, S1s, S2s, U1s, U2s, bias):\n    num_terms = S2s.shape[0]\n    # Efficiently perform the sum over all l terms\n    input = input.unsqueeze(0).expand(num_terms, input.shape[0], input.shape[1])\n    return (\n        ((input.bmm(S1s)).bmm(U1s)).mean(0) / 2\n        + ((input.bmm(U2s)).bmm(S2s)).mean(0) / 2\n        + bias\n    )\n    \n@triton_op(\"panther::backward_op\", mutates_args={})\ndef backward_op(hin: torch.Tensor, S1s: torch.Tensor, S2s: torch.Tensor, U1s: torch.Tensor, U2s: torch.Tensor, g: torch.Tensor) -> List[torch.Tensor]:\n    device = 'cuda'\n    num_terms = S2s.shape[0]\n        \n    # Transpose and make contiguous\n    hin = hin.transpose(0, 1).contiguous()\n    U1s = U1s.transpose(1, 2).contiguous()\n    S1s = S1s.transpose(1, 2).contiguous()\n    U2s = U2s.transpose(1, 2).contiguous()\n    S2s = S2s.transpose(1, 2).contiguous()\n\n    g = g.contiguous() / (2 * num_terms)\n    \n    # first_pass_gU1s_g_S2s\n    #######################\n    BSIZE, d1 = g.shape\n    L, _, K = U1s.shape\n\n    # TO UNREMOVE:\n    g_U1s = torch.empty((L, BSIZE, K), dtype=torch.float32, device='cuda')\n    g_S2s = torch.empty((L, BSIZE, K), dtype=torch.float32, device='cuda')\n\n    # TO REMOVE:\n    # g_U1s = torch.rand((L, BSIZE, K), dtype=torch.float32, device='cuda')\n    # g_S2s = torch.rand((L, BSIZE, K), dtype=torch.float32, device='cuda')\n\n    stride_g_bsize, stride_g_d1 = g.stride(0), g.stride(1)\n    stride_su_l, stride_su_d1, stride_su_k = U1s.stride(0), U1s.stride(1), U1s.stride(2)\n    stride_out_l, stride_out_bsize, stride_out_k = g_U1s.stride(0), g_U1s.stride(1), g_U1s.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(K, META[\"BLOCK_SIZE_K\"]), )\n    \n    wrap_triton(first_pass_gU1s_g_S2s_kernel)[grid](\n        g, U1s, S2s, g_U1s, g_S2s,\n        BSIZE, K, d1, L,\n        stride_g_bsize, stride_g_d1,\n        stride_su_l, stride_su_d1, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k\n    )\n\n    g_U1s = g_U1s.contiguous()\n    g_S2s = g_S2s.contiguous()\n\n    # second_pass_gUS11_22\n    #######################\n    L, BSIZE, K = g_U1s.shape\n    _, _, d2 = S1s.shape\n    \n    grad = torch.empty((BSIZE, d2), dtype=torch.float32, device='cuda')\n\n    stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k = g_U1s.stride(0), g_U1s.stride(1), g_U1s.stride(2)\n    stride_us_l, stride_us_k, stride_us_d2 = S1s.stride(0), S1s.stride(1), S1s.stride(2)\n    stride_out_bsize, stride_out_d2 = grad.stride(0), grad.stride(1)\n    \n    grid = lambda META: (triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]) * triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]), )\n    \n    wrap_triton(second_pass_gUS11_22_kernel)[grid](\n        g_U1s, g_S2s, S1s, U2s, grad,\n        BSIZE, d2, K, L,\n        stride_g_U1s2_l, stride_g_U1s2_bsize, stride_g_U1s2_k,\n        stride_us_l, stride_us_k, stride_us_d2,\n        stride_out_bsize, stride_out_d2,\n    )\n\n    grad = grad.contiguous()\n\n    # calc_grad_S1s\n    ################\n    d2, BSIZE = hin.shape\n    L, _, k = g_U1s.shape\n    \n    grad_S1s = torch.empty((L, d2, k), dtype=torch.float32, device=device)\n\n    stride_hin_bsize, stride_hin_BSIZE = hin.stride(0), hin.stride(1)\n    stride_su_l, stride_su_BSIZE, stride_su_k = g_U1s.stride(0), g_U1s.stride(1), g_U1s.stride(2)\n    stride_out_l, stride_out_bsize, stride_out_k = grad_S1s.stride(0), grad_S1s.stride(1), grad_S1s.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(d2, META[\"BLOCK_SIZE_d2\"]) * triton.cdiv(k, META[\"BLOCK_SIZE_k\"]), )\n    \n    wrap_triton(calc_grad_S1s_kernel)[grid](\n        hin, g_U1s, grad_S1s,\n        d2, k, BSIZE, L,\n        stride_hin_bsize, stride_hin_BSIZE,\n        stride_su_l, stride_su_BSIZE, stride_su_k,\n        stride_out_l, stride_out_bsize, stride_out_k\n    )\n\n    grad_S1s = grad_S1s.contiguous()\n    \n    # first_pass_U2s_hin\n    ####################\n    L, K, d2 = U2s.shape\n    _, BSIZE = hin.shape\n\n    # TO UNREMOVE:\n    U2s_hin = torch.empty((L, K, BSIZE), dtype=torch.float32, device=device)\n    # TO REMOVE:\n    # U2s_hin = torch.randn((L, K, BSIZE), dtype=torch.float32, device=device)\n\n    stride_hin_d2, stride_hin_BSIZE = hin.stride(0), hin.stride(1)\n    stride_su_l, stride_su_K, stride_su_d2 = U2s.stride(0), U2s.stride(1), U2s.stride(2)\n    stride_out_l, stride_out_K, stride_out_BSIZE = U2s_hin.stride(0), U2s_hin.stride(1), U2s_hin.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(BSIZE, META[\"BLOCK_SIZE_BSIZE\"]), )\n    \n    wrap_triton(first_pass_U2s_hin_kernel)[grid](\n        hin, U2s, U2s_hin,\n        K, d2, BSIZE, L,\n        stride_hin_d2, stride_hin_BSIZE,\n        stride_su_l, stride_su_K, stride_su_d2,\n        stride_out_l, stride_out_K, stride_out_BSIZE\n    )\n\n    U2s_hin = U2s_hin.contiguous()\n    \n    # calc_grad_S2s\n    ###############\n    L, K, BSIZE = U2s_hin.shape\n    _, d1 = g.shape\n    \n    grad_S2s = torch.empty((L, K, d1), dtype=torch.float32, device=device)\n\n    stride_g_BSIZE, stride_g_d1 = g.stride(0), g.stride(1)\n    stride_su_l, stride_su_K, stride_su_BSIZE = U2s_hin.stride(0), U2s_hin.stride(1), U2s_hin.stride(2)\n    stride_out_l, stride_out_K, stride_out_d1 = grad_S2s.stride(0), grad_S2s.stride(1), grad_S2s.stride(2)\n    \n    grid = lambda META: (L, triton.cdiv(K, META[\"BLOCK_SIZE_K\"]) * triton.cdiv(d1, META[\"BLOCK_SIZE_d1\"]), )\n    \n    wrap_triton(calc_grad_S2s_kernel)[grid](\n        g, U2s_hin, grad_S2s,\n        K, BSIZE, d1, L,\n        stride_g_BSIZE, stride_g_d1,\n        stride_su_l, stride_su_K, stride_su_BSIZE,\n        stride_out_l, stride_out_K, stride_out_d1\n    )\n\n    grad_S2s = grad_S2s.contiguous()\n\n    return [\n        grad,\n        grad_S1s,\n        grad_S2s,\n        g.sum(0)\n    ]\n    \n@backward_op.register_kernel(\"cpu\")\ndef _(input, S1s, S2s, U1s, U2s, grad_output):\n    num_terms = S2s.shape[0]\n    g = grad_output / (2 * num_terms)\n    g = g.unsqueeze(0).expand(num_terms, g.shape[0], g.shape[1])\n    input = (\n        input.unsqueeze(0)\n        .expand(num_terms, input.shape[0], input.shape[1])\n        .transpose(1, 2)\n    )\n    U1s = U1s.transpose(1, 2)\n    S1s = S1s.transpose(1, 2)\n    U2s = U2s.transpose(1, 2)\n    S2s = S2s.transpose(1, 2)\n    t1 = g.bmm(U1s)\n    grad = t1.bmm(S1s).sum(0) + g.bmm(S2s).bmm(U2s).sum(0)\n    grad_S2s = (U2s.bmm(input)).bmm(g)\n    grad_S1s = input.bmm(g.bmm(U1s))\n\n    g = g[0]\n    return [\n        grad,\n        grad_S1s,\n        grad_S2s,\n        # sum g on batch dimension input.shape[0]\n        g.reshape(input.shape[2], -1).sum(0)\n    ]\n    \nclass SketchedLinearFunction_triton(Function):\n    # Note that forward, setup_context, and backward are @staticmethods\n    @staticmethod\n    def forward(\n        input: torch.Tensor,\n        S1s: torch.Tensor,\n        S2s: torch.Tensor,\n        U1s: torch.Tensor,\n        U2s: torch.Tensor,\n        bias: torch.Tensor,\n    ): \n        return forward_op(input, S1s, S2s, U1s, U2s, bias)\n\n    @staticmethod\n    # inputs is a Tuple of all of the inputs passed to forward.\n    # output is the output of the forward().\n    def setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any):\n        input, S1s, S2s, U1s, U2s, bias = inputs\n        ctx.save_for_backward(input, S1s, S2s, U1s, U2s, bias)\n\n    @staticmethod\n    def backward(ctx: Any, *grad_output: Any) -> Any:\n        # dl/dS2_i = U1_i g h_in^T / 2 * l\n        # dl/dS1_i = g h_in^T U2_i^T / 2 * l\n        # dl/dh_in = 1/(2*l) * (sum_{i=1}^{l} (S1_i^T U1_i g) + sum_{i=1}^{l} (U2_i^T S2_i g))\n        # dl/db = g\n        hin, S1s, S2s, U1s, U2s, _ = ctx.saved_tensors\n        grad_input, grad_S1s, grad_S2s, grad_bias = backward_op(hin, S1s, S2s, U1s, U2s, grad_output[0])\n        return grad_input, grad_S1s, grad_S2s, None, None, grad_bias\n        \n\n\nclass SKLinear_triton(nn.Module):\n    __constants__ = [\"in_features\", \"out_features\", \"num_terms\", \"low_rank\"]\n    in_features: int\n    out_features: int\n    num_terms: int\n    low_rank: int\n    S1s: torch.Tensor\n    S2s: torch.Tensor\n    U1s: torch.Tensor\n    U2s: torch.Tensor\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        num_terms: int,\n        low_rank: int,\n        W_init=None,\n        bias: bool = True,\n        dtype=None,\n        device=None,\n    ):\n        factory_kwargs = {\"dtype\": dtype, \"device\": device}\n        super(SKLinear_triton, self).__init__()\n\n        # if (\n        #     2 * num_terms * low_rank * (out_features + in_features)\n        #     > out_features * in_features\n        # ):\n        #     raise ValueError(\n        #         \"The number of parameters in the sketching layer is larger \"\n        #         + \"than the number of parameters in the fully connected layer.\"\n        #     )\n\n        self.num_terms = num_terms # l\n        self.low_rank = low_rank # k\n        self.out_features = out_features\n        self.in_features = in_features\n\n        # Register U1s and U2s as buffers since they are not learnable\n        self.register_buffer(\n            \"U1s\",\n            torch.stack(\n                [\n                    gen_U(low_rank, out_features, **factory_kwargs)\n                    for _ in range(num_terms)\n                ]\n            ),\n        )  # k(low rank)xd1(out) stacked along the zeros dimension (l) -> l x k x d1\n        self.register_buffer(\n            \"U2s\",\n            torch.stack(\n                [\n                    gen_U(in_features, low_rank, **factory_kwargs)\n                    for _ in range(num_terms)\n                ]\n            ),\n        )  # d2xk stacked along the zeros dimension (l) -> l x d2 x k\n\n        # W is used to only initialize S\n        if W_init is None:\n            W = torch.empty(in_features, out_features, **factory_kwargs) # d2 * d1\n            init.kaiming_uniform_(W, a=math.sqrt(5))\n        else:\n            W = W_init.T.detach().clone()\n\n        # S1s and S2s are precomputed but not updated in the backward pass\n        self.S1s = nn.Parameter(\n            torch.stack([torch.matmul(W, self.U1s[i].T) for i in range(num_terms)])\n        )  # d2xk stacked along the zeros dimension (l) -> l x d2 x k\n        self.S2s = nn.Parameter(\n            torch.stack([torch.matmul(self.U2s[i].T, W) for i in range(num_terms)])\n        )  # kxd1 stacked along the zeros dimension (l) -> l x k x d1\n\n        # Bias term initialized with a small standard deviation\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs)) #1 * d1\n            fan_in, _ = init._calculate_fan_in_and_fan_out(W)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n        else:\n            self.register_parameter(\"bias\", None)\n\n    def forward(self, h_in):\n        # TODO: Make sure all the things are contiguos\n        return SketchedLinearFunction_triton.apply(\n            h_in.contiguous(), self.S1s.contiguous(), self.S2s.contiguous(), self.U1s.contiguous(), self.U2s.contiguous(), self.bias.contiguous()\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# checking ","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn.functional as F\n# from panther.nn.linear import SKLinear\n# from panther.nn.linear_tr import SKLinear_triton\n\n# def compare_linear_implementations(batch_size=64, in_features=128, out_features=64, num_terms=4, low_rank=8, raise_error=True):\n#     \"\"\"\n#     Compare the outputs of the forward pass and gradients between regular SKLinear and Triton-accelerated SKLinear_triton.\n    \n#     Args:\n#         batch_size: Batch size for the input tensor\n#         in_features: Number of input features\n#         out_features: Number of output features\n#         num_terms: Number of terms (l) in the sketched linear layer\n#         low_rank: The low-rank dimension (k) in the sketched linear layer\n#         raise_error: If True, raise AssertionError when comparisons fail\n    \n#     Returns:\n#         bool: True if all comparisons pass, False otherwise\n    \n#     Raises:\n#         AssertionError: If any comparison fails and raise_error is True\n#     \"\"\"\n#     # Set seed for reproducibility\n#     torch.manual_seed(42)\n    \n#     # Create identical layers\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n#     # Generate the same initialization for both layers\n#     W_init = torch.randn(out_features, in_features, device=device)\n    \n#     # Create both layer implementations with identical parameters\n#     sk_linear = SKLinear(in_features, out_features, num_terms, low_rank, W_init=W_init, device=device)\n#     sk_linear_triton = SKLinear_triton(in_features, out_features, num_terms, low_rank, W_init=W_init, device=device)\n    \n#     # Ensure parameters match exactly by copying from sk_linear to sk_linear_triton\n#     with torch.no_grad():\n#         sk_linear_triton.S1s.copy_(sk_linear.S1s)\n#         sk_linear_triton.S2s.copy_(sk_linear.S2s)\n#         sk_linear_triton.U1s.copy_(sk_linear.U1s)\n#         sk_linear_triton.U2s.copy_(sk_linear.U2s)\n#         sk_linear_triton.bias.copy_(sk_linear.bias)\n    \n#     # Create identical input\n#     input_data = torch.randn(batch_size, in_features, device=device, requires_grad=True)\n#     input_data_triton = input_data.clone().detach().requires_grad_(True)\n    \n#     # Forward pass\n#     output = sk_linear(input_data)\n#     output_triton = sk_linear_triton(input_data_triton)\n    \n#     # Check if forward outputs match\n#     forward_match = torch.allclose(output, output_triton, rtol=1e-4, atol=1e-5)\n#     print(f\"Forward outputs match: {forward_match}\")\n#     if not forward_match:\n#         max_diff = torch.max(torch.abs(output - output_triton))\n#         error_msg = f\"Forward outputs don't match. Max difference: {max_diff.item()}\"\n#         print(error_msg)\n#         if raise_error:\n#             assert forward_match, error_msg\n    \n#     # Create identical gradients\n#     grad_output = torch.randn_like(output)\n#     grad_output_triton = grad_output.clone()\n    \n#     # Backward pass\n#     output.backward(grad_output)\n#     output_triton.backward(grad_output_triton)\n    \n#     # Check if input gradients match\n#     input_grad_match = torch.allclose(input_data.grad, input_data_triton.grad, rtol=1e-4, atol=1e-5)\n#     print(f\"Input gradients match: {input_grad_match}\")\n#     if not input_grad_match:\n#         max_diff = torch.max(torch.abs(input_data.grad - input_data_triton.grad))\n#         error_msg = f\"Input gradients don't match. Max difference: {max_diff.item()}\"\n#         print(error_msg)\n#         if raise_error:\n#             assert input_grad_match, error_msg\n    \n#     # Check if S1s gradients match\n#     S1s_grad_match = torch.allclose(sk_linear.S1s.grad, sk_linear_triton.S1s.grad, rtol=1e-4, atol=1e-5)\n#     print(f\"S1s gradients match: {S1s_grad_match}\")\n#     if not S1s_grad_match:\n#         max_diff = torch.max(torch.abs(sk_linear.S1s.grad - sk_linear_triton.S1s.grad))\n#         error_msg = f\"S1s gradients don't match. Max difference: {max_diff.item()}\"\n#         print(error_msg)\n#         if raise_error:\n#             assert S1s_grad_match, error_msg\n    \n#     # Check if S2s gradients match\n#     S2s_grad_match = torch.allclose(sk_linear.S2s.grad, sk_linear_triton.S2s.grad, rtol=1e-4, atol=1e-5)\n#     print(f\"S2s gradients match: {S2s_grad_match}\")\n#     if not S2s_grad_match:\n#         max_diff = torch.max(torch.abs(sk_linear.S2s.grad - sk_linear_triton.S2s.grad))\n#         error_msg = f\"S2s gradients don't match. Max difference: {max_diff.item()}\"\n#         print(error_msg)\n#         if raise_error:\n#             assert S2s_grad_match, error_msg\n    \n#     # U1s and U2s are buffers, not parameters, so they may not have gradients\n#     # Only check if both gradients exist\n#     if hasattr(sk_linear.U1s, 'grad') and hasattr(sk_linear_triton.U1s, 'grad') and sk_linear.U1s.grad is not None and sk_linear_triton.U1s.grad is not None:\n#         U1s_grad_match = torch.allclose(sk_linear.U1s.grad, sk_linear_triton.U1s.grad, rtol=1e-4, atol=1e-5)\n#         print(f\"U1s gradients match: {U1s_grad_match}\")\n#         if not U1s_grad_match:\n#             max_diff = torch.max(torch.abs(sk_linear.U1s.grad - sk_linear_triton.U1s.grad))\n#             error_msg = f\"U1s gradients don't match. Max difference: {max_diff.item()}\"\n#             print(error_msg)\n#             if raise_error:\n#                 assert U1s_grad_match, error_msg\n#     else:\n#         print(\"U1s gradients not available - skipping comparison\")\n#         U1s_grad_match = True  # Skip this comparison\n    \n#     # Check if U2s gradients match - only if both exist\n#     if hasattr(sk_linear.U2s, 'grad') and hasattr(sk_linear_triton.U2s, 'grad') and sk_linear.U2s.grad is not None and sk_linear_triton.U2s.grad is not None:\n#         U2s_grad_match = torch.allclose(sk_linear.U2s.grad, sk_linear_triton.U2s.grad, rtol=1e-4, atol=1e-5)\n#         print(f\"U2s gradients match: {U2s_grad_match}\")\n#         if not U2s_grad_match:\n#             max_diff = torch.max(torch.abs(sk_linear.U2s.grad - sk_linear_triton.U2s.grad))\n#             error_msg = f\"U2s gradients don't match. Max difference: {max_diff.item()}\"\n#             print(error_msg)\n#             if raise_error:\n#                 assert U2s_grad_match, error_msg\n#     else:\n#         print(\"U2s gradients not available - skipping comparison\")\n#         U2s_grad_match = True  # Skip this comparison\n    \n#     # Check if bias gradients match\n#     bias_grad_match = torch.allclose(sk_linear.bias.grad, sk_linear_triton.bias.grad, rtol=1e-4, atol=1e-5)\n#     print(f\"Bias gradients match: {bias_grad_match}\")\n#     if not bias_grad_match:\n#         max_diff = torch.max(torch.abs(sk_linear.bias.grad - sk_linear_triton.bias.grad))\n#         error_msg = f\"Bias gradients don't match. Max difference: {max_diff.item()}\"\n#         print(error_msg)\n#         if raise_error:\n#             assert bias_grad_match, error_msg\n    \n#     # Return overall result\n#     all_matches = all([forward_match, input_grad_match, S1s_grad_match, S2s_grad_match, U1s_grad_match, U2s_grad_match, bias_grad_match])\n#     if raise_error:\n#         assert all_matches, \"At least one comparison failed. See detailed errors above.\"\n#     return all_matches\n\n\n# if __name__ == \"__main__\":\n#     print(\"Comparing SKLinear and SKLinear_triton implementations...\")\n    \n#     # Test with default parameters\n#     try:\n#         result = compare_linear_implementations()\n#         print(f\"All checks passed: {result}\")\n#     except AssertionError as e:\n#         print(f\"Default test failed: {e}\")\n    \n#     # Test with different parameters\n#     try:\n#         result_small = compare_linear_implementations(batch_size=32, in_features=64, out_features=32, num_terms=2, low_rank=4)\n#         print(f\"Small model checks passed: {result_small}\")\n#     except AssertionError as e:\n#         print(f\"Small model test failed: {e}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/panther/tests/run.py\nimport time\nimport numpy as np\nimport torch\nimport torch._dynamo\nimport torch._inductor.config as config\nimport itertools\nimport pandas as pd\nfrom panther.nn import SKLinear\n\n# Configure torch\nconfig.max_autotune_gemm = False\ntorch._dynamo.config.cache_size_limit = 2**16\ntorch._dynamo.config.accumulated_cache_size_limit = 2**16\n\ndef is_valid_params(in_features, out_features, num_terms, low_rank):\n    \"\"\"\n    Check if parameter combination is valid:\n    A combination is invalid if 2 * num_terms * low_rank * (out_features + in_features) >= out_features * in_features\n    \"\"\"\n    return 2 * num_terms * low_rank * (out_features + in_features) < out_features * in_features\n\nclass BenchmarkParams:\n    def __init__(self,\n                 in_features=256, \n                 out_features=256,\n                 num_terms=3,\n                 low_rank=8,\n                 batch_size=64, \n                 num_runs=200,\n                 warmup=15,\n                 device='cuda',\n                 dtype=torch.float32):\n        self.in_features = in_features\n        self.out_features = out_features\n        self.num_terms = num_terms\n        self.low_rank = low_rank\n        self.batch_size = batch_size\n        self.num_runs = num_runs\n        self.warmup = warmup\n        self.device = device\n        self.dtype = dtype\n\ndef benchmark_model(model, x, model_name, params):\n    \"\"\"\n    Generic benchmarking function for any PyTorch model.\n    \n    Args:\n        model: The PyTorch model to benchmark\n        x: Input tensor\n        model_name: Name of the model for logging\n        params: Benchmark parameters\n    \n    Returns:\n        Dictionary with benchmark results\n    \"\"\"\n    # Compile the model\n    model_compiled = torch.compile(\n        model,\n        backend=\"inductor\",\n        fullgraph=True,\n        dynamic=False\n    )\n    \n    # Benchmark forward pass\n    print(f\"\\n=== {model_name} FORWARD PASS BENCHMARK ===\")\n    \n    # Warmup runs for forward pass\n    # model_compiled.eval()\n    # with torch.no_grad():\n    #     for _ in range(params.warmup):\n    #         _ = model_compiled(x)\n    \n    # torch.cuda.synchronize()\n    \n    # Actual timed runs for forward\n    forward_times = []\n    # with torch.no_grad():\n    #     for _ in range(params.num_runs):\n    #         torch.cuda.synchronize()\n    #         start = time.perf_counter()\n    #         _ = model_compiled(x)\n    #         torch.cuda.synchronize()\n    #         end = time.perf_counter()\n            \n    #         forward_times.append((end - start) * 1000)  # Convert to ms\n    \n    # mean_forward = np.mean(forward_times)\n    # std_forward = np.std(forward_times)\n    mean_forward = 0\n    std_forward = 0\n    print(f\"{model_name} forward: {mean_forward:.3f}  {std_forward:.3f} ms\")\n    \n    # Benchmark backward pass\n    # print(f\"\\n=== {model_name} BACKWARD PASS BENCHMARK ===\")\n\n    def infer():\n        # x_to_use = x.clone().detach().to('cuda')\n        # x_to_use.requires_grad_(True)\n        x_to_use = x\n\n        out = model_compiled(x_to_use)\n        loss = out.sum()\n        \n        torch.cuda.synchronize()\n        start = time.perf_counter()\n        loss.backward()\n        torch.cuda.synchronize()\n        end = time.perf_counter()\n        \n        # model_compiled.zero_grad(set_to_none=True)\n        # x_to_use.grad.zero_()\n        # x_to_use = x_to_use.detach().requires_grad_(True)\n        # torch.cuda.empty_cache()\n\n        return ((end - start) * 1000)\n    \n    # Warmup runs for backward pass\n    model_compiled.train()\n    for _ in range(params.warmup):\n       infer()\n    \n    torch.cuda.synchronize()\n    \n    # Actual timed runs for backward\n    backward_times = []\n    for _ in range(params.num_runs):\n        backward_times.append(infer())\n    \n    mean_backward = np.mean(backward_times)\n    std_backward = np.std(backward_times)\n    print(f\"{model_name} backward: {mean_backward:.3f}  {std_backward:.3f} ms\")\n    \n    return {\n        \"forward\": {\n            \"mean\": mean_forward,\n            \"std\": std_forward,\n            \"times\": forward_times\n        },\n        \"backward\": {\n            \"mean\": mean_backward,\n            \"std\": std_backward,\n            \"times\": backward_times\n        }\n    }\n\ndef benchmark_model_factory(model_factory, model_name, params):\n    \"\"\"\n    Benchmark a model using a factory function.\n    \n    Args:\n        model_factory: Function that creates the model\n        model_name: Name of the model for logging\n        params: Benchmark parameters\n    \n    Returns:\n        Dictionary with benchmark results\n    \"\"\"\n    # Create the model\n    torch.manual_seed(42)\n    model = model_factory(params)\n    \n    # Create input tensor for benchmarking\n    x = torch.randn(params.batch_size, params.in_features, \n                  dtype=params.dtype, device=params.device, requires_grad=True)\n    \n    return benchmark_model(model, x, model_name, params)\n\nif __name__ == \"__main__\":\n    import torch.nn as nn\n    from panther.nn import SKLinear, SKLinear_triton\n    \n    # Parameter combinations to test\n    ratios = [(1, 128), (128, 1), (1, 1), (2, 1), (1, 2)]\n    base_sizes = [256, 512, 1024, 8192, 16384]\n    num_terms_options = [1, 2, 3]\n    # low_rank_options = [16, 32, 64, 128]\n    low_rank_options = [32, 64, 128]\n    \n    # Define model factories\n    def create_sklinear_triton(p):\n        return SKLinear_triton(p.in_features, p.out_features, \n                             p.num_terms, p.low_rank, \n                             dtype=p.dtype, device=p.device)\n    \n    models_to_benchmark = [\n        (create_sklinear_triton, \"SKLinear_triton\")\n    ]\n    \n    # Prepare data structure to store all results\n    results_data = []\n    \n    # Iterate through all parameter combinations\n    total_combinations = len(ratios) * len(base_sizes) * len(num_terms_options) * len(low_rank_options)\n    current_combo = 0\n    \n    for ratio, base_size in itertools.product(ratios, base_sizes):\n        ratio_in, ratio_out = ratio\n        \n        # Calculate actual dimensions based on ratio and base size\n        if ratio_in == 1:\n            in_features = base_size\n            out_features = base_size * ratio_out\n        else:\n            out_features = base_size\n            in_features = base_size * ratio_in\n        \n        for num_terms, low_rank in itertools.product(num_terms_options, low_rank_options):\n            current_combo += 1\n            print(f\"\\n\\n{'='*20} COMBINATION {current_combo}/{total_combinations} {'='*20}\")\n            print(f\"In features: {in_features}, Out features: {out_features}, Ratio: {ratio_in}:{ratio_out}\")\n            print(f\"Base size: {base_size}, Num terms: {num_terms}, Low rank: {low_rank}\")\n            \n            # Check if parameters are valid\n            is_valid = is_valid_params(in_features, out_features, num_terms, low_rank)\n            \n            if not is_valid:\n                print(f\"INVALID COMBINATION: 2 * {num_terms} * {low_rank} * ({out_features} + {in_features}) >= {out_features} * {in_features}\")\n                print(\"Skipping benchmarks for this invalid combination\")\n                \n                # Add invalid entry to results data\n                for model_name in [m[1] for m in models_to_benchmark]:\n                    results_data.append({\n                        'model': model_name,\n                        'in_features': in_features,\n                        'out_features': out_features,\n                        'ratio': f\"{ratio_in}:{ratio_out}\",\n                        'base_size': base_size,\n                        'num_terms': num_terms,\n                        'low_rank': low_rank,\n                        'forward_mean_ms': float('nan'),\n                        'forward_std_ms': float('nan'),\n                        'backward_mean_ms': float('nan'),\n                        'backward_std_ms': float('nan'),\n                        'is_valid': False,\n                        'error': \"Invalid parameter combination\"\n                    })\n                continue\n            \n            # Create parameter object for this combination\n            params = BenchmarkParams(\n                in_features=in_features,\n                out_features=out_features,\n                num_terms=num_terms,\n                low_rank=low_rank\n            )\n            \n            all_results = {}\n            for model_factory, model_name in models_to_benchmark:\n                print(f\"\\n{'='*20} Benchmarking {model_name} {'='*20}\")\n                try:\n                    results = benchmark_model_factory(model_factory, model_name, params)\n                    all_results[model_name] = results\n                    \n                    # Add result to our data collection\n                    results_data.append({\n                        'model': model_name,\n                        'in_features': in_features,\n                        'out_features': out_features,\n                        'ratio': f\"{ratio_in}:{ratio_out}\",\n                        'base_size': base_size,\n                        'num_terms': num_terms,\n                        'low_rank': low_rank,\n                        'forward_mean_ms': results['forward']['mean'],\n                        'forward_std_ms': results['forward']['std'],\n                        'backward_mean_ms': results['backward']['mean'],\n                        'backward_std_ms': results['backward']['std'],\n                        'is_valid': True\n                    })\n                except Exception as e:\n                    print(f\"Error benchmarking {model_name}: {e}\")\n                    # Add error entry to data\n                    results_data.append({\n                        'model': model_name,\n                        'in_features': in_features,\n                        'out_features': out_features,\n                        'ratio': f\"{ratio_in}:{ratio_out}\",\n                        'base_size': base_size,\n                        'num_terms': num_terms,\n                        'low_rank': low_rank,\n                        'forward_mean_ms': float('nan'),\n                        'forward_std_ms': float('nan'),\n                        'backward_mean_ms': float('nan'),\n                        'backward_std_ms': float('nan'),\n                        'is_valid': True,\n                        'error': str(e)\n                    })\n            \n            # Print comparative summary for this combination\n            if all_results:\n                print(\"\\n\" + \"=\"*60)\n                print(f\"{'='*20} SUMMARY FOR CURRENT COMBINATION {'='*20}\")\n                print(\"=\"*60)\n                print(f\"{'Model':<20} {'Forward (ms)':<25} {'Backward (ms)':<25}\")\n                print(\"-\"*60)\n                \n                for model_name, results in all_results.items():\n                    fwd = f\"{results['forward']['mean']:.3f}  {results['forward']['std']:.3f}\"\n                    bwd = f\"{results['backward']['mean']:.3f}  {results['backward']['std']:.3f}\"\n                    print(f\"{model_name:<20} {fwd:<25} {bwd:<25}\")\n    \n    # Create a DataFrame with all results\n    df = pd.DataFrame(results_data)\n    \n    # Save results to CSV\n    results_file = \"benchmark_results.csv\"\n    df.to_csv(results_file, index=False)\n    print(f\"\\nAll benchmark results saved to {results_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:50:55.272147Z","iopub.execute_input":"2025-05-05T16:50:55.272627Z","iopub.status.idle":"2025-05-05T16:50:55.285568Z","shell.execute_reply.started":"2025-05-05T16:50:55.272604Z","shell.execute_reply":"2025-05-05T16:50:55.284975Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/panther/tests/run.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/panther/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ['TORCH_USE_CUDA_DSA'] = \"1\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!PYTHONPATH=/kaggle/working/panther python /kaggle/working/panther/tests/run.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:51:47.056600Z","iopub.execute_input":"2025-05-05T16:51:47.057145Z","iopub.status.idle":"2025-05-05T16:56:07.821369Z","shell.execute_reply.started":"2025-05-05T16:51:47.057118Z","shell.execute_reply":"2025-05-05T16:56:07.820367Z"}},"outputs":[{"name":"stdout","text":"\n\n==================== COMBINATION 1/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.745  0.766 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.745  0.766            \n\n\n==================== COMBINATION 2/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.369  0.026 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.369  0.026            \n\n\n==================== COMBINATION 3/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 1, Low rank: 128\nINVALID COMBINATION: 2 * 1 * 128 * (32768 + 256) >= 32768 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 4/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.356  0.038 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.356  0.038            \n\n\n==================== COMBINATION 5/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 2, Low rank: 64\nINVALID COMBINATION: 2 * 2 * 64 * (32768 + 256) >= 32768 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 6/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (32768 + 256) >= 32768 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 7/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.489  0.051 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.489  0.051            \n\n\n==================== COMBINATION 8/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (32768 + 256) >= 32768 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 9/225 ====================\nIn features: 256, Out features: 32768, Ratio: 1:128\nBase size: 256, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (32768 + 256) >= 32768 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 10/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.307  0.059 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.307  0.059            \n\n\n==================== COMBINATION 11/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.452  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.452  0.048            \n\n\n==================== COMBINATION 12/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.754  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.754  0.048            \n\n\n==================== COMBINATION 13/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.450  0.040 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.450  0.040            \n\n\n==================== COMBINATION 14/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.761  0.032 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.761  0.032            \n\n\n==================== COMBINATION 15/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (65536 + 512) >= 65536 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 16/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.615  0.050 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.615  0.050            \n\n\n==================== COMBINATION 17/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 5.271  0.054 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             5.271  0.054            \n\n\n==================== COMBINATION 18/225 ====================\nIn features: 512, Out features: 65536, Ratio: 1:128\nBase size: 512, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (65536 + 512) >= 65536 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 19/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 8.379  0.042 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             8.379  0.042            \n\n\n==================== COMBINATION 20/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 8.552  0.017 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             8.552  0.017            \n\n\n==================== COMBINATION 21/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 9.318  0.075 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             9.318  0.075            \n\n\n==================== COMBINATION 22/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 8.624  0.039 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             8.624  0.039            \n\n\n==================== COMBINATION 23/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 9.315  0.077 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             9.315  0.077            \n\n\n==================== COMBINATION 24/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 11.540  0.200 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             11.540  0.200           \n\n\n==================== COMBINATION 25/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 8.944  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             8.944  0.047            \n\n\n==================== COMBINATION 26/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 10.469  0.101 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             10.469  0.101           \n\n\n==================== COMBINATION 27/225 ====================\nIn features: 1024, Out features: 131072, Ratio: 1:128\nBase size: 1024, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 13.844  0.387 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             13.844  0.387           \n\n\n==================== COMBINATION 28/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.47 GiB is free. Process 83045 has 278.00 MiB memory in use. Of the allocated memory 137.12 MiB is allocated by PyTorch, and 12.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 29/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.34 GiB is free. Process 83045 has 404.00 MiB memory in use. Of the allocated memory 266.12 MiB is allocated by PyTorch, and 9.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 30/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.09 GiB is free. Process 83045 has 660.00 MiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 7.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 31/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.34 GiB is free. Process 83045 has 404.00 MiB memory in use. Of the allocated memory 266.12 MiB is allocated by PyTorch, and 9.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 32/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.09 GiB is free. Process 83045 has 660.00 MiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 7.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 33/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.09 GiB is free. Process 83045 has 1.64 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 515.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 34/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.14 GiB memory in use. Of the allocated memory 396.12 MiB is allocated by PyTorch, and 647.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 35/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.84 GiB is free. Process 83045 has 1.89 GiB memory in use. Of the allocated memory 782.12 MiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 36/225 ====================\nIn features: 8192, Out features: 1048576, Ratio: 1:128\nBase size: 8192, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.59 GiB is free. Process 83045 has 2.14 GiB memory in use. Of the allocated memory 1.52 GiB is allocated by PyTorch, and 511.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 37/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.09 GiB is free. Process 83045 has 660.00 MiB memory in use. Of the allocated memory 266.12 MiB is allocated by PyTorch, and 265.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 38/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.09 GiB is free. Process 83045 has 660.00 MiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 7.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 39/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.09 GiB is free. Process 83045 has 1.64 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 515.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 40/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.14 GiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 519.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 41/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.09 GiB is free. Process 83045 has 1.64 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 515.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 42/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.09 GiB is free. Process 83045 has 2.64 GiB memory in use. Of the allocated memory 2.02 GiB is allocated by PyTorch, and 507.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 43/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.59 GiB is free. Process 83045 has 2.14 GiB memory in use. Of the allocated memory 782.12 MiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 44/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 11.09 GiB is free. Process 83045 has 3.64 GiB memory in use. Of the allocated memory 1.52 GiB is allocated by PyTorch, and 2.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 45/225 ====================\nIn features: 16384, Out features: 2097152, Ratio: 1:128\nBase size: 16384, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 10.59 GiB is free. Process 83045 has 4.14 GiB memory in use. Of the allocated memory 3.03 GiB is allocated by PyTorch, and 1011.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 46/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.956  0.041 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.956  0.041            \n\n\n==================== COMBINATION 47/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.438  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.438  0.048            \n\n\n==================== COMBINATION 48/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 1, Low rank: 128\nINVALID COMBINATION: 2 * 1 * 128 * (256 + 32768) >= 256 * 32768\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 49/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.126  0.052 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.126  0.052            \n\n\n==================== COMBINATION 50/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 2, Low rank: 64\nINVALID COMBINATION: 2 * 2 * 64 * (256 + 32768) >= 256 * 32768\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 51/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (256 + 32768) >= 256 * 32768\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 52/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.257  0.046 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.257  0.046            \n\n\n==================== COMBINATION 53/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (256 + 32768) >= 256 * 32768\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 54/225 ====================\nIn features: 32768, Out features: 256, Ratio: 128:1\nBase size: 256, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (256 + 32768) >= 256 * 32768\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 55/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 5.600  0.044 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             5.600  0.044            \n\n\n==================== COMBINATION 56/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 6.548  0.036 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             6.548  0.036            \n\n\n==================== COMBINATION 57/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 7.360  0.122 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             7.360  0.122            \n\n\n==================== COMBINATION 58/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 5.893  0.040 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             5.893  0.040            \n\n\n==================== COMBINATION 59/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 7.073  0.039 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             7.073  0.039            \n\n\n==================== COMBINATION 60/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (512 + 65536) >= 512 * 65536\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 61/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 6.145  0.038 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             6.145  0.038            \n\n\n==================== COMBINATION 62/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 5.308  0.065 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             5.308  0.065            \n\n\n==================== COMBINATION 63/225 ====================\nIn features: 65536, Out features: 512, Ratio: 128:1\nBase size: 512, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (512 + 65536) >= 512 * 65536\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 64/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 10.821  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             10.821  0.048           \n\n\n==================== COMBINATION 65/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 12.668  0.042 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             12.668  0.042           \n\n\n==================== COMBINATION 66/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 14.491  0.065 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             14.491  0.065           \n\n\n==================== COMBINATION 67/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 11.358  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             11.358  0.047           \n\n\n==================== COMBINATION 68/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 13.980  0.142 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             13.980  0.142           \n\n\n==================== COMBINATION 69/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 12.904  0.369 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             12.904  0.369           \n\n\n==================== COMBINATION 70/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 12.146  0.161 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             12.146  0.161           \n\n\n==================== COMBINATION 71/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 10.919  0.097 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             10.919  0.097           \n\n\n==================== COMBINATION 72/225 ====================\nIn features: 131072, Out features: 1024, Ratio: 128:1\nBase size: 1024, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 18.749  0.244 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             18.749  0.244           \n\n\n==================== COMBINATION 73/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.15 GiB memory in use. Of the allocated memory 137.12 MiB is allocated by PyTorch, and 908.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 74/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.15 GiB memory in use. Of the allocated memory 266.12 MiB is allocated by PyTorch, and 777.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 75/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.15 GiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 519.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 76/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.15 GiB memory in use. Of the allocated memory 266.12 MiB is allocated by PyTorch, and 777.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 77/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 14.09 GiB is free. Process 83045 has 664.00 MiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 7.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 78/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.09 GiB is free. Process 83045 has 1.65 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 515.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 79/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.15 GiB memory in use. Of the allocated memory 396.12 MiB is allocated by PyTorch, and 647.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 80/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.84 GiB is free. Process 83045 has 1.90 GiB memory in use. Of the allocated memory 782.12 MiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 81/225 ====================\nIn features: 1048576, Out features: 8192, Ratio: 128:1\nBase size: 8192, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.34 GiB is free. Process 83045 has 2.40 GiB memory in use. Of the allocated memory 1.52 GiB is allocated by PyTorch, and 767.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 82/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.84 GiB is free. Process 83045 has 920.00 MiB memory in use. Of the allocated memory 266.12 MiB is allocated by PyTorch, and 521.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 83/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.84 GiB is free. Process 83045 has 920.00 MiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 263.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 84/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.84 GiB is free. Process 83045 has 1.90 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 771.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 85/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 13.59 GiB is free. Process 83045 has 1.15 GiB memory in use. Of the allocated memory 524.12 MiB is allocated by PyTorch, and 519.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 86/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.59 GiB is free. Process 83045 has 2.15 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 87/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 11.59 GiB is free. Process 83045 has 3.15 GiB memory in use. Of the allocated memory 2.02 GiB is allocated by PyTorch, and 1019.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 88/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 11.59 GiB is free. Process 83045 has 3.15 GiB memory in use. Of the allocated memory 782.12 MiB is allocated by PyTorch, and 2.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 89/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 12.09 GiB is free. Process 83045 has 2.65 GiB memory in use. Of the allocated memory 1.52 GiB is allocated by PyTorch, and 1023.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 90/225 ====================\nIn features: 2097152, Out features: 16384, Ratio: 128:1\nBase size: 16384, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\nError benchmarking SKLinear_triton: CUDA out of memory. Tried to allocate 128.00 GiB. GPU 0 has a total capacity of 14.74 GiB of which 10.59 GiB is free. Process 83045 has 4.15 GiB memory in use. Of the allocated memory 3.03 GiB is allocated by PyTorch, and 1011.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\n==================== COMBINATION 91/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.651  0.222 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.651  0.222            \n\n\n==================== COMBINATION 92/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 1, Low rank: 64\nINVALID COMBINATION: 2 * 1 * 64 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 93/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 1, Low rank: 128\nINVALID COMBINATION: 2 * 1 * 128 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 94/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 2, Low rank: 32\nINVALID COMBINATION: 2 * 2 * 32 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 95/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 2, Low rank: 64\nINVALID COMBINATION: 2 * 2 * 64 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 96/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 97/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 3, Low rank: 32\nINVALID COMBINATION: 2 * 3 * 32 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 98/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 99/225 ====================\nIn features: 256, Out features: 256, Ratio: 1:1\nBase size: 256, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (256 + 256) >= 256 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 100/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.600  0.053 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.600  0.053            \n\n\n==================== COMBINATION 101/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.585  0.089 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.585  0.089            \n\n\n==================== COMBINATION 102/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 1, Low rank: 128\nINVALID COMBINATION: 2 * 1 * 128 * (512 + 512) >= 512 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 103/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.583  0.038 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.583  0.038            \n\n\n==================== COMBINATION 104/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 2, Low rank: 64\nINVALID COMBINATION: 2 * 2 * 64 * (512 + 512) >= 512 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 105/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (512 + 512) >= 512 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 106/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.571  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.571  0.047            \n\n\n==================== COMBINATION 107/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (512 + 512) >= 512 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 108/225 ====================\nIn features: 512, Out features: 512, Ratio: 1:1\nBase size: 512, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (512 + 512) >= 512 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 109/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.535  0.041 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.535  0.041            \n\n\n==================== COMBINATION 110/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.580  0.037 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.580  0.037            \n\n\n==================== COMBINATION 111/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.593  0.022 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.593  0.022            \n\n\n==================== COMBINATION 112/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.570  0.027 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.570  0.027            \n\n\n==================== COMBINATION 113/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.586  0.022 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.586  0.022            \n\n\n==================== COMBINATION 114/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (1024 + 1024) >= 1024 * 1024\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 115/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.540  0.039 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.540  0.039            \n\n\n==================== COMBINATION 116/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.518  0.034 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.518  0.034            \n\n\n==================== COMBINATION 117/225 ====================\nIn features: 1024, Out features: 1024, Ratio: 1:1\nBase size: 1024, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (1024 + 1024) >= 1024 * 1024\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 118/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.289  0.087 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.289  0.087            \n\n\n==================== COMBINATION 119/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.213  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.213  0.047            \n\n\n==================== COMBINATION 120/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.342  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.342  0.047            \n\n\n==================== COMBINATION 121/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.195  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.195  0.047            \n\n\n==================== COMBINATION 122/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.336  0.015 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.336  0.015            \n\n\n==================== COMBINATION 123/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.773  0.057 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.773  0.057            \n\n\n==================== COMBINATION 124/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.273  0.037 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.273  0.037            \n\n\n==================== COMBINATION 125/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.567  0.060 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.567  0.060            \n\n\n==================== COMBINATION 126/225 ====================\nIn features: 8192, Out features: 8192, Ratio: 1:1\nBase size: 8192, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.202  0.053 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.202  0.053            \n\n\n==================== COMBINATION 127/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.991  0.020 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.991  0.020            \n\n\n==================== COMBINATION 128/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.148  0.060 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.148  0.060            \n\n\n==================== COMBINATION 129/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.483  0.046 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.483  0.046            \n\n\n==================== COMBINATION 130/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.116  0.049 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.116  0.049            \n\n\n==================== COMBINATION 131/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.471  0.054 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.471  0.054            \n\n\n==================== COMBINATION 132/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.283  0.046 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.283  0.046            \n\n\n==================== COMBINATION 133/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.275  0.107 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.275  0.107            \n\n\n==================== COMBINATION 134/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.869  0.138 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.869  0.138            \n\n\n==================== COMBINATION 135/225 ====================\nIn features: 16384, Out features: 16384, Ratio: 1:1\nBase size: 16384, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.146  0.054 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.146  0.054            \n\n\n==================== COMBINATION 136/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.530  0.037 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.530  0.037            \n\n\n==================== COMBINATION 137/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.505  0.027 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.505  0.027            \n\n\n==================== COMBINATION 138/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 1, Low rank: 128\nINVALID COMBINATION: 2 * 1 * 128 * (256 + 512) >= 256 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 139/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.529  0.042 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.529  0.042            \n\n\n==================== COMBINATION 140/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 2, Low rank: 64\nINVALID COMBINATION: 2 * 2 * 64 * (256 + 512) >= 256 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 141/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (256 + 512) >= 256 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 142/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 3, Low rank: 32\nINVALID COMBINATION: 2 * 3 * 32 * (256 + 512) >= 256 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 143/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (256 + 512) >= 256 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 144/225 ====================\nIn features: 512, Out features: 256, Ratio: 2:1\nBase size: 256, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (256 + 512) >= 256 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 145/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.584  0.025 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.584  0.025            \n\n\n==================== COMBINATION 146/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.517  0.046 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.517  0.046            \n\n\n==================== COMBINATION 147/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.556  0.044 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.556  0.044            \n\n\n==================== COMBINATION 148/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.495  0.037 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.495  0.037            \n\n\n==================== COMBINATION 149/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.493  0.028 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.493  0.028            \n\n\n==================== COMBINATION 150/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (512 + 1024) >= 512 * 1024\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 151/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.502  0.052 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.502  0.052            \n\n\n==================== COMBINATION 152/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (512 + 1024) >= 512 * 1024\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 153/225 ====================\nIn features: 1024, Out features: 512, Ratio: 2:1\nBase size: 512, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (512 + 1024) >= 512 * 1024\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 154/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.546  0.043 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.546  0.043            \n\n\n==================== COMBINATION 155/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.563  0.039 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.563  0.039            \n\n\n==================== COMBINATION 156/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.607  0.020 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.607  0.020            \n\n\n==================== COMBINATION 157/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.591  0.021 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.591  0.021            \n\n\n==================== COMBINATION 158/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.543  0.032 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.543  0.032            \n\n\n==================== COMBINATION 159/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.570  0.031 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.570  0.031            \n\n\n==================== COMBINATION 160/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.611  0.025 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.611  0.025            \n\n\n==================== COMBINATION 161/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.776  0.034 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.776  0.034            \n\n\n==================== COMBINATION 162/225 ====================\nIn features: 2048, Out features: 1024, Ratio: 2:1\nBase size: 1024, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (1024 + 2048) >= 1024 * 2048\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 163/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.551  0.180 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.551  0.180            \n\n\n==================== COMBINATION 164/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.576  0.016 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.576  0.016            \n\n\n==================== COMBINATION 165/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.848  0.018 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.848  0.018            \n\n\n==================== COMBINATION 166/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.586  0.052 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.586  0.052            \n\n\n==================== COMBINATION 167/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.851  0.046 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.851  0.046            \n\n\n==================== COMBINATION 168/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.554  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.554  0.048            \n\n\n==================== COMBINATION 169/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.739  0.067 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.739  0.067            \n\n\n==================== COMBINATION 170/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.196  0.043 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.196  0.043            \n\n\n==================== COMBINATION 171/225 ====================\nIn features: 16384, Out features: 8192, Ratio: 2:1\nBase size: 8192, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.320  0.068 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.320  0.068            \n\n\n==================== COMBINATION 172/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.731  0.054 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.731  0.054            \n\n\n==================== COMBINATION 173/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.879  0.088 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.879  0.088            \n\n\n==================== COMBINATION 174/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.520  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.520  0.048            \n\n\n==================== COMBINATION 175/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.950  0.173 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.950  0.173            \n\n\n==================== COMBINATION 176/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.473  0.034 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.473  0.034            \n\n\n==================== COMBINATION 177/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.898  0.055 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.898  0.055            \n\n\n==================== COMBINATION 178/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.240  0.205 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.240  0.205            \n\n\n==================== COMBINATION 179/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.197  0.047 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.197  0.047            \n\n\n==================== COMBINATION 180/225 ====================\nIn features: 32768, Out features: 16384, Ratio: 2:1\nBase size: 16384, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 6.629  0.073 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             6.629  0.073            \n\n\n==================== COMBINATION 181/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.548  0.040 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.548  0.040            \n\n\n==================== COMBINATION 182/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.511  0.036 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.511  0.036            \n\n\n==================== COMBINATION 183/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 1, Low rank: 128\nINVALID COMBINATION: 2 * 1 * 128 * (512 + 256) >= 512 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 184/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.566  0.035 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.566  0.035            \n\n\n==================== COMBINATION 185/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 2, Low rank: 64\nINVALID COMBINATION: 2 * 2 * 64 * (512 + 256) >= 512 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 186/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (512 + 256) >= 512 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 187/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 3, Low rank: 32\nINVALID COMBINATION: 2 * 3 * 32 * (512 + 256) >= 512 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 188/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (512 + 256) >= 512 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 189/225 ====================\nIn features: 256, Out features: 512, Ratio: 1:2\nBase size: 256, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (512 + 256) >= 512 * 256\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 190/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.521  0.042 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.521  0.042            \n\n\n==================== COMBINATION 191/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.496  0.026 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.496  0.026            \n\n\n==================== COMBINATION 192/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.531  0.034 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.531  0.034            \n\n\n==================== COMBINATION 193/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.569  0.029 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.569  0.029            \n\n\n==================== COMBINATION 194/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.518  0.035 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.518  0.035            \n\n\n==================== COMBINATION 195/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 2, Low rank: 128\nINVALID COMBINATION: 2 * 2 * 128 * (1024 + 512) >= 1024 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 196/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.514  0.043 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.514  0.043            \n\n\n==================== COMBINATION 197/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 3, Low rank: 64\nINVALID COMBINATION: 2 * 3 * 64 * (1024 + 512) >= 1024 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 198/225 ====================\nIn features: 512, Out features: 1024, Ratio: 1:2\nBase size: 512, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (1024 + 512) >= 1024 * 512\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 199/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.629  0.018 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.629  0.018            \n\n\n==================== COMBINATION 200/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.691  0.031 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.691  0.031            \n\n\n==================== COMBINATION 201/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.635  0.034 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.635  0.034            \n\n\n==================== COMBINATION 202/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.510  0.035 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.510  0.035            \n\n\n==================== COMBINATION 203/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.554  0.056 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.554  0.056            \n\n\n==================== COMBINATION 204/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.818  0.077 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.818  0.077            \n\n\n==================== COMBINATION 205/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.547  0.021 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.547  0.021            \n\n\n==================== COMBINATION 206/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 0.652  0.110 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             0.652  0.110            \n\n\n==================== COMBINATION 207/225 ====================\nIn features: 1024, Out features: 2048, Ratio: 1:2\nBase size: 1024, Num terms: 3, Low rank: 128\nINVALID COMBINATION: 2 * 3 * 128 * (2048 + 1024) >= 2048 * 1024\nSkipping benchmarks for this invalid combination\n\n\n==================== COMBINATION 208/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.721  0.168 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.721  0.168            \n\n\n==================== COMBINATION 209/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.722  0.019 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.722  0.019            \n\n\n==================== COMBINATION 210/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.954  0.054 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.954  0.054            \n\n\n==================== COMBINATION 211/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.735  0.040 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.735  0.040            \n\n\n==================== COMBINATION 212/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.946  0.061 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.946  0.061            \n\n\n==================== COMBINATION 213/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.498  0.063 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.498  0.063            \n\n\n==================== COMBINATION 214/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 1.840  0.049 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             1.840  0.049            \n\n\n==================== COMBINATION 215/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.236  0.043 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.236  0.043            \n\n\n==================== COMBINATION 216/225 ====================\nIn features: 8192, Out features: 16384, Ratio: 1:2\nBase size: 8192, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.073  0.051 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.073  0.051            \n\n\n==================== COMBINATION 217/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 1, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 2.948  0.028 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             2.948  0.028            \n\n\n==================== COMBINATION 218/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 1, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.131  0.048 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.131  0.048            \n\n\n==================== COMBINATION 219/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 1, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.634  0.051 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.634  0.051            \n\n\n==================== COMBINATION 220/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 2, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.154  0.041 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.154  0.041            \n\n\n==================== COMBINATION 221/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 2, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.645  0.050 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.645  0.050            \n\n\n==================== COMBINATION 222/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 2, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.777  0.126 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.777  0.126            \n\n\n==================== COMBINATION 223/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 3, Low rank: 32\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 3.460  0.169 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             3.460  0.169            \n\n\n==================== COMBINATION 224/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 3, Low rank: 64\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 4.294  0.258 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             4.294  0.258            \n\n\n==================== COMBINATION 225/225 ====================\nIn features: 16384, Out features: 32768, Ratio: 1:2\nBase size: 16384, Num terms: 3, Low rank: 128\n\n==================== Benchmarking SKLinear_triton ====================\n\n=== SKLinear_triton FORWARD PASS BENCHMARK ===\nSKLinear_triton forward: 0.000  0.000 ms\nSKLinear_triton backward: 6.022  0.053 ms\n\n============================================================\n==================== SUMMARY FOR CURRENT COMBINATION ====================\n============================================================\nModel                Forward (ms)              Backward (ms)            \n------------------------------------------------------------\nSKLinear_triton      0.000  0.000             6.022  0.053            \n\nAll benchmark results saved to benchmark_results.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# !CUDA_LAUNCH_BLOCKING=1 PYTHONPATH=/kaggle/working/panther python /kaggle/working/panther/tests/run.py","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}