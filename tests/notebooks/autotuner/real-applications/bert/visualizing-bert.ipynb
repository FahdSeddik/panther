{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:10.139161Z",
     "iopub.status.busy": "2025-05-10T02:28:10.138526Z",
     "iopub.status.idle": "2025-05-10T02:28:10.244229Z",
     "shell.execute_reply": "2025-05-10T02:28:10.243475Z",
     "shell.execute_reply.started": "2025-05-10T02:28:10.139135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "token = user_secrets.get_secret(\"github_repos_wildcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:10.245918Z",
     "iopub.status.busy": "2025-05-10T02:28:10.245599Z",
     "iopub.status.idle": "2025-05-10T02:28:10.249930Z",
     "shell.execute_reply": "2025-05-10T02:28:10.249271Z",
     "shell.execute_reply.started": "2025-05-10T02:28:10.245862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "repo_url = f\"https://{token}@github.com/gaserSami/panther.git\"\n",
    "branch = \"autotuner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:10.251253Z",
     "iopub.status.busy": "2025-05-10T02:28:10.250976Z",
     "iopub.status.idle": "2025-05-10T02:28:13.592148Z",
     "shell.execute_reply": "2025-05-10T02:28:13.591133Z",
     "shell.execute_reply.started": "2025-05-10T02:28:10.251223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Cloning into 'panther'...\nremote: Enumerating objects: 1301, done.\u001b[K\nremote: Counting objects: 100% (275/275), done.\u001b[K\nremote: Compressing objects: 100% (44/44), done.\u001b[K\nremote: Total 1301 (delta 249), reused 232 (delta 231), pack-reused 1026 (from 1)\u001b[K\nReceiving objects: 100% (1301/1301), 27.78 MiB | 18.53 MiB/s, done.\nResolving deltas: 100% (839/839), done.\n"
    }
   ],
   "source": [
    "!git clone -b {branch} {repo_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.594761Z",
     "iopub.status.busy": "2025-05-10T02:28:13.594314Z",
     "iopub.status.idle": "2025-05-10T02:28:13.598320Z",
     "shell.execute_reply": "2025-05-10T02:28:13.597531Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.594720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # First uninstall existing torch, torchvision, torchaudio\n",
    "# !pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# # Install the specified versions from PyTorch's official CUDA 12.4 wheels\n",
    "# !pip install torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.599450Z",
     "iopub.status.busy": "2025-05-10T02:28:13.599179Z",
     "iopub.status.idle": "2025-05-10T02:28:13.729331Z",
     "shell.execute_reply": "2025-05-10T02:28:13.728393Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.599426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mv panther Panther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.730674Z",
     "iopub.status.busy": "2025-05-10T02:28:13.730438Z",
     "iopub.status.idle": "2025-05-10T02:28:13.850275Z",
     "shell.execute_reply": "2025-05-10T02:28:13.849678Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.730650Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Panther\n"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.851246Z",
     "iopub.status.busy": "2025-05-10T02:28:13.851055Z",
     "iopub.status.idle": "2025-05-10T02:28:13.855424Z",
     "shell.execute_reply": "2025-05-10T02:28:13.854769Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.851227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%writefile /kaggle/working/Panther/pawX/setup.py\n",
    "# from setuptools import setup\n",
    "# from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n",
    "\n",
    "# setup(\n",
    "#     name=\"pawX\",\n",
    "#     ext_modules=[\n",
    "#         CUDAExtension(\n",
    "#             name=\"pawX\",\n",
    "#             sources=[\n",
    "#                 \"skops.cpp\",\n",
    "#                 \"bindings.cpp\",\n",
    "#                 \"linear.cpp\",\n",
    "#                 \"linear_cuda.cu\",\n",
    "#                 \"cqrrpt.cpp\",\n",
    "#                 \"rsvd.cpp\",\n",
    "#                 \"attention.cpp\",\n",
    "#                 \"conv2d.cpp\"\n",
    "#             ],\n",
    "#             # Use system includes and libraries\n",
    "#             include_dirs=[\"/usr/include/x86_64-linux-gnu\"],\n",
    "#             library_dirs=[],\n",
    "#             libraries=[\"openblas\"],\n",
    "#             extra_compile_args={\"cxx\": [\"-O2\", \"-fopenmp\"], \"nvcc\": [\"-O2\"]},\n",
    "#             extra_link_args=[\"-llapacke\", \"-lopenblas\"]\n",
    "#         )\n",
    "#     ],\n",
    "#     cmdclass={\"build_ext\": BuildExtension},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.856466Z",
     "iopub.status.busy": "2025-05-10T02:28:13.856188Z",
     "iopub.status.idle": "2025-05-10T02:28:13.866980Z",
     "shell.execute_reply": "2025-05-10T02:28:13.866190Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.856440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !sudo apt-get install liblapacke-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.868349Z",
     "iopub.status.busy": "2025-05-10T02:28:13.867775Z",
     "iopub.status.idle": "2025-05-10T02:28:13.876759Z",
     "shell.execute_reply": "2025-05-10T02:28:13.876125Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.868327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !cd /kaggle/working/Panther/pawX; python setup.py install\n",
    "# !cd /kaggle/working/Panther/pawX; pip install --no-build-isolation -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:13.879027Z",
     "iopub.status.busy": "2025-05-10T02:28:13.878606Z",
     "iopub.status.idle": "2025-05-10T02:28:18.620065Z",
     "shell.execute_reply": "2025-05-10T02:28:18.619195Z",
     "shell.execute_reply.started": "2025-05-10T02:28:13.879011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.5.1+cu124\n3.1.0\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "import triton\n",
    "\n",
    "print(triton.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:18.621850Z",
     "iopub.status.busy": "2025-05-10T02:28:18.621063Z",
     "iopub.status.idle": "2025-05-10T02:28:18.625574Z",
     "shell.execute_reply": "2025-05-10T02:28:18.624666Z",
     "shell.execute_reply.started": "2025-05-10T02:28:18.621831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/kaggle/working/Panther\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:18.626798Z",
     "iopub.status.busy": "2025-05-10T02:28:18.626532Z",
     "iopub.status.idle": "2025-05-10T02:28:18.764363Z",
     "shell.execute_reply": "2025-05-10T02:28:18.763651Z",
     "shell.execute_reply.started": "2025-05-10T02:28:18.626774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/kaggle/working/Panther\n"
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:28:45.227397Z",
     "iopub.status.busy": "2025-05-10T02:28:45.226647Z",
     "iopub.status.idle": "2025-05-10T02:29:57.226350Z",
     "shell.execute_reply": "2025-05-10T02:29:57.225194Z",
     "shell.execute_reply.started": "2025-05-10T02:28:45.227373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Collecting botorch\n  Downloading botorch-0.14.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.13.1)\nCollecting pyre_extensions (from botorch)\n  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\nCollecting gpytorch==1.14 (from botorch)\n  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\nCollecting linear_operator==0.6 (from botorch)\n  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.5.1+cu124)\nCollecting pyro-ppl>=1.8.4 (from botorch)\n  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.15.2)\nRequirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\nRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.6.0)\nCollecting jaxtyping (from gpytorch==1.14->botorch)\n  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.2.2)\nRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\nCollecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->botorch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.1->botorch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->botorch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->botorch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->botorch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.1->botorch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.1->botorch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\nRequirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyre_extensions->botorch) (0.9.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2.4.1)\nCollecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch==1.14->botorch)\n  Downloading wadler_lindig-0.1.5-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.4.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyre_extensions->botorch) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nDownloading botorch-0.14.0-py3-none-any.whl (738 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.3/738.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\nDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\nDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wadler_lindig-0.1.5-py3-none-any.whl (20 kB)\nInstalling collected packages: pyro-api, wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, pyre_extensions, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, linear_operator, pyro-ppl, gpytorch, botorch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botorch-0.14.0 gpytorch-1.14 jaxtyping-0.3.2 linear_operator-0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 wadler-lindig-0.1.5\n"
    }
   ],
   "source": [
    "!pip install botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T02:32:24.916372Z",
     "iopub.status.busy": "2025-05-10T02:32:24.915707Z",
     "iopub.status.idle": "2025-05-10T02:32:25.345717Z",
     "shell.execute_reply": "2025-05-10T02:32:25.344904Z",
     "shell.execute_reply.started": "2025-05-10T02:32:24.916332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loading BERT model for visualization...\nModel: BERT base uncased\nTotal trainable parameters: 109,514,298\n\n===== Linear Layer Parameters =====\nLayer: bert.encoder.layer.0.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.0.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.0.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.0.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.0.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.0.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.1.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.1.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.1.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.1.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.1.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.1.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.2.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.2.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.2.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.2.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.2.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.2.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.3.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.3.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.3.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.3.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.3.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.3.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.4.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.4.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.4.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.4.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.4.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.4.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.5.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.5.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.5.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.5.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.5.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.5.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.6.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.6.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.6.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.6.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.6.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.6.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.7.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.7.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.7.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.7.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.7.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.7.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.8.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.8.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.8.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.8.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.8.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.8.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.9.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.9.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.9.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.9.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.9.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.9.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.10.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.10.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.10.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.10.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.10.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.10.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.11.attention.self.query\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.11.attention.self.key\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.11.attention.self.value\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.11.attention.output.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: bert.encoder.layer.11.intermediate.dense\n  - in_features: 768\n  - out_features: 3072\n  - bias: True\n  - weight shape: torch.Size([3072, 768])\n  - bias shape: torch.Size([3072])\n----------------------------------------\nLayer: bert.encoder.layer.11.output.dense\n  - in_features: 3072\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 3072])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: cls.predictions.transform.dense\n  - in_features: 768\n  - out_features: 768\n  - bias: True\n  - weight shape: torch.Size([768, 768])\n  - bias shape: torch.Size([768])\n----------------------------------------\nLayer: cls.predictions.decoder\n  - in_features: 768\n  - out_features: 30522\n  - bias: True\n  - weight shape: torch.Size([30522, 768])\n  - bias shape: torch.Size([30522])\n----------------------------------------\n\nModel tree structure:\nmodel (BertForMaskedLM)/\n└─ bert (BertModel)/\n│   ├─ embeddings (BertEmbeddings)/\n│   │   ├─ LayerNorm (LayerNorm)\n│   │   ├─ dropout (Dropout)\n│   │   ├─ position_embeddings (Embedding)\n│   │   ├─ token_type_embeddings (Embedding)\n│   │   ├─ word_embeddings (Embedding)\n│   ├─ encoder (BertEncoder)/\n│       └─ layer (ModuleList)/\n│           └─ 0 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 1 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 10 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 11 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 2 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 3 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 4 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 5 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 6 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 7 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 8 (BertLayer)/\n│           │   ├─ attention (BertAttention)/\n│           │   │   ├─ output (BertSelfOutput)/\n│           │   │   │   ├─ LayerNorm (LayerNorm)\n│           │   │   │   ├─ dense (Linear)\n│           │   │   │   ├─ dropout (Dropout)\n│           │   │   ├─ self (BertSdpaSelfAttention)/\n│           │   │       └─ dropout (Dropout)\n│           │   │       └─ key (Linear)\n│           │   │       └─ query (Linear)\n│           │   │       └─ value (Linear)\n│           │   ├─ intermediate (BertIntermediate)/\n│           │   │   ├─ dense (Linear)\n│           │   │   ├─ intermediate_act_fn (GELUActivation)\n│           │   ├─ output (BertOutput)/\n│           │       └─ LayerNorm (LayerNorm)\n│           │       └─ dense (Linear)\n│           │       └─ dropout (Dropout)\n│           └─ 9 (BertLayer)/\n│               └─ attention (BertAttention)/\n│               │   ├─ output (BertSelfOutput)/\n│               │   │   ├─ LayerNorm (LayerNorm)\n│               │   │   ├─ dense (Linear)\n│               │   │   ├─ dropout (Dropout)\n│               │   ├─ self (BertSdpaSelfAttention)/\n│               │       └─ dropout (Dropout)\n│               │       └─ key (Linear)\n│               │       └─ query (Linear)\n│               │       └─ value (Linear)\n│               └─ intermediate (BertIntermediate)/\n│               │   ├─ dense (Linear)\n│               │   ├─ intermediate_act_fn (GELUActivation)\n│               └─ output (BertOutput)/\n│                   └─ LayerNorm (LayerNorm)\n│                   └─ dense (Linear)\n│                   └─ dropout (Dropout)\n└─ cls (BertOnlyMLMHead)/\n    └─ predictions (BertLMPredictionHead)/\n        └─ decoder (Linear)\n        └─ transform (BertPredictionHeadTransform)/\n            └─ LayerNorm (LayerNorm)\n            └─ dense (Linear)\n            └─ transform_act_fn (GELUActivation)\n\nCreating interactive visualization...\n\nVisualization saved to: bert_model_visualization.html\nThe visualization should have opened in your default web browser.\nIf not, you can open it manually by navigating to the file.\n\nUsing the visualization:\n- Hover over modules to see details like parameter counts\n- Click on modules to expand/collapse their children\n- Use the search box to find specific modules\n- The interactive interface allows exploring the entire model structure\n"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForMaskedLM\n",
    "from panther.tuner.SkAutoTuner.ModelVisualizer import ModelVisualizer\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def print_linear_layer_params(model):\n",
    "    \"\"\"\n",
    "    Print parameters of all Linear layers in the BERT model.\n",
    "    This provides detailed information about each Linear layer's configuration.\n",
    "    \"\"\"\n",
    "    print(\"\\n===== Linear Layer Parameters =====\")\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            print(f\"Layer: {name}\")\n",
    "            print(f\"  - in_features: {module.in_features}\")\n",
    "            print(f\"  - out_features: {module.out_features}\")\n",
    "            print(f\"  - bias: {module.bias is not None}\")\n",
    "            # Print shape information\n",
    "            weight_shape = module.weight.shape\n",
    "            print(f\"  - weight shape: {weight_shape}\")\n",
    "            if module.bias is not None:\n",
    "                bias_shape = module.bias.shape\n",
    "                print(f\"  - bias shape: {bias_shape}\")\n",
    "            print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "def visualize_bert_model():\n",
    "    \"\"\"\n",
    "    Load a BERT model and create an interactive visualization of its structure.\n",
    "    This function demonstrates how to use ModelVisualizer with a BERT model.\n",
    "    \"\"\"\n",
    "    print(\"Loading BERT model for visualization...\")\n",
    "\n",
    "    # Load BERT model\n",
    "    model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Print basic model information\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model: BERT base uncased\")\n",
    "    print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "    # Print details of all linear layers in the model\n",
    "    print_linear_layer_params(model)\n",
    "\n",
    "    # Print model tree structure in console\n",
    "    print(\"\\nModel tree structure:\")\n",
    "    ModelVisualizer.print_module_tree(model)\n",
    "\n",
    "    # Create an interactive visualization\n",
    "    print(\"\\nCreating interactive visualization...\")\n",
    "    output_path = ModelVisualizer.create_interactive_visualization(\n",
    "        model=model, output_path=\"bert_model_visualization.html\", open_browser=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nVisualization saved to: {output_path}\")\n",
    "    print(\"The visualization should have opened in your default web browser.\")\n",
    "    print(\"If not, you can open it manually by navigating to the file.\")\n",
    "\n",
    "    # Additional information about using the visualization\n",
    "    print(\"\\nUsing the visualization:\")\n",
    "    print(\"- Hover over modules to see details like parameter counts\")\n",
    "    print(\"- Click on modules to expand/collapse their children\")\n",
    "    print(\"- Use the search box to find specific modules\")\n",
    "    print(\"- The interactive interface allows exploring the entire model structure\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the visualization function\n",
    "    visualize_bert_model()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7295817,
     "sourceId": 11628705,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}