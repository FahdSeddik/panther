{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5def202",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-08T21:55:03.159542Z",
     "iopub.status.busy": "2025-05-08T21:55:03.159221Z",
     "iopub.status.idle": "2025-05-08T21:55:03.305814Z",
     "shell.execute_reply": "2025-05-08T21:55:03.305254Z"
    },
    "papermill": {
     "duration": 0.154086,
     "end_time": "2025-05-08T21:55:03.307114",
     "exception": false,
     "start_time": "2025-05-08T21:55:03.153028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "token = user_secrets.get_secret(\"github_repos_wildcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c04ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:55:03.316975Z",
     "iopub.status.busy": "2025-05-08T21:55:03.316755Z",
     "iopub.status.idle": "2025-05-08T21:55:03.319975Z",
     "shell.execute_reply": "2025-05-08T21:55:03.319454Z"
    },
    "papermill": {
     "duration": 0.00924,
     "end_time": "2025-05-08T21:55:03.321058",
     "exception": false,
     "start_time": "2025-05-08T21:55:03.311818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_url = f\"https://{token}@github.com/gaserSami/panther.git\"\n",
    "branch = \"autotuner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3112a141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:55:03.329815Z",
     "iopub.status.busy": "2025-05-08T21:55:03.329615Z",
     "iopub.status.idle": "2025-05-08T21:55:06.654299Z",
     "shell.execute_reply": "2025-05-08T21:55:06.653238Z"
    },
    "papermill": {
     "duration": 3.330692,
     "end_time": "2025-05-08T21:55:06.656001",
     "exception": false,
     "start_time": "2025-05-08T21:55:03.325309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'panther'...\r\n",
      "remote: Enumerating objects: 1221, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (356/356), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (197/197), done.\u001b[K\r\n",
      "remote: Total 1221 (delta 257), reused 215 (delta 150), pack-reused 865 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (1221/1221), 27.81 MiB | 19.57 MiB/s, done.\r\n",
      "Resolving deltas: 100% (758/758), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone -b {branch} {repo_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32a179c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:55:06.667212Z",
     "iopub.status.busy": "2025-05-08T21:55:06.666984Z",
     "iopub.status.idle": "2025-05-08T21:57:37.455222Z",
     "shell.execute_reply": "2025-05-08T21:57:37.454363Z"
    },
    "papermill": {
     "duration": 150.795617,
     "end_time": "2025-05-08T21:57:37.456941",
     "exception": false,
     "start_time": "2025-05-08T21:55:06.661324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1+cu124\r\n",
      "Uninstalling torch-2.5.1+cu124:\r\n",
      "  Successfully uninstalled torch-2.5.1+cu124\r\n",
      "Found existing installation: torchvision 0.20.1+cu124\r\n",
      "Uninstalling torchvision-0.20.1+cu124:\r\n",
      "  Successfully uninstalled torchvision-0.20.1+cu124\r\n",
      "Found existing installation: torchaudio 2.5.1+cu124\r\n",
      "Uninstalling torchaudio-2.5.1+cu124:\r\n",
      "  Successfully uninstalled torchaudio-2.5.1+cu124\r\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu124\r\n",
      "Collecting torch==2.6.0+cu124\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\r\n",
      "Collecting torchvision==0.21.0+cu124\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\r\n",
      "Collecting torchaudio==2.6.0+cu124\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (4.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting triton==3.2.0 (from torch==2.6.0+cu124)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (11.1.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cu124) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cu124) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.21.0+cu124) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.21.0+cu124) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\r\n",
      "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m899.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, torchvision\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.1.0\r\n",
      "    Uninstalling triton-3.1.0:\r\n",
      "      Successfully uninstalled triton-3.1.0\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu124 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0\r\n"
     ]
    }
   ],
   "source": [
    "# First uninstall existing torch, torchvision, torchaudio\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# Install the specified versions from PyTorch's official CUDA 12.4 wheels\n",
    "!pip install torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec5e885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:57:37.540472Z",
     "iopub.status.busy": "2025-05-08T21:57:37.540193Z",
     "iopub.status.idle": "2025-05-08T21:57:37.669551Z",
     "shell.execute_reply": "2025-05-08T21:57:37.668336Z"
    },
    "papermill": {
     "duration": 0.171308,
     "end_time": "2025-05-08T21:57:37.671036",
     "exception": false,
     "start_time": "2025-05-08T21:57:37.499728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv panther Panther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99eae71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:57:37.798799Z",
     "iopub.status.busy": "2025-05-08T21:57:37.798483Z",
     "iopub.status.idle": "2025-05-08T21:57:37.803012Z",
     "shell.execute_reply": "2025-05-08T21:57:37.802446Z"
    },
    "papermill": {
     "duration": 0.046417,
     "end_time": "2025-05-08T21:57:37.804035",
     "exception": false,
     "start_time": "2025-05-08T21:57:37.757618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "src = '/kaggle/working/Panther'\n",
    "dst = '/kaggle/working/panther'\n",
    "\n",
    "# Simple rename\n",
    "os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b4a2aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:57:37.885201Z",
     "iopub.status.busy": "2025-05-08T21:57:37.884990Z",
     "iopub.status.idle": "2025-05-08T21:57:37.890981Z",
     "shell.execute_reply": "2025-05-08T21:57:37.890360Z"
    },
    "papermill": {
     "duration": 0.048238,
     "end_time": "2025-05-08T21:57:37.892061",
     "exception": false,
     "start_time": "2025-05-08T21:57:37.843823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/panther/pawX/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/panther/pawX/setup.py\n",
    "from setuptools import setup\n",
    "from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n",
    "\n",
    "setup(\n",
    "    name=\"pawX\",\n",
    "    ext_modules=[\n",
    "        CUDAExtension(\n",
    "            name=\"pawX\",\n",
    "            sources=[\n",
    "                \"skops.cpp\",\n",
    "                \"bindings.cpp\",\n",
    "                \"linear.cpp\",\n",
    "                \"linear_cuda.cu\",\n",
    "                \"cqrrpt.cpp\",\n",
    "                \"rsvd.cpp\",\n",
    "                \"attention.cpp\",\n",
    "                \"conv2d.cpp\"\n",
    "            ],\n",
    "            # Use system includes and libraries\n",
    "            include_dirs=[\"/usr/include/x86_64-linux-gnu\"],\n",
    "            library_dirs=[],\n",
    "            libraries=[\"openblas\"],\n",
    "            extra_compile_args={\"cxx\": [\"-O2\", \"-fopenmp\"], \"nvcc\": [\"-O2\"]},\n",
    "            extra_link_args=[\"-llapacke\", \"-lopenblas\"]\n",
    "        )\n",
    "    ],\n",
    "    cmdclass={\"build_ext\": BuildExtension},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfaec78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:57:37.974944Z",
     "iopub.status.busy": "2025-05-08T21:57:37.974703Z",
     "iopub.status.idle": "2025-05-08T21:57:47.858274Z",
     "shell.execute_reply": "2025-05-08T21:57:47.857266Z"
    },
    "papermill": {
     "duration": 9.926356,
     "end_time": "2025-05-08T21:57:47.859822",
     "exception": false,
     "start_time": "2025-05-08T21:57:37.933466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  liblapacke libtmglib-dev libtmglib3\r\n",
      "Suggested packages:\r\n",
      "  liblapack-doc\r\n",
      "The following NEW packages will be installed:\r\n",
      "  liblapacke liblapacke-dev libtmglib-dev libtmglib3\r\n",
      "0 upgraded, 4 newly installed, 0 to remove and 122 not upgraded.\r\n",
      "Need to get 1,071 kB of archives.\r\n",
      "After this operation, 12.3 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtmglib3 amd64 3.10.0-2ubuntu1 [144 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblapacke amd64 3.10.0-2ubuntu1 [435 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtmglib-dev amd64 3.10.0-2ubuntu1 [134 kB]\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblapacke-dev amd64 3.10.0-2ubuntu1 [358 kB]\r\n",
      "Fetched 1,071 kB in 1s (1,000 kB/s)\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Selecting previously unselected package libtmglib3:amd64.\r\n",
      "(Reading database ... 128691 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libtmglib3_3.10.0-2ubuntu1_amd64.deb ...\r\n",
      "Unpacking libtmglib3:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Selecting previously unselected package liblapacke:amd64.\r\n",
      "Preparing to unpack .../liblapacke_3.10.0-2ubuntu1_amd64.deb ...\r\n",
      "Unpacking liblapacke:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Selecting previously unselected package libtmglib-dev:amd64.\r\n",
      "Preparing to unpack .../libtmglib-dev_3.10.0-2ubuntu1_amd64.deb ...\r\n",
      "Unpacking libtmglib-dev:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Selecting previously unselected package liblapacke-dev:amd64.\r\n",
      "Preparing to unpack .../liblapacke-dev_3.10.0-2ubuntu1_amd64.deb ...\r\n",
      "Unpacking liblapacke-dev:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Setting up libtmglib3:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Setting up liblapacke:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Setting up libtmglib-dev:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Setting up liblapacke-dev:amd64 (3.10.0-2ubuntu1) ...\r\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install liblapacke-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788934c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T21:57:47.944989Z",
     "iopub.status.busy": "2025-05-08T21:57:47.944730Z",
     "iopub.status.idle": "2025-05-08T22:00:26.905436Z",
     "shell.execute_reply": "2025-05-08T22:00:26.904579Z"
    },
    "papermill": {
     "duration": 159.005008,
     "end_time": "2025-05-08T22:00:26.907077",
     "exception": false,
     "start_time": "2025-05-08T21:57:47.902069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\r\n",
      "!!\r\n",
      "\r\n",
      "        ********************************************************************************\r\n",
      "        Please avoid running ``setup.py`` directly.\r\n",
      "        Instead, use pypa/build, pypa/installer or other\r\n",
      "        standards-based tools.\r\n",
      "\r\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\r\n",
      "        ********************************************************************************\r\n",
      "\r\n",
      "!!\r\n",
      "  self.initialize_options()\r\n",
      "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\r\n",
      "!!\r\n",
      "\r\n",
      "        ********************************************************************************\r\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\r\n",
      "        Instead, use pypa/build, pypa/installer or other\r\n",
      "        standards-based tools.\r\n",
      "\r\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\r\n",
      "        ********************************************************************************\r\n",
      "\r\n",
      "!!\r\n",
      "  self.initialize_options()\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\r\n",
      "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\r\n",
      "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\r\n",
      "  warnings.warn(\r\n",
      "Emitting ninja build file /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/build.ninja...\r\n",
      "Compiling objects...\r\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n",
      "[1/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/conv2d.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/conv2d.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/conv2d.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "/kaggle/working/panther/pawX/conv2d.cpp: In function ‘at::Tensor sketched_conv2d_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const std::vector<long int>&, const std::vector<long int>&, const std::vector<long int>&, const at::Tensor&)’:\r\n",
      "/kaggle/working/panther/pawX/conv2d.cpp:17:28: warning: unused variable ‘C’ [-Wunused-variable]\r\n",
      "   17 |     int64_t B = x.size(0), C = x.size(1), H = x.size(2), W = x.size(3);\r\n",
      "      |                            ^\r\n",
      "[2/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/linear.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/linear.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/linear.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "[3/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/cqrrpt.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/cqrrpt.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/cqrrpt.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "[4/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/bindings.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/bindings.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/bindings.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "In file included from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/Exceptions.h:12,\r\n",
      "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/python.h:11,\r\n",
      "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:9,\r\n",
      "                 from /kaggle/working/panther/pawX/attention.h:3,\r\n",
      "                 from /kaggle/working/panther/pawX/bindings.cpp:1:\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘class pybind11::class_<DistributionFamily>’:\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:2216:7:   required from ‘class pybind11::enum_<DistributionFamily>’\r\n",
      "/kaggle/working/panther/pawX/bindings.cpp:24:58:   required from here\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1539:7: warning: ‘pybind11::class_<DistributionFamily>’ declared with greater visibility than its base ‘pybind11::detail::generic_type’ [-Wattributes]\r\n",
      " 1539 | class class_ : public detail::generic_type {\r\n",
      "      |       ^~~~~~\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘pybind11::class_< <template-parameter-1-1>, <template-parameter-1-2> >::class_(pybind11::handle, const char*, const Extra& ...) [with Extra = {}; type_ = DistributionFamily; options = {}]’:\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:2232:67:   required from ‘pybind11::enum_<Type>::enum_(const pybind11::handle&, const char*, const Extra& ...) [with Extra = {}; Type = DistributionFamily]’\r\n",
      "/kaggle/working/panther/pawX/bindings.cpp:24:58:   required from here\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1599:28: warning: ‘pybind11::class_<DistributionFamily>::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>’ declared with greater visibility than the type of its field ‘pybind11::class_<DistributionFamily>::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>::<record capture>’ [-Wattributes]\r\n",
      " 1599 |             with_internals([&](internals &internals) {\r\n",
      "      |                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      " 1600 |                 auto &instances = record.module_local ? get_local_internals().registered_types_cpp\r\n",
      "      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      " 1601 |                                                       : internals.registered_types_cpp;\r\n",
      "      |                                                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      " 1602 |                 instances[std::type_index(typeid(type_alias))]\r\n",
      "      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      " 1603 |                     = instances[std::type_index(typeid(type))];\r\n",
      "      |                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      " 1604 |             });\r\n",
      "      |             ~               \r\n",
      "[5/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/attention.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/attention.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/attention.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "[6/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/rsvd.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/rsvd.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/rsvd.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "[7/8] c++ -MMD -MF /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/skops.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/skops.cpp -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/skops.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "[8/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/linear_cuda.o.d -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/panther/pawX/linear_cuda.cu -o /kaggle/working/panther/pawX/build/temp.linux-x86_64-cpython-311/linear_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\r\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/pawX-0.0.0-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[0mObtaining file:///kaggle/working/panther/pawX\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Installing collected packages: pawX\r\n",
      "  Attempting uninstall: pawX\r\n",
      "    Found existing installation: pawX 0.0.0\r\n",
      "    Uninstalling pawX-0.0.0:\r\n",
      "      Successfully uninstalled pawX-0.0.0\r\n",
      "  Running setup.py develop for pawX\r\n",
      "Successfully installed pawX-0.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/panther/pawX; python setup.py install\n",
    "!cd /kaggle/working/panther/pawX; pip install --no-build-isolation -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e37ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:26.992686Z",
     "iopub.status.busy": "2025-05-08T22:00:26.992009Z",
     "iopub.status.idle": "2025-05-08T22:00:28.779398Z",
     "shell.execute_reply": "2025-05-08T22:00:28.778683Z"
    },
    "papermill": {
     "duration": 1.830739,
     "end_time": "2025-05-08T22:00:28.780805",
     "exception": false,
     "start_time": "2025-05-08T22:00:26.950066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import triton\n",
    "print(triton.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c381fcd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:28.869064Z",
     "iopub.status.busy": "2025-05-08T22:00:28.868371Z",
     "iopub.status.idle": "2025-05-08T22:00:28.872084Z",
     "shell.execute_reply": "2025-05-08T22:00:28.871522Z"
    },
    "papermill": {
     "duration": 0.048492,
     "end_time": "2025-05-08T22:00:28.873054",
     "exception": false,
     "start_time": "2025-05-08T22:00:28.824562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/working/panther\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb292b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:28.958120Z",
     "iopub.status.busy": "2025-05-08T22:00:28.957875Z",
     "iopub.status.idle": "2025-05-08T22:00:29.085225Z",
     "shell.execute_reply": "2025-05-08T22:00:29.084329Z"
    },
    "papermill": {
     "duration": 0.171909,
     "end_time": "2025-05-08T22:00:29.086775",
     "exception": false,
     "start_time": "2025-05-08T22:00:28.914866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/panther\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5359d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:29.179960Z",
     "iopub.status.busy": "2025-05-08T22:00:29.179683Z",
     "iopub.status.idle": "2025-05-08T22:00:29.187392Z",
     "shell.execute_reply": "2025-05-08T22:00:29.186822Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.057184,
     "end_time": "2025-05-08T22:00:29.188466",
     "exception": false,
     "start_time": "2025-05-08T22:00:29.131282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile /kaggle/working/panther/panther/nn/conv2d.py\n",
    "# import math\n",
    "# from typing import Any, Tuple\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.autograd import Function\n",
    "# from torch.nn import functional as F\n",
    "# from torch.nn import init\n",
    "\n",
    "# from panther.random import scaled_sign_sketch as gen_U\n",
    "\n",
    "\n",
    "# def mode4_unfold(tensor: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"Computes mode-4 matricization (unfolding along the last dimension).\"\"\"\n",
    "#     return tensor.reshape(-1, tensor.shape[-1])  # (I4, I1 * I2 * I3)\n",
    "\n",
    "\n",
    "# class SketchedConv2dFunction(Function):\n",
    "#     # Note that forward, setup_context, and backward are @staticmethods\n",
    "#     @staticmethod\n",
    "#     def forward(\n",
    "#         input: torch.Tensor,\n",
    "#         S1s: torch.Tensor,\n",
    "#         S2s: torch.Tensor,\n",
    "#         U1s: torch.Tensor,\n",
    "#         U2s: torch.Tensor,\n",
    "#         stride: Tuple[int, int],\n",
    "#         padding: Tuple[int, int],\n",
    "#         kernelSize: Tuple[int, int],\n",
    "#         inshape,\n",
    "#         bias: torch.Tensor,\n",
    "#     ):\n",
    "#         # in_channels, height, width = input.shape\n",
    "#         _, dout = U1s[0].shape\n",
    "#         hout = (inshape[2] + 2 * padding[0] - kernelSize[0]) // stride[0] + 1\n",
    "#         wout = (inshape[3] + 2 * padding[1] - kernelSize[1]) // stride[1] + 1\n",
    "#         input.transpose_(1, 2)\n",
    "#         t = (\n",
    "#             torch.einsum(\"nab,lbc,lcd->nlad\", input, S1s, U1s)\n",
    "#             + torch.einsum(\"nab,lbc,lcd->nlad\", input, U2s.transpose(1, 2), S2s)\n",
    "#         ).mean(dim=1)\n",
    "#         t = t.view(inshape[0], dout, hout, wout)\n",
    "#         return t + bias.view(1, dout, 1, 1)\n",
    "\n",
    "#     @staticmethod\n",
    "#     # inputs is a Tuple of all of the inputs passed to forward.\n",
    "#     # output is the output of the forward().\n",
    "#     def setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any):\n",
    "#         input, S1s, S2s, U1s, U2s, stride, padding, kernelSize, inshap, bias = inputs\n",
    "#         ctx.save_for_backward(\n",
    "#             input,\n",
    "#             S1s,\n",
    "#             S2s,\n",
    "#             U1s,\n",
    "#             U2s,\n",
    "#             torch.tensor(stride),\n",
    "#             torch.tensor(padding),\n",
    "#             torch.tensor(kernelSize),\n",
    "#             torch.tensor(inshap),\n",
    "#             bias,\n",
    "#         )\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx: Any, *grad_output: Any) -> Any:\n",
    "#         input, S1s, S2s, U1s, U2s, stride, padding, kernelSize, inshape, bias = (\n",
    "#             ctx.saved_tensors\n",
    "#         )\n",
    "#         input.transpose_(1, 2)\n",
    "#         num_terms, _, __ = S2s.shape\n",
    "#         hout = grad_output[0].shape[2]\n",
    "#         wout = grad_output[0].shape[3]\n",
    "#         g_bias = grad_output[0].sum(dim=(0, 2, 3))\n",
    "#         grad_output = grad_output[0].view(\n",
    "#             grad_output[0].shape[0],\n",
    "#             hout * wout,\n",
    "#             grad_output[0].shape[1],\n",
    "#         )\n",
    "#         grad_output /= 2 * num_terms\n",
    "#         g_S1s = torch.zeros_like(S1s)\n",
    "#         g_S2s = torch.zeros_like(S2s)\n",
    "#         g_S1s = torch.einsum(\n",
    "#             \"nab,nbc,lcd->lad\", input, grad_output, U1s.transpose(1, 2)\n",
    "#         )\n",
    "#         g_S2s = torch.einsum(\"lab,nbc,ncd->lad\", U2s, input, grad_output)\n",
    "#         gout = torch.einsum(\n",
    "#             \"nab,lbc,lcd->nad\", grad_output, U1s.transpose(1, 2), S1s.transpose(1, 2)\n",
    "#         ) + torch.einsum(\"nab,lbc,lcd->nad\", grad_output, S2s.transpose(1, 2), U2s)\n",
    "#         fold = nn.Fold(\n",
    "#             output_size=(inshape[2], inshape[3]),\n",
    "#             kernel_size=(kernelSize[0], kernelSize[1]),\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#         )\n",
    "#         gout = gout.transpose(1, 2)\n",
    "#         gout = fold(gout)\n",
    "\n",
    "#         return (gout, g_S1s, g_S2s, None, None, None, None, None, None, g_bias)\n",
    "\n",
    "\n",
    "# class SKConv2d(nn.Module):\n",
    "#     __constants__ = [\"in_features\", \"out_features\", \"num_terms\", \"low_rank\"]\n",
    "#     in_features: int\n",
    "#     out_features: int\n",
    "#     num_terms: int\n",
    "#     low_rank: int\n",
    "#     S1s: torch.Tensor\n",
    "#     S2s: torch.Tensor\n",
    "#     U1s: torch.Tensor\n",
    "#     U2s: torch.Tensor\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels: int,\n",
    "#         out_channels: int,\n",
    "#         kernel_size: Tuple = (3, 3),\n",
    "#         stride: Tuple = (1, 1),\n",
    "#         padding: Tuple = (1, 1),\n",
    "#         num_terms: int = 6,\n",
    "#         low_rank: int = 8,\n",
    "#         dtype=None,\n",
    "#         device=None,\n",
    "#     ):\n",
    "#         factory_kwargs = {\"dtype\": dtype, \"device\": device}\n",
    "#         super(SKConv2d, self).__init__()\n",
    "#         self.num_terms = num_terms\n",
    "#         self.low_rank = low_rank\n",
    "#         self.out_channels = out_channels\n",
    "#         self.in_channels = in_channels\n",
    "#         self.stride = stride if isinstance(stride, tuple) else (stride, stride)\n",
    "#         self.padding = padding if isinstance(padding, tuple) else (padding, padding)\n",
    "#         self.kernel_size = (\n",
    "#             kernel_size\n",
    "#             if isinstance(kernel_size, tuple)\n",
    "#             else (kernel_size, kernel_size)\n",
    "#         )\n",
    "#         self.register_buffer(\n",
    "#             \"U1s\",\n",
    "#             torch.stack(\n",
    "#                 [\n",
    "#                     gen_U(low_rank, out_channels, **factory_kwargs)\n",
    "#                     for _ in range(num_terms)\n",
    "#                 ]\n",
    "#             ),\n",
    "#         )  # kxd1\n",
    "#         self.register_buffer(\n",
    "#             \"U2s\",\n",
    "#             torch.stack(\n",
    "#                 [\n",
    "#                     gen_U(\n",
    "#                         low_rank * self.kernel_size[0] * self.kernel_size[1],\n",
    "#                         in_channels * self.kernel_size[0] * self.kernel_size[1],\n",
    "#                         **factory_kwargs,\n",
    "#                     )\n",
    "#                     for _ in range(num_terms)\n",
    "#                 ]\n",
    "#             ),\n",
    "#         )  # k h w x d2 h w\n",
    "#         kernels = nn.Parameter(\n",
    "#             torch.empty(\n",
    "#                 (in_channels, *self.kernel_size, out_channels), **factory_kwargs\n",
    "#             )\n",
    "#         )  # doutxdinxhxw\n",
    "#         init.kaiming_uniform_(kernels, a=math.sqrt(5))\n",
    "#         self.S1s = nn.Parameter(\n",
    "#             torch.stack(\n",
    "#                 [\n",
    "#                     mode4_unfold(torch.matmul(kernels, self.U1s[i].T))\n",
    "#                     for i in range(num_terms)\n",
    "#                 ]\n",
    "#             )\n",
    "#         )  # d2xk\n",
    "#         K_mat4 = kernels.view(\n",
    "#             in_channels * self.kernel_size[0] * self.kernel_size[1], out_channels\n",
    "#         )\n",
    "#         self.S2s = nn.Parameter(\n",
    "#             torch.stack(\n",
    "#                 [\n",
    "#                     mode4_unfold(\n",
    "#                         torch.matmul(self.U2s[i], K_mat4).view(\n",
    "#                             low_rank, *self.kernel_size, out_channels\n",
    "#                         )\n",
    "#                     )\n",
    "#                     for i in range(num_terms)\n",
    "#                 ]\n",
    "#             )\n",
    "#         )  #\n",
    "#         self.bias = nn.Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "#         fan_in, _ = init._calculate_fan_in_and_fan_out(kernels)\n",
    "#         bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "#         init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "#         # Register U1s and U2s as buffers since they are not learnable\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"Forward pass of the SKConv2d layer.\"\"\"\n",
    "#         # padd x\n",
    "#         B, C, H, W = x.shape\n",
    "#         if self.padding[0] > 0 or self.padding[1] > 0:\n",
    "#             x = F.pad(\n",
    "#                 x, (self.padding[1], self.padding[1], self.padding[0], self.padding[0])\n",
    "#             )\n",
    "#         H_out = (x.shape[2] - self.kernel_size[0]) // self.stride[0] + 1\n",
    "#         W_out = (x.shape[3] - self.kernel_size[1]) // self.stride[1] + 1\n",
    "#         x_strided = x.as_strided(\n",
    "#             size=(\n",
    "#                 x.shape[0],\n",
    "#                 x.shape[1],\n",
    "#                 H_out,\n",
    "#                 W_out,\n",
    "#                 self.kernel_size[0],\n",
    "#                 self.kernel_size[1],\n",
    "#             ),\n",
    "#             stride=(\n",
    "#                 x.stride(0),\n",
    "#                 x.stride(1),\n",
    "#                 x.stride(2) * self.stride[0],\n",
    "#                 x.stride(3) * self.stride[1],\n",
    "#                 x.stride(2),\n",
    "#                 x.stride(3),\n",
    "#             ),\n",
    "#         )\n",
    "#         x_windows = x_strided.permute(0, 2, 3, 1, 4, 5)\n",
    "\n",
    "#         x_windows = x_windows.reshape(\n",
    "#             -1, self.kernel_size[0] * self.kernel_size[1] * self.in_channels\n",
    "#         )\n",
    "#         out1 = (\n",
    "#             torch.einsum(\"nd,tdr,tro->no\", x_windows, self.S1s, self.U1s)\n",
    "#             / self.num_terms\n",
    "#         ) + self.bias\n",
    "#         out2 = (\n",
    "#             torch.einsum(\n",
    "#                 \"nd,tdr,tro->no\", x_windows, self.U2s.transpose(1, 2), self.S2s\n",
    "#             )\n",
    "#             / self.num_terms\n",
    "#         )\n",
    "#         return (\n",
    "#             (out1 + out2 + self.bias)\n",
    "#             .view(B, H_out, W_out, self.out_channels)\n",
    "#             .permute(0, 3, 1, 2)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2389efc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:29.271881Z",
     "iopub.status.busy": "2025-05-08T22:00:29.271642Z",
     "iopub.status.idle": "2025-05-08T22:00:29.275305Z",
     "shell.execute_reply": "2025-05-08T22:00:29.274669Z"
    },
    "papermill": {
     "duration": 0.046637,
     "end_time": "2025-05-08T22:00:29.276603",
     "exception": false,
     "start_time": "2025-05-08T22:00:29.229966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "# # 1. Load pretrained tokenizer & model\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model     = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "# model.eval()\n",
    "\n",
    "# # 2. Tokenize a sentence with a mask\n",
    "# text = \"Machine learning is the future of [MASK].\"\n",
    "# inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# # 3. Forward pass: yields logits over the full vocab for each position\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "# logits = outputs.logits  # shape: (1, seq_len, vocab_size)\n",
    "\n",
    "# # 4. Locate the [MASK] position\n",
    "# mask_token_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
    "# batch_idx, token_idx = mask_token_index\n",
    "\n",
    "# # 5. Extract the logits for that position and pick the highest-scoring token\n",
    "# mask_logits = logits[batch_idx, token_idx, :]\n",
    "# predicted_token_id = mask_logits.argmax(dim=-1).item()\n",
    "# predicted_token = tokenizer.decode([predicted_token_id])\n",
    "\n",
    "# print(f\"Filled mask: {predicted_token}\")  # e.g. “technology”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c37c9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:29.363877Z",
     "iopub.status.busy": "2025-05-08T22:00:29.363397Z",
     "iopub.status.idle": "2025-05-08T22:00:35.279127Z",
     "shell.execute_reply": "2025-05-08T22:00:35.278290Z"
    },
    "papermill": {
     "duration": 5.961889,
     "end_time": "2025-05-08T22:00:35.280868",
     "exception": false,
     "start_time": "2025-05-08T22:00:29.318979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting botorch\r\n",
      "  Downloading botorch-0.14.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.13.1)\r\n",
      "Collecting pyre_extensions (from botorch)\r\n",
      "  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting gpytorch==1.14 (from botorch)\r\n",
      "  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Collecting linear_operator==0.6 (from botorch)\r\n",
      "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.6.0+cu124)\r\n",
      "Collecting pyro-ppl>=1.8.4 (from botorch)\r\n",
      "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.15.2)\r\n",
      "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\r\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.6.0)\r\n",
      "Collecting jaxtyping (from gpytorch==1.14->botorch)\r\n",
      "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\r\n",
      "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\r\n",
      "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.18.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\r\n",
      "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyre_extensions->botorch) (0.9.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2.4.1)\r\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch==1.14->botorch)\r\n",
      "  Downloading wadler_lindig-0.1.5-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.4.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyre_extensions->botorch) (1.0.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\r\n",
      "Downloading botorch-0.14.0-py3-none-any.whl (738 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.3/738.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\r\n",
      "Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\r\n",
      "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wadler_lindig-0.1.5-py3-none-any.whl (20 kB)\r\n",
      "Installing collected packages: pyro-api, wadler-lindig, pyre_extensions, jaxtyping, linear_operator, pyro-ppl, gpytorch, botorch\r\n",
      "Successfully installed botorch-0.14.0 gpytorch-1.14 jaxtyping-0.3.2 linear_operator-0.6 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 wadler-lindig-0.1.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66e2113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:35.371114Z",
     "iopub.status.busy": "2025-05-08T22:00:35.370843Z",
     "iopub.status.idle": "2025-05-08T22:00:35.375497Z",
     "shell.execute_reply": "2025-05-08T22:00:35.374782Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.05025,
     "end_time": "2025-05-08T22:00:35.376748",
     "exception": false,
     "start_time": "2025-05-08T22:00:35.326498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile /kaggle/working/panther/panther/random.py\n",
    "# import torch\n",
    "\n",
    "# # DISCLAIMER: THIS FILE NEEDS TO BE CHECKED FOR CORRECTNESS\n",
    "\n",
    "\n",
    "# def uniform_dense_sketch(m, n, device=None, dtype=None):\n",
    "#     factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "#     return torch.empty(m, n, **factory_kwargs).uniform_(-1, 1)\n",
    "\n",
    "\n",
    "# def gaussian_dense_sketch(m, n, device=None, dtype=None):\n",
    "#     factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "#     return torch.randn(m, n, **factory_kwargs)\n",
    "\n",
    "\n",
    "# def hadamard_sketch(m, device=None, dtype=None):\n",
    "#     factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "#     if m & (m - 1) != 0:\n",
    "#         raise ValueError(\"m must be a power of 2\")\n",
    "\n",
    "#     H = torch.tensor([[1.0]])\n",
    "#     while H.shape[0] < m:\n",
    "#         H = torch.cat((torch.cat((H, H), dim=1), torch.cat((H, -H), dim=1)), dim=0)\n",
    "\n",
    "#     return H / torch.sqrt(torch.tensor(m, **factory_kwargs))\n",
    "\n",
    "\n",
    "# def gaussian_orthonormal_sketch(m, n, device=None, dtype=None):\n",
    "#     factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "#     return torch.qr(torch.randn(m, n, **factory_kwargs))[0]\n",
    "\n",
    "\n",
    "# def scaled_sign_sketch(m, n, device=None, dtype=None):\n",
    "#     factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "#     return (torch.randint(0, 2, (m, n), **factory_kwargs) * 2 - 1) / torch.sqrt(\n",
    "#         torch.tensor(m, **factory_kwargs)\n",
    "#     )\n",
    "\n",
    "\n",
    "# def clarkson_woodruff_sketch(m, n, device=None, dtype=None):\n",
    "#     factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "#     indices = torch.randint(0, m, (n,), **factory_kwargs)\n",
    "#     signs = torch.randint(0, 2, (n,), **factory_kwargs) * 2 - 1\n",
    "#     sketch = torch.zeros(m, n, **factory_kwargs)\n",
    "#     sketch[indices, torch.arange(n)] = signs\n",
    "#     return sketch\n",
    "\n",
    "\n",
    "# def sparse_sign_embeddings_sketch(m, n, sparsity=0.1):\n",
    "#     mask = torch.rand(m, n) < sparsity\n",
    "#     signs = torch.randint(0, 2, (m, n)) * 2 - 1\n",
    "#     return mask.float() * signs.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eae6ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:35.461347Z",
     "iopub.status.busy": "2025-05-08T22:00:35.461132Z",
     "iopub.status.idle": "2025-05-08T22:00:38.873166Z",
     "shell.execute_reply": "2025-05-08T22:00:38.872363Z"
    },
    "papermill": {
     "duration": 3.455477,
     "end_time": "2025-05-08T22:00:38.874303",
     "exception": false,
     "start_time": "2025-05-08T22:00:35.418826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: botorch is not available. Install with: pip install botorch\n"
     ]
    }
   ],
   "source": [
    "# Import components\n",
    "from panther.tuner.SkAutoTuner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60959063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:38.967075Z",
     "iopub.status.busy": "2025-05-08T22:00:38.966623Z",
     "iopub.status.idle": "2025-05-08T22:00:38.970196Z",
     "shell.execute_reply": "2025-05-08T22:00:38.969648Z"
    },
    "papermill": {
     "duration": 0.049772,
     "end_time": "2025-05-08T22:00:38.971335",
     "exception": false,
     "start_time": "2025-05-08T22:00:38.921563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ModelVisualizer.print_module_tree(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a98f70",
   "metadata": {
    "papermill": {
     "duration": 0.044516,
     "end_time": "2025-05-08T22:00:39.062023",
     "exception": false,
     "start_time": "2025-05-08T22:00:39.017507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# the normal without changing bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b17716c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T22:00:39.157093Z",
     "iopub.status.busy": "2025-05-08T22:00:39.156342Z",
     "iopub.status.idle": "2025-05-09T00:44:35.093577Z",
     "shell.execute_reply": "2025-05-09T00:44:35.092651Z"
    },
    "papermill": {
     "duration": 9835.987663,
     "end_time": "2025-05-09T00:44:35.095050",
     "exception": false,
     "start_time": "2025-05-08T22:00:39.107387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 22:00:48.331297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746741648.592270      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746741648.662502      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Random seed set to 42 for reproducibility\n",
      "\n",
      "Running BERT optimization test with SKAutoTuner...\n",
      "Random seed set to 42 for reproducibility\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fd1e9048084fd494d1b89d024d823e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925cfb365fc94bd1b3fb7c9d2336d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing BERT test dataset...\n",
      "Loading WikiText dataset for evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79320ba881f84e7b9c1fd5dbe5dd3be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9c0499cf8b4d7e80c9d32280d6829e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22d7d520b0b41f6ba0f0511abeadc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094e4dc7ef5a4bc5b4d31935940098c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a8ab4ab95248bcbf2abadbbadbd997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ab530eec1e4518baae029ae1f9eca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740dd04e1a9249e19a48581f8d9c5dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1937 examples from WikiText dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903751eeebe14ef0adb50cd2de8c3b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a349e61c7b34d5688d31c9dfc6ff57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3fb4154520400f8b459afd46617b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Model Parameter Counts Before Optimization =====\n",
      "Total parameters: 109.51M\n",
      "Parameters by layer:\n",
      "  - bert.encoder.layer.0: 7.09M parameters\n",
      "  - bert.encoder.layer.1: 7.09M parameters\n",
      "  - bert.encoder.layer.2: 7.09M parameters\n",
      "  - bert.encoder.layer.3: 7.09M parameters\n",
      "  - bert.encoder.layer.4: 7.09M parameters\n",
      "  - bert.encoder.layer.5: 7.09M parameters\n",
      "  - bert.encoder.layer.6: 7.09M parameters\n",
      "  - bert.encoder.layer.7: 7.09M parameters\n",
      "  - bert.encoder.layer.8: 7.09M parameters\n",
      "  - bert.encoder.layer.9: 7.09M parameters\n",
      "  - bert.encoder.layer.10: 7.09M parameters\n",
      "  - bert.encoder.layer.11: 7.09M parameters\n",
      "  - cls.predictions.transform: 0.59M parameters\n",
      "  - cls.predictions.decoder: 23.47M parameters\n",
      "\n",
      "Baseline BERT model (before any modifications):\n",
      "MLM Loss: 4.6017±0.0049\n",
      "Baseline model memory usage: 1509.11 MB\n",
      "Baseline model speed: 7.63±0.07 samples/sec\n",
      "\n",
      "===== Original Model Structure =====\n",
      "model (BertForMaskedLM)/\n",
      "└─ bert/\n",
      "│   ├─ embeddings/\n",
      "│   │   ├─ LayerNorm\n",
      "│   │   ├─ dropout\n",
      "│   │   ├─ position_embeddings\n",
      "│   │   ├─ token_type_embeddings\n",
      "│   │   ├─ word_embeddings\n",
      "│   ├─ encoder/\n",
      "│       └─ layer/\n",
      "│           └─ 0/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 1/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 10/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 11/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 2/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 3/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 4/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 5/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 6/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 7/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 8/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 9/\n",
      "│               └─ attention/\n",
      "│               │   ├─ output/\n",
      "│               │   │   ├─ LayerNorm\n",
      "│               │   │   ├─ dense\n",
      "│               │   │   ├─ dropout\n",
      "│               │   ├─ self/\n",
      "│               │       └─ dropout\n",
      "│               │       └─ key\n",
      "│               │       └─ query\n",
      "│               │       └─ value\n",
      "│               └─ intermediate/\n",
      "│               │   ├─ dense\n",
      "│               │   ├─ intermediate_act_fn\n",
      "│               └─ output/\n",
      "│                   └─ LayerNorm\n",
      "│                   └─ dense\n",
      "│                   └─ dropout\n",
      "└─ cls/\n",
      "    └─ predictions/\n",
      "        └─ decoder\n",
      "        └─ transform/\n",
      "            └─ LayerNorm\n",
      "            └─ dense\n",
      "            └─ transform_act_fn\n",
      "Setting loss threshold to -9999.0000\n",
      "\n",
      "===== Optimizing both MLM head linear layers =====\n",
      "\n",
      "Running combined MLM head layers tuning...\n",
      "Trying parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5984±0.0032\n",
      "Inference speed: 7.09±0.05 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.598403640631204, speed_score: 7.086008344124606, final score: 7.086008344124606\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5977±0.0019\n",
      "Inference speed: 6.62±0.03 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.597706157335253, speed_score: 6.616690140489569, final score: 6.616690140489569\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5937±0.0114\n",
      "Inference speed: 6.58±0.05 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.5937079658372495, speed_score: 6.577267887413615, final score: 6.577267887413615\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5999±0.0037\n",
      "Inference speed: 6.29±0.05 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.599871009654913, speed_score: 6.287883853183007, final score: 6.287883853183007\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5924±0.0040\n",
      "Inference speed: 6.22±0.04 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.59235574974084, speed_score: 6.216334703278235, final score: 6.216334703278235\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.6010±0.0071\n",
      "Inference speed: 6.20±0.02 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.601024407432486, speed_score: 6.201718375450901, final score: 6.201718375450901\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5973±0.0026\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.597335944793614, speed_score: 6.214797406213962, final score: 6.214797406213962\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.5936±0.0010\n",
      "Inference speed: 6.22±0.02 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.5936187916113, speed_score: 6.21684146869275, final score: 6.21684146869275\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.6022±0.0054\n",
      "Inference speed: 6.21±0.02 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.602187134593474, speed_score: 6.212499787081041, final score: 6.212499787081041\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\n",
      "MLM Loss: 4.6029±0.0106\n",
      "Inference speed: 6.22±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.6029431771194025, speed_score: 6.220711272093678, final score: 6.220711272093678\n",
      "Tried parameters: {'num_terms': 1, 'low_rank': 16}, accuracy_score: -4.598403640631204, speed_score: 7.086008344124606, final score: 7.086008344124606\n",
      "Trying parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6002±0.0050\n",
      "Inference speed: 6.23±0.04 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.60018734950614, speed_score: 6.233426847774669, final score: 6.233426847774669\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6020±0.0082\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.601958007374312, speed_score: 6.211979928791047, final score: 6.211979928791047\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.5991±0.0032\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.599106607082645, speed_score: 6.213517673095182, final score: 6.213517673095182\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.5987±0.0030\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.59865569569859, speed_score: 6.209173277560425, final score: 6.209173277560425\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6043±0.0030\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.604265467432522, speed_score: 6.214212714537033, final score: 6.214212714537033\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6063±0.0030\n",
      "Inference speed: 6.22±0.03 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.606286966632472, speed_score: 6.2154789180278645, final score: 6.2154789180278645\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6035±0.0022\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.603511711966866, speed_score: 6.205018540476527, final score: 6.205018540476527\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6018±0.0055\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.601833884112089, speed_score: 6.206566616093375, final score: 6.206566616093375\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6021±0.0067\n",
      "Inference speed: 6.22±0.02 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.602054833483725, speed_score: 6.217561217563441, final score: 6.217561217563441\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\n",
      "MLM Loss: 4.6008±0.0052\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.600842938563065, speed_score: 6.205567532290951, final score: 6.205567532290951\n",
      "Tried parameters: {'num_terms': 1, 'low_rank': 32}, accuracy_score: -4.60018734950614, speed_score: 6.233426847774669, final score: 6.233426847774669\n",
      "Trying parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.6001±0.0044\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.600130159982899, speed_score: 6.21329952658504, final score: 6.21329952658504\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.5990±0.0024\n",
      "Inference speed: 6.20±0.02 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.599047990894383, speed_score: 6.203510690001061, final score: 6.203510690001061\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.5974±0.0056\n",
      "Inference speed: 6.23±0.04 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.597383226375534, speed_score: 6.231859790048795, final score: 6.231859790048795\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.6024±0.0022\n",
      "Inference speed: 6.21±0.05 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.602357738031576, speed_score: 6.213630894410597, final score: 6.213630894410597\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.6012±0.0053\n",
      "Inference speed: 6.20±0.05 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.6011560304278545, speed_score: 6.200149803920061, final score: 6.200149803920061\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.5993±0.0022\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.599328183498016, speed_score: 6.211097748988252, final score: 6.211097748988252\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.5963±0.0042\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.596342930662881, speed_score: 6.2102976566191215, final score: 6.2102976566191215\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.6003±0.0042\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.600289101394272, speed_score: 6.211071075921212, final score: 6.211071075921212\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.6005±0.0049\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.600460111705105, speed_score: 6.207399737928785, final score: 6.207399737928785\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\n",
      "MLM Loss: 4.6004±0.0037\n",
      "Inference speed: 6.21±0.05 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.600413101416121, speed_score: 6.205117682312421, final score: 6.205117682312421\n",
      "Tried parameters: {'num_terms': 1, 'low_rank': 64}, accuracy_score: -4.597383226375534, speed_score: 6.231859790048795, final score: 6.231859790048795\n",
      "Trying parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5952±0.0078\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.595182807961258, speed_score: 6.2113470152746, final score: 6.2113470152746\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.6046±0.0048\n",
      "Inference speed: 6.19±0.03 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.60456956575545, speed_score: 6.190844560990381, final score: 6.190844560990381\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5970±0.0034\n",
      "Inference speed: 6.20±0.04 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.596969980100945, speed_score: 6.2021200426930445, final score: 6.2021200426930445\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.6013±0.0072\n",
      "Inference speed: 6.21±0.02 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.601313237375861, speed_score: 6.210561572351648, final score: 6.210561572351648\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5969±0.0047\n",
      "Inference speed: 6.23±0.04 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.596906125042898, speed_score: 6.229703133236325, final score: 6.229703133236325\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5991±0.0027\n",
      "Inference speed: 6.24±0.04 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.5991473483497725, speed_score: 6.243236054173787, final score: 6.243236054173787\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.6024±0.0050\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.60239139084889, speed_score: 6.214143663729262, final score: 6.214143663729262\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5979±0.0039\n",
      "Inference speed: 6.20±0.03 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.5979395697396255, speed_score: 6.204137418931602, final score: 6.204137418931602\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5973±0.0028\n",
      "Inference speed: 6.24±0.05 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.597262400518985, speed_score: 6.2426376372808186, final score: 6.2426376372808186\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\n",
      "MLM Loss: 4.5948±0.0024\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.594773773758491, speed_score: 6.210114675951452, final score: 6.210114675951452\n",
      "Tried parameters: {'num_terms': 2, 'low_rank': 16}, accuracy_score: -4.5991473483497725, speed_score: 6.243236054173787, final score: 6.243236054173787\n",
      "Trying parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.6025±0.0035\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.602535423221533, speed_score: 6.213762530883228, final score: 6.213762530883228\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5953±0.0043\n",
      "Inference speed: 6.21±0.02 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.595317741983873, speed_score: 6.211016810733352, final score: 6.211016810733352\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5982±0.0024\n",
      "Inference speed: 6.21±0.02 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.598228964680875, speed_score: 6.212304715010812, final score: 6.212304715010812\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5983±0.0021\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.598286785648194, speed_score: 6.210979101584943, final score: 6.210979101584943\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5996±0.0014\n",
      "Inference speed: 6.20±0.05 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.599625352347622, speed_score: 6.201836669302083, final score: 6.201836669302083\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5984±0.0043\n",
      "Inference speed: 6.19±0.04 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.5984151916031255, speed_score: 6.194536590235996, final score: 6.194536590235996\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.6002±0.0014\n",
      "Inference speed: 6.23±0.04 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.600165668647397, speed_score: 6.2346666040371375, final score: 6.2346666040371375\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.6011±0.0059\n",
      "Inference speed: 6.22±0.03 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.601081406181886, speed_score: 6.2167935527897065, final score: 6.2167935527897065\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5912±0.0014\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.591150873561998, speed_score: 6.211568704315365, final score: 6.211568704315365\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\n",
      "MLM Loss: 4.5949±0.0030\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.594935550816476, speed_score: 6.210671007404732, final score: 6.210671007404732\n",
      "Tried parameters: {'num_terms': 2, 'low_rank': 32}, accuracy_score: -4.600165668647397, speed_score: 6.2346666040371375, final score: 6.2346666040371375\n",
      "Trying parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.6051±0.0031\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.605102771326753, speed_score: 6.208836870416429, final score: 6.208836870416429\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.5959±0.0061\n",
      "Inference speed: 6.22±0.06 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.595920959908423, speed_score: 6.223379694201074, final score: 6.223379694201074\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.5984±0.0027\n",
      "Inference speed: 6.20±0.03 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.598441836223034, speed_score: 6.1975012611311255, final score: 6.1975012611311255\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.5966±0.0033\n",
      "Inference speed: 6.21±0.05 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.596648896033866, speed_score: 6.211362652572013, final score: 6.211362652572013\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.5991±0.0063\n",
      "Inference speed: 6.23±0.03 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.599135893200704, speed_score: 6.229800289514702, final score: 6.229800289514702\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.6036±0.0058\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.60360991107558, speed_score: 6.2097698924384135, final score: 6.2097698924384135\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.6011±0.0053\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.6011108575333335, speed_score: 6.212460219585812, final score: 6.212460219585812\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.6011±0.0050\n",
      "Inference speed: 6.23±0.06 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.601128140541674, speed_score: 6.233634366029304, final score: 6.233634366029304\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.5966±0.0037\n",
      "Inference speed: 6.21±0.02 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.596627343185099, speed_score: 6.210045716185946, final score: 6.210045716185946\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\n",
      "MLM Loss: 4.5952±0.0019\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.595194044877936, speed_score: 6.213822367487324, final score: 6.213822367487324\n",
      "Tried parameters: {'num_terms': 2, 'low_rank': 64}, accuracy_score: -4.601128140541674, speed_score: 6.233634366029304, final score: 6.233634366029304\n",
      "Trying parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.6000±0.0076\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.600018264555598, speed_score: 6.20759909571575, final score: 6.20759909571575\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5994±0.0076\n",
      "Inference speed: 6.23±0.04 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.599405166081605, speed_score: 6.232598765190858, final score: 6.232598765190858\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5945±0.0059\n",
      "Inference speed: 6.20±0.05 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.594462741654212, speed_score: 6.201722960399827, final score: 6.201722960399827\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5956±0.0033\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.595610144923628, speed_score: 6.214080138341414, final score: 6.214080138341414\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.6007±0.0017\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.600727686915253, speed_score: 6.209870105566062, final score: 6.209870105566062\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5986±0.0014\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.598644255566076, speed_score: 6.214198904252713, final score: 6.214198904252713\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.6008±0.0029\n",
      "Inference speed: 6.20±0.03 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.600845198698163, speed_score: 6.204653211799584, final score: 6.204653211799584\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5989±0.0038\n",
      "Inference speed: 6.20±0.03 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.5988508887451784, speed_score: 6.204722969731461, final score: 6.204722969731461\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5964±0.0063\n",
      "Inference speed: 6.22±0.03 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.5963598894100555, speed_score: 6.217487484025669, final score: 6.217487484025669\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 16}\n",
      "MLM Loss: 4.5971±0.0063\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.597099411387059, speed_score: 6.213266391746347, final score: 6.213266391746347\n",
      "Tried parameters: {'num_terms': 3, 'low_rank': 16}, accuracy_score: -4.599405166081605, speed_score: 6.232598765190858, final score: 6.232598765190858\n",
      "Trying parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.6039±0.0051\n",
      "Inference speed: 6.21±0.02 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.603863709755761, speed_score: 6.2068072523520605, final score: 6.2068072523520605\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.5958±0.0020\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.595805743683884, speed_score: 6.211678174864579, final score: 6.211678174864579\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.5955±0.0047\n",
      "Inference speed: 6.24±0.05 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.595545943582187, speed_score: 6.239171122079858, final score: 6.239171122079858\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.5999±0.0042\n",
      "Inference speed: 6.20±0.03 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.599900835199623, speed_score: 6.200936282383831, final score: 6.200936282383831\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.6030±0.0097\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.602951654600536, speed_score: 6.214176807925479, final score: 6.214176807925479\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.5940±0.0015\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.594032634927287, speed_score: 6.208838708607781, final score: 6.208838708607781\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.5971±0.0026\n",
      "Inference speed: 6.21±0.04 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.597060764334407, speed_score: 6.214235731813973, final score: 6.214235731813973\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.6021±0.0067\n",
      "Inference speed: 6.20±0.03 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.60211670862338, speed_score: 6.201529481448361, final score: 6.201529481448361\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.6037±0.0039\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.603690233211718, speed_score: 6.213816844060205, final score: 6.213816844060205\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\n",
      "MLM Loss: 4.5968±0.0043\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.596799464002982, speed_score: 6.207457614676835, final score: 6.207457614676835\n",
      "Tried parameters: {'num_terms': 3, 'low_rank': 32}, accuracy_score: -4.595545943582187, speed_score: 6.239171122079858, final score: 6.239171122079858\n",
      "Trying parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.6022±0.0094\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 1/10 - accuracy_score: -4.602246350264348, speed_score: 6.206792556473057, final score: 6.206792556473057\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.5948±0.0014\n",
      "Inference speed: 6.25±0.05 samples/sec\n",
      "run: 2/10 - accuracy_score: -4.594842701775956, speed_score: 6.247789263667836, final score: 6.247789263667836\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.5992±0.0059\n",
      "Inference speed: 6.20±0.05 samples/sec\n",
      "run: 3/10 - accuracy_score: -4.599221616342338, speed_score: 6.197814460873554, final score: 6.197814460873554\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.6015±0.0018\n",
      "Inference speed: 6.23±0.04 samples/sec\n",
      "run: 4/10 - accuracy_score: -4.601472320864972, speed_score: 6.230956219043388, final score: 6.230956219043388\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.6027±0.0008\n",
      "Inference speed: 6.22±0.05 samples/sec\n",
      "run: 5/10 - accuracy_score: -4.6026716271790065, speed_score: 6.2241674592234535, final score: 6.2241674592234535\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.5954±0.0035\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 6/10 - accuracy_score: -4.5954093543844365, speed_score: 6.209613603190627, final score: 6.209613603190627\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.6048±0.0084\n",
      "Inference speed: 6.23±0.05 samples/sec\n",
      "run: 7/10 - accuracy_score: -4.604822328519009, speed_score: 6.233591749546076, final score: 6.233591749546076\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.5941±0.0009\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 8/10 - accuracy_score: -4.594065496708599, speed_score: 6.20702861744833, final score: 6.20702861744833\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.6083±0.0063\n",
      "Inference speed: 6.21±0.03 samples/sec\n",
      "run: 9/10 - accuracy_score: -4.608300329013733, speed_score: 6.214284529005004, final score: 6.214284529005004\n",
      "Replaced cls.predictions.decoder with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "Replaced cls.predictions.transform.dense with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\n",
      "MLM Loss: 4.6037±0.0026\n",
      "Inference speed: 6.24±0.05 samples/sec\n",
      "run: 10/10 - accuracy_score: -4.603718250882213, speed_score: 6.2375918989161, final score: 6.2375918989161\n",
      "Tried parameters: {'num_terms': 3, 'low_rank': 64}, accuracy_score: -4.594842701775956, speed_score: 6.247789263667836, final score: 6.247789263667836\n",
      "Best parameters: {'cls.predictions.decoder': {'params': {'num_terms': 1, 'low_rank': 16}, 'copy_weights': True, 'best_layer': SKLinear()}, 'cls.predictions.transform.dense': {'params': {'num_terms': 1, 'low_rank': 16}, 'copy_weights': True, 'best_layer': SKLinear()}}\n",
      "replaced cls.predictions.decoder with SKLinear\n",
      "replaced cls.predictions.transform.dense with SKLinear\n",
      "\n",
      "===== Tuned Model Structure =====\n",
      "model (BertForMaskedLM)/\n",
      "└─ bert/\n",
      "│   ├─ embeddings/\n",
      "│   │   ├─ LayerNorm\n",
      "│   │   ├─ dropout\n",
      "│   │   ├─ position_embeddings\n",
      "│   │   ├─ token_type_embeddings\n",
      "│   │   ├─ word_embeddings\n",
      "│   ├─ encoder/\n",
      "│       └─ layer/\n",
      "│           └─ 0/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 1/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 10/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 11/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 2/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 3/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 4/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 5/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 6/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 7/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 8/\n",
      "│           │   ├─ attention/\n",
      "│           │   │   ├─ output/\n",
      "│           │   │   │   ├─ LayerNorm\n",
      "│           │   │   │   ├─ dense\n",
      "│           │   │   │   ├─ dropout\n",
      "│           │   │   ├─ self/\n",
      "│           │   │       └─ dropout\n",
      "│           │   │       └─ key\n",
      "│           │   │       └─ query\n",
      "│           │   │       └─ value\n",
      "│           │   ├─ intermediate/\n",
      "│           │   │   ├─ dense\n",
      "│           │   │   ├─ intermediate_act_fn\n",
      "│           │   ├─ output/\n",
      "│           │       └─ LayerNorm\n",
      "│           │       └─ dense\n",
      "│           │       └─ dropout\n",
      "│           └─ 9/\n",
      "│               └─ attention/\n",
      "│               │   ├─ output/\n",
      "│               │   │   ├─ LayerNorm\n",
      "│               │   │   ├─ dense\n",
      "│               │   │   ├─ dropout\n",
      "│               │   ├─ self/\n",
      "│               │       └─ dropout\n",
      "│               │       └─ key\n",
      "│               │       └─ query\n",
      "│               │       └─ value\n",
      "│               └─ intermediate/\n",
      "│               │   ├─ dense\n",
      "│               │   ├─ intermediate_act_fn\n",
      "│               └─ output/\n",
      "│                   └─ LayerNorm\n",
      "│                   └─ dense\n",
      "│                   └─ dropout\n",
      "└─ cls/\n",
      "    └─ predictions/\n",
      "        └─ decoder\n",
      "        └─ transform/\n",
      "            └─ LayerNorm\n",
      "            └─ dense\n",
      "            └─ transform_act_fn\n",
      "\n",
      "Evaluating models with identical conditions:\n",
      "\n",
      "===== Model Parameter Counts After Optimization =====\n",
      "Original model: 109.51M parameters\n",
      "Tuned model: 109.48M parameters\n",
      "Reduction: 0.03%\n",
      "\n",
      "Parameters by layer:\n",
      "  - bert.encoder.layer.0: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.1: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.10: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.11: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.2: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.3: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.4: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.5: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.6: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.7: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.8: 7.09M → 7.09M (0.00% reduction)\n",
      "  - bert.encoder.layer.9: 7.09M → 7.09M (0.00% reduction)\n",
      "  - cls.predictions.decoder: 23.47M → 0.53M (97.74% reduction)\n",
      "  - cls.predictions.transform: 0.59M → 0.03M (95.46% reduction)\n",
      "MLM Loss: 4.6007±0.0029 (original: 4.6059±0.0064)\n",
      "Speed: 6.20±0.04 samples/sec (original: 6.22±0.03)\n",
      "Memory: 2021.96 MB (original: 2021.96)\n",
      "\n",
      "===== Performance Comparison =====\n",
      "| Model Version | MLM Loss | Speed (samples/sec) | Memory (MB) | Speed Improvement |\n",
      "|--------------|----------|---------------------|-------------|-------------------|\n",
      "| Original     | 4.6059±0.0064 | 6.22±0.03 | 2021.96 | 1.00x |\n",
      "| Tuned        | 4.6007±0.0029 | 6.20±0.04 | 2021.96 | 1.00x |\n",
      "\n",
      "===== Qualitative Comparison: Mask Filling =====\n",
      "\n",
      "Sentence: The capital of France is [MASK].\n",
      "Original model predictions: paris, lille, lyon, marseille, tours\n",
      "Tuned model predictions:    paris, lille, lyon, marseille, tours\n",
      "\n",
      "Sentence: Machine learning models [MASK] data to make predictions.\n",
      "Original model predictions: use, process, utilize, gather, analyze\n",
      "Tuned model predictions:    use, process, utilize, gather, analyze\n",
      "\n",
      "Sentence: Transformers use [MASK] attention to process sequences.\n",
      "Original model predictions: mechanical, special, close, careful, manual\n",
      "Tuned model predictions:    mechanical, special, close, careful, manual\n",
      "\n",
      "Sentence: The [MASK] language model was developed by Google researchers.\n",
      "Original model predictions: google, natural, programming, query, human\n",
      "Tuned model predictions:    google, natural, programming, query, human\n",
      "\n",
      "===== Testing Performance Scaling with Sequence Length =====\n",
      "Preparing BERT test datasets with varying lengths: [128, 256, 384, 512]\n",
      "Loading WikiText dataset for sequence length tests...\n",
      "Loaded 5500 examples from WikiText dataset\n",
      "\n",
      "Testing with sequence length: 128\n",
      "Evaluating Original model accuracy...\n",
      "Measuring Original model speed...\n",
      "Evaluating Tuned model accuracy...\n",
      "Measuring Tuned model speed...\n",
      "\n",
      "Testing with sequence length: 256\n",
      "Evaluating Original model accuracy...\n",
      "Measuring Original model speed...\n",
      "Evaluating Tuned model accuracy...\n",
      "Measuring Tuned model speed...\n",
      "\n",
      "Testing with sequence length: 384\n",
      "Evaluating Original model accuracy...\n",
      "Measuring Original model speed...\n",
      "Evaluating Tuned model accuracy...\n",
      "Measuring Tuned model speed...\n",
      "\n",
      "Testing with sequence length: 512\n",
      "Evaluating Original model accuracy...\n",
      "Measuring Original model speed...\n",
      "Evaluating Tuned model accuracy...\n",
      "Measuring Tuned model speed...\n",
      "\n",
      "===== Sequence Length Scaling Results =====\n",
      "| Seq Length | Model | MLM Loss | Speed (samples/sec) | Memory (MB) | Speedup |\n",
      "|------------|-------|----------|---------------------|-------------|---------|\n",
      "|        128 | Original | 3.9971±0.0032 | 6.21±0.03 | 2022.11 | 1.00x |\n",
      "|        128 | Tuned | 3.9957±0.0009 | 6.21±0.04 | 2022.11 | 1.00x |\n",
      "|        256 | Original | 9.0506±0.0056 | 6.10±0.07 | 2022.11 | 1.00x |\n",
      "|        256 | Tuned | 9.0436±0.0067 | 6.12±0.02 | 2022.11 | 1.00x |\n",
      "|        384 | Original | 12.1698±0.0054 | 8.06±0.08 | 1901.36 | 1.00x |\n",
      "|        384 | Tuned | 12.1759±0.0060 | 8.06±0.07 | 1901.36 | 1.00x |\n",
      "|        512 | Original | 13.8800±0.0020 | 11.95±0.16 | 1782.11 | 1.00x |\n",
      "|        512 | Tuned | 13.8779±0.0020 | 11.91±0.18 | 1782.11 | 1.00x |\n",
      "\n",
      "Test completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import components\n",
    "from panther.tuner.SkAutoTuner import (\n",
    "    SKAutoTuner,\n",
    "    LayerConfig,\n",
    "    TuningConfigs,\n",
    "    GridSearch,\n",
    "    RandomSearch, \n",
    "    ModelVisualizer\n",
    ")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"Random seed set to {seed} for reproducibility\")\n",
    "\n",
    "# Setting up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Call set_seed early in the script\n",
    "set_seed(42)\n",
    "\n",
    "##################################### HELPERS #######################################\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in the model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def model_size_info(model):\n",
    "    \"\"\"Get detailed size information about the model\"\"\"\n",
    "    total_params = count_parameters(model)\n",
    "    \n",
    "    # Get layer-wise parameter counts for important components\n",
    "    layer_params = {}\n",
    "    \n",
    "    # Check BERT layers\n",
    "    if hasattr(model, 'bert') and hasattr(model.bert, 'encoder'):\n",
    "        for i, layer in enumerate(model.bert.encoder.layer):\n",
    "            layer_params[f'bert.encoder.layer.{i}'] = sum(p.numel() for p in layer.parameters() if p.requires_grad)\n",
    "    \n",
    "    # Check MLM head\n",
    "    if hasattr(model, 'cls'):\n",
    "        if hasattr(model.cls, 'predictions'):\n",
    "            if hasattr(model.cls.predictions, 'transform'):\n",
    "                layer_params['cls.predictions.transform'] = sum(\n",
    "                    p.numel() for p in model.cls.predictions.transform.parameters() if p.requires_grad)\n",
    "            if hasattr(model.cls.predictions, 'decoder'):\n",
    "                layer_params['cls.predictions.decoder'] = sum(\n",
    "                    p.numel() for p in model.cls.predictions.decoder.parameters() if p.requires_grad)\n",
    "    \n",
    "    return {\n",
    "        \"total_params\": total_params,\n",
    "        \"total_params_millions\": total_params / 1e6,\n",
    "        \"layer_params\": layer_params\n",
    "    }\n",
    "\n",
    "def dump_tensor_info(tensor, name=\"Tensor\"):\n",
    "    \"\"\"Print details about a tensor\"\"\"\n",
    "    print(f\"{name}: shape={tensor.shape}, dtype={tensor.dtype}, device={tensor.device}\")\n",
    "    print(f\"  - Values: min={tensor.min().item():.4f}, max={tensor.max().item():.4f}, mean={tensor.mean().item():.4f}\")\n",
    "    print(f\"  - First few values: {tensor.flatten()[:5]}\")\n",
    "\n",
    "def measure_time_with_stats(func, *args, n_runs=20, warmup=5):\n",
    "    \"\"\"Measure execution time of a function with proper GPU synchronization and report statistics\"\"\"\n",
    "    # Clear cache first\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        result = func(*args)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "    \n",
    "    # Timed runs\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        start = time.time()\n",
    "        result = func(*args)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    times = np.array(times)\n",
    "    mean_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    return {\n",
    "        \"mean\": mean_time,\n",
    "        \"std\": std_time,\n",
    "        \"min\": np.min(times),\n",
    "        \"max\": np.max(times),\n",
    "        \"samples_per_sec\": 1.0 / mean_time,\n",
    "        \"samples_per_sec_std\": std_time / (mean_time * mean_time)\n",
    "    }\n",
    "\n",
    "def measure_memory(model, input_tensor):\n",
    "    \"\"\"Measure peak memory usage of a model during inference\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return 0  # Cannot measure CUDA memory on CPU\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        model(**input_tensor)\n",
    "    \n",
    "    # Get peak memory\n",
    "    return torch.cuda.max_memory_allocated() / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "class MaskedTextDataset(Dataset):\n",
    "    \"\"\"Dataset for masked language modeling\"\"\"\n",
    "    def __init__(self, texts, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_special_tokens_mask=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Create input_ids with masks\n",
    "        input_ids = encoding.input_ids.clone().squeeze(0)\n",
    "        special_tokens_mask = encoding.special_tokens_mask.squeeze(0).bool()\n",
    "        \n",
    "        # Create labels (clone of input_ids)\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        # Find positions eligible for masking (not special tokens)\n",
    "        mask_positions = (~special_tokens_mask).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        # Randomly mask 15% of eligible tokens\n",
    "        num_to_mask = max(1, int(0.15 * len(mask_positions)))\n",
    "        mask_indices = np.random.choice(mask_positions.tolist(), size=num_to_mask, replace=False)\n",
    "        input_ids[mask_indices] = self.tokenizer.mask_token_id\n",
    "        \n",
    "        # Create attention mask\n",
    "        attention_mask = encoding.attention_mask.squeeze(0)\n",
    "        \n",
    "        # Create return dictionary\n",
    "        batch = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "def evaluate_model_with_stats(model, dataloader, tokenizer=None, n_runs=3):\n",
    "    \"\"\"Evaluate model loss on a dataset with multiple runs for statistics\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Accumulate loss statistics\n",
    "                batch_size = batch[\"input_ids\"].size(0)\n",
    "                total_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "        \n",
    "        avg_loss = total_loss / total_samples\n",
    "        \n",
    "        all_results.append({\n",
    "            \"loss\": avg_loss\n",
    "        })\n",
    "    \n",
    "    # Compute statistics across runs\n",
    "    losses = [res[\"loss\"] for res in all_results]\n",
    "    \n",
    "    results = {\n",
    "        \"loss_mean\": np.mean(losses),\n",
    "        \"loss_std\": np.std(losses),\n",
    "        \"runs\": all_results\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"Prepare dataset for BERT testing\"\"\"\n",
    "    print(\"Preparing BERT test dataset...\")\n",
    "    \n",
    "    # Load WikiText dataset - using a larger portion\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        # Use a variable for the number of examples instead of hardcoding\n",
    "        num_examples = 100  # Can be easily changed to any value\n",
    "        \n",
    "        print(\"Loading WikiText dataset for evaluation...\")\n",
    "        wiki_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "        \n",
    "        # Process valid entries from WikiText\n",
    "        texts = []\n",
    "        for item in wiki_dataset:\n",
    "            text = item['text'].strip()\n",
    "            # Filter for non-empty, meaningful text\n",
    "            if len(text) >= 50 and len(text.split()) > 10:\n",
    "                texts.append(text)\n",
    "        \n",
    "        # If we need more examples, load from train split as well\n",
    "        if len(texts) < num_examples:\n",
    "            print(f\"Found only {len(texts)} examples in test split, loading more from train split...\")\n",
    "            wiki_train = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "            \n",
    "            for item in wiki_train:\n",
    "                text = item['text'].strip()\n",
    "                if len(text) >= 50 and len(text.split()) > 10:\n",
    "                    texts.append(text)\n",
    "                    if len(texts) >= num_examples + 50:  # Get a bit more than needed\n",
    "                        break\n",
    "        \n",
    "        print(f\"Loaded {len(texts)} examples from WikiText dataset\")\n",
    "        \n",
    "        # Ensure we have enough examples\n",
    "        if len(texts) < num_examples:\n",
    "            raise ValueError(f\"Could only find {len(texts)} valid examples in WikiText, need at least {num_examples}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load WikiText dataset: {str(e)}. Please install the datasets package with 'pip install datasets'\")\n",
    "    \n",
    "    # Tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = MaskedTextDataset(texts, tokenizer)\n",
    "    \n",
    "    # Create data loader with batch size that's a multiple of 16 for Tensor Core optimization\n",
    "    batch_size = 16  # For Tensor Core optimizations\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Create a single batch for memory testing\n",
    "    memory_batch = {k: v.to(device) for k, v in next(iter(dataloader)).items()}\n",
    "    \n",
    "    return tokenizer, dataloader, memory_batch\n",
    "\n",
    "def get_data_varied_lengths(seq_lengths=[128, 256, 384, 512]):\n",
    "    \"\"\"Prepare datasets with varying sequence lengths for scaling tests\"\"\"\n",
    "    print(f\"Preparing BERT test datasets with varying lengths: {seq_lengths}\")\n",
    "    \n",
    "    # Try to load more complex texts from WikiText\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        print(\"Loading WikiText dataset for sequence length tests...\")\n",
    "        \n",
    "        # Load both test and train splits to ensure we have enough data\n",
    "        wiki_test = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "        wiki_train = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "        \n",
    "        # Process valid entries from WikiText\n",
    "        texts = []\n",
    "        \n",
    "        # First collect longer texts that are good for sequence length testing\n",
    "        for item in wiki_test:\n",
    "            text = item['text'].strip()\n",
    "            # Filter for meaningful, longer text\n",
    "            if len(text) >= 100 and len(text.split()) >= 20:\n",
    "                texts.append(text)\n",
    "        \n",
    "        # Add texts from train split\n",
    "        for item in wiki_train:\n",
    "            text = item['text'].strip()\n",
    "            if len(text) >= 100 and len(text.split()) >= 20:\n",
    "                texts.append(text)\n",
    "                # Once we have enough data, stop collecting\n",
    "                if len(texts) >= 5500:\n",
    "                    break\n",
    "        \n",
    "        print(f\"Loaded {len(texts)} examples from WikiText dataset\")\n",
    "        \n",
    "        # Ensure we have enough examples\n",
    "        if len(texts) < 5000:\n",
    "            raise ValueError(f\"Could only find {len(texts)} valid examples in WikiText, need at least 5000\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load WikiText dataset: {str(e)}. Please install the datasets package with 'pip install datasets'\")\n",
    "    \n",
    "    # Tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    # Create datasets and dataloaders for each sequence length\n",
    "    datasets = {}\n",
    "    dataloaders = {}\n",
    "    memory_batches = {}\n",
    "    \n",
    "    for max_length in seq_lengths:\n",
    "        # Create dataset with this specific max_length\n",
    "        dataset = MaskedTextDataset(texts, tokenizer, max_length=max_length)\n",
    "        \n",
    "        # Create data loader with batch size that's a multiple of 16 for Tensor Core optimization\n",
    "        # Use smaller batches for longer sequences to prevent OOM\n",
    "        batch_size = 16 if max_length <= 128 else 8 if max_length <= 256 else 4 if max_length <= 384 else 2\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Create a memory test batch\n",
    "        memory_batch = {k: v.to(device) for k, v in next(iter(dataloader)).items()}\n",
    "        \n",
    "        datasets[max_length] = dataset\n",
    "        dataloaders[max_length] = dataloader\n",
    "        memory_batches[max_length] = memory_batch\n",
    "    \n",
    "    return tokenizer, datasets, dataloaders, memory_batches\n",
    "\n",
    "def test_sequence_scaling(orig_model, tuned_model, tokenizer):\n",
    "    \"\"\"Test how performance improvements scale with sequence length\"\"\"\n",
    "    print(\"\\n===== Testing Performance Scaling with Sequence Length =====\")\n",
    "    \n",
    "    # Get datasets with varying sequence lengths\n",
    "    tokenizer, datasets, dataloaders, memory_batches = get_data_varied_lengths()\n",
    "    \n",
    "    # Results table\n",
    "    results = []\n",
    "    \n",
    "    # Test each sequence length\n",
    "    for seq_length in sorted(dataloaders.keys()):\n",
    "        print(f\"\\nTesting with sequence length: {seq_length}\")\n",
    "        dataloader = dataloaders[seq_length]\n",
    "        memory_batch = memory_batches[seq_length]\n",
    "        \n",
    "        # Function for inference\n",
    "        def infer(model, inputs):\n",
    "            with torch.no_grad():\n",
    "                return model(**inputs)\n",
    "        \n",
    "        # Test models\n",
    "        for model_name, model in [(\"Original\", orig_model), (\"Tuned\", tuned_model)]:\n",
    "            model.eval()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Measure accuracy\n",
    "            print(f\"Evaluating {model_name} model accuracy...\")\n",
    "            eval_results = evaluate_model_with_stats(model, dataloader, tokenizer, n_runs=3)\n",
    "            \n",
    "            # Measure speed\n",
    "            print(f\"Measuring {model_name} model speed...\")\n",
    "            time_results = measure_time_with_stats(infer, model, memory_batch, n_runs=10, warmup=3)\n",
    "            \n",
    "            # Measure memory\n",
    "            memory_used = measure_memory(model, memory_batch)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"seq_length\": seq_length,\n",
    "                \"model\": model_name,\n",
    "                \"loss_mean\": eval_results[\"loss_mean\"],\n",
    "                \"loss_std\": eval_results[\"loss_std\"],\n",
    "                \"speed_mean\": time_results[\"samples_per_sec\"],\n",
    "                \"speed_std\": time_results[\"samples_per_sec_std\"],\n",
    "                \"memory\": memory_used\n",
    "            })\n",
    "    \n",
    "    # Print results table\n",
    "    print(\"\\n===== Sequence Length Scaling Results =====\")\n",
    "    print(\"| Seq Length | Model | MLM Loss | Speed (samples/sec) | Memory (MB) | Speedup |\")\n",
    "    print(\"|------------|-------|----------|---------------------|-------------|---------|\")\n",
    "    \n",
    "    for seq_length in sorted(dataloaders.keys()):\n",
    "        # Extract results for this sequence length\n",
    "        orig_result = next(r for r in results if r[\"seq_length\"] == seq_length and r[\"model\"] == \"Original\")\n",
    "        tuned_result = next(r for r in results if r[\"seq_length\"] == seq_length and r[\"model\"] == \"Tuned\")\n",
    "        \n",
    "        # Calculate speedup\n",
    "        speedup = tuned_result[\"speed_mean\"] / orig_result[\"speed_mean\"]\n",
    "        \n",
    "        # Print original model results\n",
    "        print(f\"| {seq_length:10d} | Original | {orig_result['loss_mean']:.4f}±{orig_result['loss_std']:.4f} | \"\n",
    "              f\"{orig_result['speed_mean']:.2f}±{orig_result['speed_std']:.2f} | \"\n",
    "              f\"{orig_result['memory']:.2f} | 1.00x |\")\n",
    "        \n",
    "        # Print tuned model results\n",
    "        print(f\"| {seq_length:10d} | Tuned | {tuned_result['loss_mean']:.4f}±{tuned_result['loss_std']:.4f} | \"\n",
    "              f\"{tuned_result['speed_mean']:.2f}±{tuned_result['speed_std']:.2f} | \"\n",
    "              f\"{tuned_result['memory']:.2f} | {speedup:.2f}x |\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def fill_mask_test(model, tokenizer, text=\"The capital of France is [MASK].\"):\n",
    "    \"\"\"Test mask filling capability\"\"\"\n",
    "    # Replace [MASK] with actual mask token if needed\n",
    "    if \"[MASK]\" in text:\n",
    "        text = text.replace(\"[MASK]\", tokenizer.mask_token)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Find mask token position\n",
    "    mask_token_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Get predictions for mask position\n",
    "    if len(mask_token_index[0]) > 0:\n",
    "        batch_idx, token_idx = mask_token_index\n",
    "        mask_logits = logits[batch_idx, token_idx, :]\n",
    "        \n",
    "        # Get top 5 predictions\n",
    "        topk_values, topk_indices = torch.topk(mask_logits, 5, dim=1)\n",
    "        \n",
    "        # Convert to tokens\n",
    "        topk_tokens = [tokenizer.convert_ids_to_tokens(idx.item()) for idx in topk_indices[0]]\n",
    "        \n",
    "        return topk_tokens\n",
    "    else:\n",
    "        return [\"No mask token found\"]\n",
    "\n",
    "def test_bert_optimization():\n",
    "    \"\"\"Test SKAutoTuner on BERT model's linear layers\"\"\"\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "    \n",
    "    # Create reference copy before any modifications to ensure identical initial states\n",
    "    model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "    model.eval()\n",
    "    orig_model = copy.deepcopy(model)  # Create copy before any modifications\n",
    "    \n",
    "    # Get data for testing (do this before modifying the models)\n",
    "    tokenizer, val_loader, memory_batch = get_data()\n",
    "    \n",
    "    # Get parameter counts before optimization\n",
    "    print(\"\\n===== Model Parameter Counts Before Optimization =====\")\n",
    "    orig_params = model_size_info(model)\n",
    "    print(f\"Total parameters: {orig_params['total_params_millions']:.2f}M\")\n",
    "    print(\"Parameters by layer:\")\n",
    "    for layer_name, param_count in orig_params['layer_params'].items():\n",
    "        print(f\"  - {layer_name}: {param_count/1e6:.2f}M parameters\")\n",
    "    \n",
    "    # Apply identical vocab size modifications to both models\n",
    "    orig_out_features = model.cls.predictions.decoder.weight.size(0)\n",
    "    new_out_features = ((orig_out_features + 15) // 16) * 16\n",
    "    \n",
    "    # Store the true original forward methods before any wrapping\n",
    "    true_orig_forward = model.forward\n",
    "    true_orig_ref_forward = orig_model.forward\n",
    "    \n",
    "    # Define the post-processing function\n",
    "    def post_process_outputs(model_outputs, orig_size=orig_out_features):\n",
    "        \"\"\"Trim any padded outputs back to original vocabulary size\"\"\"\n",
    "        if hasattr(model_outputs, 'logits') and model_outputs.logits is not None:\n",
    "            if model_outputs.logits.size(-1) > orig_size:\n",
    "                # Trim to original vocabulary size\n",
    "                model_outputs.logits = model_outputs.logits[..., :orig_size]\n",
    "        return model_outputs\n",
    "    \n",
    "    # Create a wrapper factory for forward methods\n",
    "    def create_wrapped_forward(original_forward_fn):\n",
    "        def wrapped_forward(*args, **kwargs):\n",
    "            outputs = original_forward_fn(*args, **kwargs)\n",
    "            return post_process_outputs(outputs)\n",
    "        return wrapped_forward\n",
    "    \n",
    "    # Apply identical modifications to both models\n",
    "    for m in [model, orig_model]:\n",
    "        if orig_out_features != new_out_features:\n",
    "            # Create padded weights and bias\n",
    "            orig_weight = m.cls.predictions.decoder.weight\n",
    "            orig_bias = m.cls.predictions.decoder.bias\n",
    "            \n",
    "            new_weight = torch.zeros(new_out_features, orig_weight.size(1), \n",
    "                                    device=orig_weight.device, dtype=orig_weight.dtype)\n",
    "            new_bias = torch.zeros(new_out_features, \n",
    "                                  device=orig_bias.device, dtype=orig_bias.dtype)\n",
    "            \n",
    "            # Copy the original values\n",
    "            new_weight[:orig_out_features, :] = orig_weight\n",
    "            new_bias[:orig_out_features] = orig_bias\n",
    "            \n",
    "            # Replace the decoder\n",
    "            new_decoder = torch.nn.Linear(orig_weight.size(1), new_out_features, bias=True)\n",
    "            new_decoder.weight = torch.nn.Parameter(new_weight)\n",
    "            new_decoder.bias = torch.nn.Parameter(new_bias)\n",
    "            \n",
    "            m.cls.predictions.decoder = new_decoder\n",
    "            \n",
    "        # Update the config's vocab_size\n",
    "        m.config.vocab_size = new_out_features\n",
    "    \n",
    "    # Apply a single wrapping to each model\n",
    "    model.forward = create_wrapped_forward(true_orig_forward)\n",
    "    orig_model.forward = create_wrapped_forward(true_orig_ref_forward)\n",
    "    \n",
    "    # First evaluate the original model before any modifications\n",
    "    print(\"\\nBaseline BERT model (before any modifications):\")\n",
    "    baseline_results = evaluate_model_with_stats(model, val_loader, tokenizer)\n",
    "    \n",
    "    # Measure performance metrics of original model\n",
    "    def infer(model, inputs):\n",
    "        with torch.no_grad():\n",
    "            return model(**inputs)\n",
    "    \n",
    "    baseline_time_stats = measure_time_with_stats(infer, model, memory_batch, n_runs=10)\n",
    "    baseline_speed = baseline_time_stats[\"samples_per_sec\"]\n",
    "    baseline_memory = measure_memory(model, memory_batch)\n",
    "    \n",
    "    print(f\"MLM Loss: {baseline_results['loss_mean']:.4f}±{baseline_results['loss_std']:.4f}\")\n",
    "    print(f\"Baseline model memory usage: {baseline_memory:.2f} MB\")\n",
    "    print(f\"Baseline model speed: {baseline_speed:.2f}±{baseline_time_stats['samples_per_sec_std']:.2f} samples/sec\")\n",
    "    \n",
    "    print(\"\\n===== Original Model Structure =====\")\n",
    "    ModelVisualizer.print_module_tree(model)\n",
    "    \n",
    "    # Create an evaluation function for the model\n",
    "    def acc_eval_func(model):\n",
    "        \"\"\"Evaluation function based on MLM loss (lower is better)\"\"\"\n",
    "        results = evaluate_model_with_stats(model, val_loader, tokenizer)\n",
    "        print(f\"MLM Loss: {results['loss_mean']:.4f}±{results['loss_std']:.4f}\")\n",
    "        # Return negative loss since SKAutoTuner maximizes the score\n",
    "        return -results['loss_mean']  # Negative loss (higher is better, as required by SKAutoTuner)\n",
    "    \n",
    "    # Create a separate speed evaluation function\n",
    "    def speed_eval_func(model):\n",
    "        \"\"\"Speed evaluation function\"\"\"\n",
    "        def infer(model, inputs):\n",
    "            with torch.no_grad():\n",
    "                return model(**inputs)\n",
    "        \n",
    "        # Higher is better (inverse of time)\n",
    "        time_stats = measure_time_with_stats(infer, model, memory_batch, n_runs=10)\n",
    "        throughput = time_stats[\"samples_per_sec\"]\n",
    "        print(f\"Inference speed: {throughput:.2f}±{time_stats['samples_per_sec_std']:.2f} samples/sec\")\n",
    "        return throughput\n",
    "    \n",
    "    # Calculate loss threshold (allow some increase in loss)\n",
    "    loss_threshold = -9999  # Allow 0.5 increase in loss\n",
    "    print(f\"Setting loss threshold to {loss_threshold:.4f}\")\n",
    "    \n",
    "    # Strategy: Optimizing both linear layers in the MLM head\n",
    "    print(\"\\n===== Optimizing both MLM head linear layers =====\")\n",
    "    \n",
    "    # Create configs to tune both linear layers together with Tensor Core friendly dimensions\n",
    "    configs = TuningConfigs([\n",
    "        LayerConfig(\n",
    "            # Target both linear layers in the MLM head\n",
    "            layer_names={\n",
    "                \"pattern\": \"cls.predictions.*\",\n",
    "                \"type\": \"Linear\",\n",
    "            },\n",
    "            params={\n",
    "                \"num_terms\": [1, 2, 3],\n",
    "                \"low_rank\": [16, 32, 64],  # All values are multiples of 16 for Tensor Core\n",
    "            },\n",
    "            separate=False  # Tune as a group\n",
    "        ),\n",
    "    ])\n",
    "    \n",
    "    # Create tuner for both layers together\n",
    "    tuner = SKAutoTuner(\n",
    "        model=copy.deepcopy(model),\n",
    "        configs=configs,\n",
    "        accuracy_eval_func=acc_eval_func,  # Using loss evaluation, despite the function name\n",
    "        search_algorithm=GridSearch(),\n",
    "        verbose=True,\n",
    "        accuracy_threshold=loss_threshold,  # Negative since we're using negative loss as our metric\n",
    "        optmization_eval_func=speed_eval_func,\n",
    "        num_runs_per_param=10\n",
    "    )\n",
    "    \n",
    "    # Run tuning\n",
    "    print(\"\\nRunning combined MLM head layers tuning...\")\n",
    "    best_params = tuner.tune()\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Apply best parameters\n",
    "    tuned_model = tuner.apply_best_params()\n",
    "    \n",
    "    print(\"\\n===== Tuned Model Structure =====\")\n",
    "    ModelVisualizer.print_module_tree(tuned_model)\n",
    "    \n",
    "    # Test the tuned model\n",
    "    print(\"\\nEvaluating models with identical conditions:\")\n",
    "    \n",
    "    # Ensure both models are in the same state for fair comparison\n",
    "    for m in [orig_model, tuned_model]:\n",
    "        m.eval()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Use identical test conditions\n",
    "    def test_model(model_name, model):\n",
    "        torch.cuda.empty_cache()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        # Run standardized tests\n",
    "        results = evaluate_model_with_stats(model, val_loader, tokenizer)\n",
    "        \n",
    "        def infer(model, inputs):\n",
    "            with torch.no_grad():\n",
    "                return model(**inputs)\n",
    "        \n",
    "        time_result = measure_time_with_stats(infer, model, memory_batch, n_runs=10)\n",
    "        speed = time_result[\"samples_per_sec\"]\n",
    "        speed_std = time_result[\"samples_per_sec_std\"]\n",
    "        memory_used = measure_memory(model, memory_batch)\n",
    "        \n",
    "        return {\n",
    "            \"name\": model_name,\n",
    "            \"loss\": results[\"loss_mean\"],\n",
    "            \"loss_std\": results[\"loss_std\"],\n",
    "            \"speed\": speed,\n",
    "            \"speed_std\": speed_std,\n",
    "            \"memory\": memory_used\n",
    "        }\n",
    "\n",
    "    # Test both models under identical conditions\n",
    "    baseline_results = test_model(\"Original\", orig_model)\n",
    "    tuned_results = test_model(\"Tuned\", tuned_model)\n",
    "    \n",
    "    # Extract results for the comparison table\n",
    "    baseline_loss = baseline_results[\"loss\"]\n",
    "    baseline_speed = baseline_results[\"speed\"]\n",
    "    baseline_memory = baseline_results[\"memory\"]\n",
    "    \n",
    "    final_loss = tuned_results[\"loss\"]\n",
    "    final_speed = tuned_results[\"speed\"]\n",
    "    final_memory = tuned_results[\"memory\"]\n",
    "    \n",
    "    # After optimization, get new parameter counts\n",
    "    print(\"\\n===== Model Parameter Counts After Optimization =====\")\n",
    "    tuned_params = model_size_info(tuned_model)\n",
    "    print(f\"Original model: {orig_params['total_params_millions']:.2f}M parameters\")\n",
    "    print(f\"Tuned model: {tuned_params['total_params_millions']:.2f}M parameters\")\n",
    "    print(f\"Reduction: {(1 - tuned_params['total_params_millions']/orig_params['total_params_millions'])*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\nParameters by layer:\")\n",
    "    for layer_name in sorted(set(list(orig_params['layer_params'].keys()) + list(tuned_params['layer_params'].keys()))):\n",
    "        orig_count = orig_params['layer_params'].get(layer_name, 0) / 1e6\n",
    "        tuned_count = tuned_params['layer_params'].get(layer_name, 0) / 1e6\n",
    "        \n",
    "        if orig_count > 0 and tuned_count > 0:\n",
    "            reduction = (1 - tuned_count/orig_count) * 100\n",
    "            print(f\"  - {layer_name}: {orig_count:.2f}M → {tuned_count:.2f}M ({reduction:.2f}% reduction)\")\n",
    "    \n",
    "    print(f\"MLM Loss: {final_loss:.4f}±{tuned_results['loss_std']:.4f} (original: {baseline_loss:.4f}±{baseline_results['loss_std']:.4f})\")\n",
    "    print(f\"Speed: {final_speed:.2f}±{tuned_results['speed_std']:.2f} samples/sec (original: {baseline_speed:.2f}±{baseline_results['speed_std']:.2f})\")\n",
    "    print(f\"Memory: {final_memory:.2f} MB (original: {baseline_memory:.2f})\")\n",
    "    \n",
    "    # Enhanced performance comparison table\n",
    "    print(\"\\n===== Performance Comparison =====\")\n",
    "    print(\"| Model Version | MLM Loss | Speed (samples/sec) | Memory (MB) | Speed Improvement |\")\n",
    "    print(\"|--------------|----------|---------------------|-------------|-------------------|\")\n",
    "    print(f\"| Original     | {baseline_loss:.4f}±{baseline_results['loss_std']:.4f} | {baseline_speed:.2f}±{baseline_results['speed_std']:.2f} | {baseline_memory:.2f} | 1.00x |\")\n",
    "    print(f\"| Tuned        | {final_loss:.4f}±{tuned_results['loss_std']:.4f} | {final_speed:.2f}±{tuned_results['speed_std']:.2f} | {final_memory:.2f} | {final_speed/baseline_speed:.2f}x |\")\n",
    "    \n",
    "    # Additional comparison tests with real examples\n",
    "    test_examples = [\n",
    "        \"The capital of France is [MASK].\",\n",
    "        \"Machine learning models [MASK] data to make predictions.\",\n",
    "        \"Transformers use [MASK] attention to process sequences.\",\n",
    "        \"The [MASK] language model was developed by Google researchers.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n===== Qualitative Comparison: Mask Filling =====\")\n",
    "    for test_sentence in test_examples:\n",
    "        print(f\"\\nSentence: {test_sentence}\")\n",
    "        \n",
    "        # Original model predictions\n",
    "        orig_predictions = fill_mask_test(orig_model, tokenizer, test_sentence)\n",
    "        print(f\"Original model predictions: {', '.join(orig_predictions)}\")\n",
    "        \n",
    "        # Tuned model predictions\n",
    "        tuned_predictions = fill_mask_test(tuned_model, tokenizer, test_sentence)\n",
    "        print(f\"Tuned model predictions:    {', '.join(tuned_predictions)}\")\n",
    "    \n",
    "    # Run sequence length scaling test\n",
    "    test_sequence_scaling(orig_model, tuned_model, tokenizer)\n",
    "    \n",
    "    return tuned_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import copy  # Used for deep copying models\n",
    "    \n",
    "    # Run the BERT optimization test\n",
    "    print(\"\\nRunning BERT optimization test with SKAutoTuner...\")\n",
    "    test_bert_optimization()\n",
    "    \n",
    "    print(\"\\nTest completed.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7295817,
     "sourceId": 11628705,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10180.628985,
   "end_time": "2025-05-09T00:44:38.860778",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-08T21:54:58.231793",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0368d3b1fa8d4284ae84747e0442e694": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "05d9bf2f75b34bf689ae9716e767fbe4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "075dd171baa94678a661fb5f7f83f105": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "07eb4dce5a004118afa89ae71286937a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "085f4b6427194eaf9d70bb22418e5937": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "094e4dc7ef5a4bc5b4d31935940098c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_905a4602042f49a2ab744b01c28b9821",
        "IPY_MODEL_81231d2d6f8242768b80d97cc164243e",
        "IPY_MODEL_d666429f6e354a76a50794dd28ddde0c"
       ],
       "layout": "IPY_MODEL_4cb90f6a30dc45a6b5ad92d0f862ddc3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "09949c1030894cf386d9ab31057e49dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0be77cc96e904c4b96e36029cd15fda0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0ee47ab563e94612b1aa7b4cc6fcc615": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "106277293a5245b9b3dcae27cc98887a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "113541eaa68b45e98c133fa2a18370da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "117d9312cfd948e49546ba3256a6b171": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12535bc3f6e0498596713bcb59c7f071": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9b06bdf8f454869998eb94c8fabc4e1",
       "placeholder": "​",
       "style": "IPY_MODEL_e5c93ab96a8d40f884c27c309946de8b",
       "tabbable": null,
       "tooltip": null,
       "value": "test-00000-of-00001.parquet: 100%"
      }
     },
     "128364a29cf94353aadf1e7fc3454271": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12f5c74132e34b7c8d228514ec6033c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_91a3e76da1954fbb8a363ccbcc7e34b6",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_46bcc9cd0b9e49aab01c1a9d5f84fa70",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "144f35697c94478bbf4f7e0fa0438125": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3aa6b0efad904845bb877c1419d02282",
       "max": 36718.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_79346aebdc11440ba69ba54b02e30d1b",
       "tabbable": null,
       "tooltip": null,
       "value": 36718.0
      }
     },
     "14fd1e9048084fd494d1b89d024d823e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_30838f28212b4fb4896caf259f467ca6",
        "IPY_MODEL_55b5433885064415bd5c954e5353529d",
        "IPY_MODEL_31dbbaafd8514494bf0ac04724500e67"
       ],
       "layout": "IPY_MODEL_e03e49b071a34088815afd70fd210630",
       "tabbable": null,
       "tooltip": null
      }
     },
     "15d03fd11ab14dbaa77cd493e2cac499": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1758fcc7caaa4f329f3c3b010b68769e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2270dfdd2a824981b642314414df67f7",
       "placeholder": "​",
       "style": "IPY_MODEL_a505dc9a9bc14c40bd687e5d93043fcb",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 9.19MB/s]"
      }
     },
     "1ccccb2b31eb49608991a3fb9e96c458": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b50d0049e8b9495dba1b26da9b4d8ea2",
       "placeholder": "​",
       "style": "IPY_MODEL_1d71ff4a089846ef92d79f3c5c525d87",
       "tabbable": null,
       "tooltip": null,
       "value": "README.md: 100%"
      }
     },
     "1d71ff4a089846ef92d79f3c5c525d87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "210999813d6c4bbb81fc00b64211576e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bb49ae763ec74b0f816cc337fdfaf0dd",
       "placeholder": "​",
       "style": "IPY_MODEL_09949c1030894cf386d9ab31057e49dd",
       "tabbable": null,
       "tooltip": null,
       "value": "Computing checksums: 100%"
      }
     },
     "217b420382724205afbc0af0c49c1f49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2270dfdd2a824981b642314414df67f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2344527042bc4d43a337fe666e9abf1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5dd02019cb5a499bbca41d16637c4ad0",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5a563a79d68a4f26812b9e7d95488a21",
       "tabbable": null,
       "tooltip": null,
       "value": 3.0
      }
     },
     "2509c5b4b5134238b636f4f8d192fc41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c0ee3691b6064d41875c3363c5f02e8a",
       "placeholder": "​",
       "style": "IPY_MODEL_42e6232917a34c35b4ae3dd5b574d3b7",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "25a7c0314ac64ed28212c371a6ce0df4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28a8ab4ab95248bcbf2abadbbadbd997": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f575aeb93a94483d84c216116c2c1b12",
        "IPY_MODEL_cc023a9a732c4f67b3cc40dd4754b34d",
        "IPY_MODEL_ff686fd48f164e5eaa07a5ef8c40b1e8"
       ],
       "layout": "IPY_MODEL_e9eacbb63ffd4c609889ab599eed9108",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2b9a0a9079b842b4a1aaecd85527ad7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2dfa62d54f2d4a1e97d8b7aaf8382182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_085f4b6427194eaf9d70bb22418e5937",
       "placeholder": "​",
       "style": "IPY_MODEL_0be77cc96e904c4b96e36029cd15fda0",
       "tabbable": null,
       "tooltip": null,
       "value": " 6.36M/6.36M [00:00&lt;00:00, 107MB/s]"
      }
     },
     "2ebf84a4dfbc42ce907dda52f9bb2757": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ee258c03ec84642b4aec217ec5f0489": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30838f28212b4fb4896caf259f467ca6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cd348ae767e94c249153b96a8cfa638f",
       "placeholder": "​",
       "style": "IPY_MODEL_cf68ee4851a94f558c1743c6e421d66a",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "31dbbaafd8514494bf0ac04724500e67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25a7c0314ac64ed28212c371a6ce0df4",
       "placeholder": "​",
       "style": "IPY_MODEL_4f34b385f7e04bd5a72965fa8a6937f4",
       "tabbable": null,
       "tooltip": null,
       "value": " 570/570 [00:00&lt;00:00, 67.7kB/s]"
      }
     },
     "353e22b1a2a240b3ad0b02adf0b4f5db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3aa6b0efad904845bb877c1419d02282": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b4cbb418e3d409a82e0b6b9b6739f7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4078121724ee4e12a91e0c8b669cc0a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4176f6389a4a430d9ac1266ed1567ba6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "42e6232917a34c35b4ae3dd5b574d3b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "434aa822128e4f7a81591e8cb873e89c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f2a058d22ea345ea80b92d9e098074fb",
       "placeholder": "​",
       "style": "IPY_MODEL_dff0996fe2a748b69f213dc9a98a4b39",
       "tabbable": null,
       "tooltip": null,
       "value": " 3760/3760 [00:00&lt;00:00, 244687.26 examples/s]"
      }
     },
     "456e93864f95433a9d7e6b0ed1fa2dac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8bfbe18771e9489c8117c6982570ce0e",
       "max": 732610.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4176f6389a4a430d9ac1266ed1567ba6",
       "tabbable": null,
       "tooltip": null,
       "value": 732610.0
      }
     },
     "46bcc9cd0b9e49aab01c1a9d5f84fa70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "48603f57722042a48692c57aa97b31bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4a349e61c7b34d5688d31c9dfc6ff57a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_af9988fae99e43ceabb13342d684f1dd",
        "IPY_MODEL_eb0add5147334d1a9576b50b9c040ed0",
        "IPY_MODEL_1758fcc7caaa4f329f3c3b010b68769e"
       ],
       "layout": "IPY_MODEL_634ad183a8354fd8982111552a693e02",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4cb90f6a30dc45a6b5ad92d0f862ddc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f332e5f76e84a2a92366ec88d8050c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f34b385f7e04bd5a72965fa8a6937f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4f78997f023147089dbf30c7df7e84f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5076c72b55194161ab04c04b690205b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55b5433885064415bd5c954e5353529d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f78997f023147089dbf30c7df7e84f1",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_106277293a5245b9b3dcae27cc98887a",
       "tabbable": null,
       "tooltip": null,
       "value": 570.0
      }
     },
     "58fbfb77fe644961aea144a4e19fbb41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a563a79d68a4f26812b9e7d95488a21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5cac014f8a4243689fc97ca413c04249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d7777192845435bb047b7a846a933cc",
       "placeholder": "​",
       "style": "IPY_MODEL_5ff74655cb384771af7f587abac6b1b6",
       "tabbable": null,
       "tooltip": null,
       "value": " 36718/36718 [00:00&lt;00:00, 612817.11 examples/s]"
      }
     },
     "5d7777192845435bb047b7a846a933cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5dd02019cb5a499bbca41d16637c4ad0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ff74655cb384771af7f587abac6b1b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6293f2d6010b43a283f77b32eb3851b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "634ad183a8354fd8982111552a693e02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63d7e87822d34875ba526006db6c5ba2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a4257b7274947cdbb506d35b6e96ee9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb969c767ac14d14a39c5e0f039b68c0",
       "placeholder": "​",
       "style": "IPY_MODEL_e894d002d7544e98b8bd79121cc90547",
       "tabbable": null,
       "tooltip": null,
       "value": " 10.5k/10.5k [00:00&lt;00:00, 1.23MB/s]"
      }
     },
     "6df0dadf29a8488285fece3436f861fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6eb1c2eeed734c74ae7c6ccac9d0d64d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73ab530eec1e4518baae029ae1f9eca1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80fd6ee87d7d4e459e08b3b8f0314fb7",
        "IPY_MODEL_144f35697c94478bbf4f7e0fa0438125",
        "IPY_MODEL_5cac014f8a4243689fc97ca413c04249"
       ],
       "layout": "IPY_MODEL_8a11986a9d0443cf84864ffb9dd4f113",
       "tabbable": null,
       "tooltip": null
      }
     },
     "740143bb7c574ed4bffdcfb3aa1e0d02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "740dd04e1a9249e19a48581f8d9c5dbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9aa1f970218e41208cc020270b48deb4",
        "IPY_MODEL_f6a6524eff974c1281fbf4c9e67e344e",
        "IPY_MODEL_434aa822128e4f7a81591e8cb873e89c"
       ],
       "layout": "IPY_MODEL_07eb4dce5a004118afa89ae71286937a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "749e095378574ba8b62864b1fb6264b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76839a3f4e0345fdb0078bde3c61f3e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4078121724ee4e12a91e0c8b669cc0a1",
       "placeholder": "​",
       "style": "IPY_MODEL_82d4d29923c3430fa06b8e1d5117c4fa",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "79320ba881f84e7b9c1fd5dbe5dd3be4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ccccb2b31eb49608991a3fb9e96c458",
        "IPY_MODEL_92ebf0c2f9824b26af36f1500faad697",
        "IPY_MODEL_6a4257b7274947cdbb506d35b6e96ee9"
       ],
       "layout": "IPY_MODEL_6eb1c2eeed734c74ae7c6ccac9d0d64d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "79346aebdc11440ba69ba54b02e30d1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d0c0b7bd1644e49a4862bcf0efdbb80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ee258c03ec84642b4aec217ec5f0489",
       "placeholder": "​",
       "style": "IPY_MODEL_c7cc092e320f4751b9aa7e2b9d842a94",
       "tabbable": null,
       "tooltip": null,
       "value": " 440M/440M [00:02&lt;00:00, 235MB/s]"
      }
     },
     "7d53af3df06a4126a7ea552eb4ba31f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f056091ddd64a11a748f0ff20260fa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f3fb4154520400f8b459afd46617b1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2509c5b4b5134238b636f4f8d192fc41",
        "IPY_MODEL_12f5c74132e34b7c8d228514ec6033c9",
        "IPY_MODEL_bbcf0d5a1cd1404f821e4d445df89d8f"
       ],
       "layout": "IPY_MODEL_f831d895684f4ce0b02d29442bf91207",
       "tabbable": null,
       "tooltip": null
      }
     },
     "806873fdc6844f93857a066ce09a7aa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "80fd6ee87d7d4e459e08b3b8f0314fb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d762f99699f14681916ec5d3f5ec319c",
       "placeholder": "​",
       "style": "IPY_MODEL_2b9a0a9079b842b4a1aaecd85527ad7d",
       "tabbable": null,
       "tooltip": null,
       "value": "Generating train split: 100%"
      }
     },
     "81231d2d6f8242768b80d97cc164243e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15d03fd11ab14dbaa77cd493e2cac499",
       "max": 657209.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_81be9636a4894e5bbad412d630877fd4",
       "tabbable": null,
       "tooltip": null,
       "value": 657209.0
      }
     },
     "81be9636a4894e5bbad412d630877fd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "82d4d29923c3430fa06b8e1d5117c4fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "866785875aaa45398340651ecc45255c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bf47683390f24cd487d7eaa5de1b2b5f",
       "placeholder": "​",
       "style": "IPY_MODEL_48603f57722042a48692c57aa97b31bb",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/3 [00:00&lt;00:00, 621.32it/s]"
      }
     },
     "8a11986a9d0443cf84864ffb9dd4f113": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bfbe18771e9489c8117c6982570ce0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8cdc2d0a77104f2a9ae56d83dbbe1890": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "903751eeebe14ef0adb50cd2de8c3b86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fed2cc6740434685ab73f8e86292cf4c",
        "IPY_MODEL_fdd9371d9ccd4b629cc7cae9fda1b015",
        "IPY_MODEL_d5e644bdb58a42eaba556039c1c35a8b"
       ],
       "layout": "IPY_MODEL_dc4a746657284d9cb8b7b21df6eabdfd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "905a4602042f49a2ab744b01c28b9821": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_128364a29cf94353aadf1e7fc3454271",
       "placeholder": "​",
       "style": "IPY_MODEL_806873fdc6844f93857a066ce09a7aa3",
       "tabbable": null,
       "tooltip": null,
       "value": "validation-00000-of-00001.parquet: 100%"
      }
     },
     "91a3e76da1954fbb8a363ccbcc7e34b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "925cfb365fc94bd1b3fb7c9d2336d161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_76839a3f4e0345fdb0078bde3c61f3e5",
        "IPY_MODEL_f2a77d5d1c804922824b577a9b5551cf",
        "IPY_MODEL_7d0c0b7bd1644e49a4862bcf0efdbb80"
       ],
       "layout": "IPY_MODEL_0368d3b1fa8d4284ae84747e0442e694",
       "tabbable": null,
       "tooltip": null
      }
     },
     "92e6ce0e2c5744cbad419966188bcd35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "92ebf0c2f9824b26af36f1500faad697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5076c72b55194161ab04c04b690205b5",
       "max": 10464.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fdccab30efa6422a99e5a112d93d9bcc",
       "tabbable": null,
       "tooltip": null,
       "value": 10464.0
      }
     },
     "93c6dea39ecc4117a269b75ca3005844": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_210999813d6c4bbb81fc00b64211576e",
        "IPY_MODEL_2344527042bc4d43a337fe666e9abf1b",
        "IPY_MODEL_866785875aaa45398340651ecc45255c"
       ],
       "layout": "IPY_MODEL_6293f2d6010b43a283f77b32eb3851b9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "946c0155ddd242cc8accd35e31237bce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "987e71c296134d5c9b8d32d5a8144f29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9aa1f970218e41208cc020270b48deb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ebf84a4dfbc42ce907dda52f9bb2757",
       "placeholder": "​",
       "style": "IPY_MODEL_c831530807a84c5f9ebd67f3e5db226f",
       "tabbable": null,
       "tooltip": null,
       "value": "Generating validation split: 100%"
      }
     },
     "9d9c0499cf8b4d7e80c9d32280d6829e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_12535bc3f6e0498596713bcb59c7f071",
        "IPY_MODEL_456e93864f95433a9d7e6b0ed1fa2dac",
        "IPY_MODEL_a1f3725a99e146a9b7f62a4a60e4cf00"
       ],
       "layout": "IPY_MODEL_a0171b6154ca4e629eccb91290729936",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9db0717bfd8f483aa2d635fa1d7d74f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0171b6154ca4e629eccb91290729936": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1f3725a99e146a9b7f62a4a60e4cf00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_749e095378574ba8b62864b1fb6264b1",
       "placeholder": "​",
       "style": "IPY_MODEL_adb1edb19dab462c98d35c93b2775770",
       "tabbable": null,
       "tooltip": null,
       "value": " 733k/733k [00:00&lt;00:00, 11.6MB/s]"
      }
     },
     "a505dc9a9bc14c40bd687e5d93043fcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a5236ba602904a9dbca612ea0d1804e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adb1edb19dab462c98d35c93b2775770": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "af9988fae99e43ceabb13342d684f1dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_353e22b1a2a240b3ad0b02adf0b4f5db",
       "placeholder": "​",
       "style": "IPY_MODEL_f05ab1908e1f40df8f9d27d42d4b2998",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "b50d0049e8b9495dba1b26da9b4d8ea2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb49ae763ec74b0f816cc337fdfaf0dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbcf0d5a1cd1404f821e4d445df89d8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d53af3df06a4126a7ea552eb4ba31f5",
       "placeholder": "​",
       "style": "IPY_MODEL_987e71c296134d5c9b8d32d5a8144f29",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 31.2MB/s]"
      }
     },
     "bdfae2685ef9423ab7950feae858bce5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf47683390f24cd487d7eaa5de1b2b5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0ee3691b6064d41875c3363c5f02e8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2842a47adb9431a974c83b798482eae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c7cc092e320f4751b9aa7e2b9d842a94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c831530807a84c5f9ebd67f3e5db226f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb969c767ac14d14a39c5e0f039b68c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc023a9a732c4f67b3cc40dd4754b34d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5236ba602904a9dbca612ea0d1804e7",
       "max": 4358.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_217b420382724205afbc0af0c49c1f49",
       "tabbable": null,
       "tooltip": null,
       "value": 4358.0
      }
     },
     "cd348ae767e94c249153b96a8cfa638f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf68ee4851a94f558c1743c6e421d66a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0794969d0304eef9c09e9115223c03f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1bf2e822fd944f88a9266fb7a5e73dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d22d7d520b0b41f6ba0f0511abeadc28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e86e7d718ef44e8b97cdae2cfd1903db",
        "IPY_MODEL_efcc9d6fad984089b378bbd978b334b4",
        "IPY_MODEL_2dfa62d54f2d4a1e97d8b7aaf8382182"
       ],
       "layout": "IPY_MODEL_63d7e87822d34875ba526006db6c5ba2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d5e644bdb58a42eaba556039c1c35a8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f332e5f76e84a2a92366ec88d8050c0",
       "placeholder": "​",
       "style": "IPY_MODEL_e1ae2728267847a5b21068db9c6150ed",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 4.30kB/s]"
      }
     },
     "d666429f6e354a76a50794dd28ddde0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0794969d0304eef9c09e9115223c03f",
       "placeholder": "​",
       "style": "IPY_MODEL_946c0155ddd242cc8accd35e31237bce",
       "tabbable": null,
       "tooltip": null,
       "value": " 657k/657k [00:00&lt;00:00, 64.3MB/s]"
      }
     },
     "d762f99699f14681916ec5d3f5ec319c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc4a746657284d9cb8b7b21df6eabdfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dff0996fe2a748b69f213dc9a98a4b39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e03e49b071a34088815afd70fd210630": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1ae2728267847a5b21068db9c6150ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e5c93ab96a8d40f884c27c309946de8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e86e7d718ef44e8b97cdae2cfd1903db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7f056091ddd64a11a748f0ff20260fa6",
       "placeholder": "​",
       "style": "IPY_MODEL_eee4114153164294b5513827089888c9",
       "tabbable": null,
       "tooltip": null,
       "value": "train-00000-of-00001.parquet: 100%"
      }
     },
     "e894d002d7544e98b8bd79121cc90547": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e9eacbb63ffd4c609889ab599eed9108": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb0add5147334d1a9576b50b9c040ed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_05d9bf2f75b34bf689ae9716e767fbe4",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_075dd171baa94678a661fb5f7f83f105",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "eee4114153164294b5513827089888c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "efcc9d6fad984089b378bbd978b334b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bdfae2685ef9423ab7950feae858bce5",
       "max": 6357543.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6df0dadf29a8488285fece3436f861fd",
       "tabbable": null,
       "tooltip": null,
       "value": 6357543.0
      }
     },
     "f05ab1908e1f40df8f9d27d42d4b2998": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f2a058d22ea345ea80b92d9e098074fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2a77d5d1c804922824b577a9b5551cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8cdc2d0a77104f2a9ae56d83dbbe1890",
       "max": 440449768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3b4cbb418e3d409a82e0b6b9b6739f7a",
       "tabbable": null,
       "tooltip": null,
       "value": 440449768.0
      }
     },
     "f450a884248443719d596a8ef152ed9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f575aeb93a94483d84c216116c2c1b12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0ee47ab563e94612b1aa7b4cc6fcc615",
       "placeholder": "​",
       "style": "IPY_MODEL_58fbfb77fe644961aea144a4e19fbb41",
       "tabbable": null,
       "tooltip": null,
       "value": "Generating test split: 100%"
      }
     },
     "f6a6524eff974c1281fbf4c9e67e344e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_740143bb7c574ed4bffdcfb3aa1e0d02",
       "max": 3760.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92e6ce0e2c5744cbad419966188bcd35",
       "tabbable": null,
       "tooltip": null,
       "value": 3760.0
      }
     },
     "f831d895684f4ce0b02d29442bf91207": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9b06bdf8f454869998eb94c8fabc4e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdccab30efa6422a99e5a112d93d9bcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fdd9371d9ccd4b629cc7cae9fda1b015": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9db0717bfd8f483aa2d635fa1d7d74f7",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c2842a47adb9431a974c83b798482eae",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "fed2cc6740434685ab73f8e86292cf4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_117d9312cfd948e49546ba3256a6b171",
       "placeholder": "​",
       "style": "IPY_MODEL_113541eaa68b45e98c133fa2a18370da",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "ff686fd48f164e5eaa07a5ef8c40b1e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f450a884248443719d596a8ef152ed9e",
       "placeholder": "​",
       "style": "IPY_MODEL_d1bf2e822fd944f88a9266fb7a5e73dc",
       "tabbable": null,
       "tooltip": null,
       "value": " 4358/4358 [00:00&lt;00:00, 56297.82 examples/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
