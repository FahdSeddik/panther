{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"github_repos_wildcard\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:48:57.474577Z","iopub.execute_input":"2025-06-01T20:48:57.474856Z","iopub.status.idle":"2025-06-01T20:48:57.636211Z","shell.execute_reply.started":"2025-06-01T20:48:57.474833Z","shell.execute_reply":"2025-06-01T20:48:57.635342Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"repo_url = f\"https://{token}@github.com/gaserSami/panther.git\"\nbranch = \"autotuner\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:48:57.637404Z","iopub.execute_input":"2025-06-01T20:48:57.637628Z","iopub.status.idle":"2025-06-01T20:48:57.642607Z","shell.execute_reply.started":"2025-06-01T20:48:57.637610Z","shell.execute_reply":"2025-06-01T20:48:57.641561Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!git clone -b {branch} {repo_url}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:48:57.643524Z","iopub.execute_input":"2025-06-01T20:48:57.643994Z","iopub.status.idle":"2025-06-01T20:49:02.412239Z","shell.execute_reply.started":"2025-06-01T20:48:57.643968Z","shell.execute_reply":"2025-06-01T20:49:02.411166Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'panther'...\nremote: Enumerating objects: 2307, done.\u001b[K\nremote: Counting objects: 100% (296/296), done.\u001b[K\nremote: Compressing objects: 100% (58/58), done.\u001b[K\nremote: Total 2307 (delta 258), reused 248 (delta 238), pack-reused 2011 (from 1)\u001b[K\nReceiving objects: 100% (2307/2307), 38.82 MiB | 18.53 MiB/s, done.\nResolving deltas: 100% (1533/1533), done.\nUpdating files: 100% (198/198), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# First uninstall existing torch, torchvision, torchaudio\n!pip uninstall -y torch torchvision torchaudio\n\n# Install the specified versions from PyTorch's official CUDA 12.4 wheels\n!pip install torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:49:02.414571Z","iopub.execute_input":"2025-06-01T20:49:02.414841Z","iopub.status.idle":"2025-06-01T20:51:57.086598Z","shell.execute_reply.started":"2025-06-01T20:49:02.414812Z","shell.execute_reply":"2025-06-01T20:51:57.085544Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.6.0+cu124\nUninstalling torch-2.6.0+cu124:\n  Successfully uninstalled torch-2.6.0+cu124\nFound existing installation: torchvision 0.21.0+cu124\nUninstalling torchvision-0.21.0+cu124:\n  Successfully uninstalled torchvision-0.21.0+cu124\nFound existing installation: torchaudio 2.6.0+cu124\nUninstalling torchaudio-2.6.0+cu124:\n  Successfully uninstalled torchaudio-2.6.0+cu124\nLooking in indexes: https://download.pytorch.org/whl/cu124\nCollecting torch==2.6.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\nCollecting torchvision==0.21.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\nCollecting torchaudio==2.6.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (11.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cu124) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cu124) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.21.0+cu124) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nDownloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, torchvision\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!mv panther Panther","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:51:57.087946Z","iopub.execute_input":"2025-06-01T20:51:57.088274Z","iopub.status.idle":"2025-06-01T20:51:57.215981Z","shell.execute_reply.started":"2025-06-01T20:51:57.088235Z","shell.execute_reply":"2025-06-01T20:51:57.214829Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:51:57.217153Z","iopub.execute_input":"2025-06-01T20:51:57.217499Z","iopub.status.idle":"2025-06-01T20:51:57.342075Z","shell.execute_reply.started":"2025-06-01T20:51:57.217468Z","shell.execute_reply":"2025-06-01T20:51:57.341017Z"}},"outputs":[{"name":"stdout","text":"Panther\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# %%writefile /kaggle/working/Panther/pawX/setup.py\n# from setuptools import setup\n# from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n\n# setup(\n#     name=\"pawX\",\n#     ext_modules=[\n#         CUDAExtension(\n#             name=\"pawX\",\n#             sources=[\n#                 \"skops.cpp\",\n#                 \"bindings.cpp\",\n#                 \"linear.cpp\",\n#                 \"linear_cuda.cu\",\n#                 \"cqrrpt.cpp\",\n#                 \"rsvd.cpp\",\n#                 \"attention.cpp\",\n#                 \"conv2d.cpp\"\n#             ],\n#             # Use system includes and libraries\n#             include_dirs=[\"/usr/include/x86_64-linux-gnu\"],\n#             library_dirs=[],\n#             libraries=[\"openblas\"],\n#             extra_compile_args={\"cxx\": [\"-O2\", \"-fopenmp\"], \"nvcc\": [\"-O2\"]},\n#             extra_link_args=[\"-llapacke\", \"-lopenblas\"]\n#         )\n#     ],\n#     cmdclass={\"build_ext\": BuildExtension},\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:51:57.343562Z","iopub.execute_input":"2025-06-01T20:51:57.343910Z","iopub.status.idle":"2025-06-01T20:51:57.349314Z","shell.execute_reply.started":"2025-06-01T20:51:57.343870Z","shell.execute_reply":"2025-06-01T20:51:57.348514Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!sudo apt-get install liblapacke-dev","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:51:57.350350Z","iopub.execute_input":"2025-06-01T20:51:57.351310Z","iopub.status.idle":"2025-06-01T20:52:11.837455Z","shell.execute_reply.started":"2025-06-01T20:51:57.351282Z","shell.execute_reply":"2025-06-01T20:52:11.836599Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  liblapacke libtmglib-dev libtmglib3\nSuggested packages:\n  liblapack-doc\nThe following NEW packages will be installed:\n  liblapacke liblapacke-dev libtmglib-dev libtmglib3\n0 upgraded, 4 newly installed, 0 to remove and 87 not upgraded.\nNeed to get 1,071 kB of archives.\nAfter this operation, 12.3 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtmglib3 amd64 3.10.0-2ubuntu1 [144 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblapacke amd64 3.10.0-2ubuntu1 [435 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtmglib-dev amd64 3.10.0-2ubuntu1 [134 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblapacke-dev amd64 3.10.0-2ubuntu1 [358 kB]\nFetched 1,071 kB in 1s (996 kB/s)       \ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\ndebconf: falling back to frontend: Readline\nSelecting previously unselected package libtmglib3:amd64.\n(Reading database ... 129184 files and directories currently installed.)\nPreparing to unpack .../libtmglib3_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking libtmglib3:amd64 (3.10.0-2ubuntu1) ...\nSelecting previously unselected package liblapacke:amd64.\nPreparing to unpack .../liblapacke_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking liblapacke:amd64 (3.10.0-2ubuntu1) ...\nSelecting previously unselected package libtmglib-dev:amd64.\nPreparing to unpack .../libtmglib-dev_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking libtmglib-dev:amd64 (3.10.0-2ubuntu1) ...\nSelecting previously unselected package liblapacke-dev:amd64.\nPreparing to unpack .../liblapacke-dev_3.10.0-2ubuntu1_amd64.deb ...\nUnpacking liblapacke-dev:amd64 (3.10.0-2ubuntu1) ...\nSetting up libtmglib3:amd64 (3.10.0-2ubuntu1) ...\nSetting up liblapacke:amd64 (3.10.0-2ubuntu1) ...\nSetting up libtmglib-dev:amd64 (3.10.0-2ubuntu1) ...\nSetting up liblapacke-dev:amd64 (3.10.0-2ubuntu1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!cd /kaggle/working/Panther/pawX; python setup.py install\n!cd /kaggle/working/Panther/pawX; pip install --no-build-isolation -e .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:52:11.838626Z","iopub.execute_input":"2025-06-01T20:52:11.838914Z","iopub.status.idle":"2025-06-01T20:57:32.157554Z","shell.execute_reply.started":"2025-06-01T20:52:11.838886Z","shell.execute_reply":"2025-06-01T20:57:32.156594Z"}},"outputs":[{"name":"stdout","text":"Detected system: linux\n\u001b[92m[OK] CUDA is available. Detected device capability: 7.5\u001b[0m\n\u001b[92m[OK] Tensor Core support detected based on device capability.\u001b[0m\n\u001b[94m[INFO] Using CUDA source file: ['linear_tc.cu']\u001b[0m\n/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` and ``easy_install``.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://github.com/pypa/setuptools/issues/917 for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nEmitting ninja build file /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n[1/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/cqrrpt.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/cqrrpt.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/cqrrpt.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n[2/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/conv2d.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/conv2d.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/conv2d.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n/kaggle/working/Panther/pawX/conv2d.cpp: In function ‘at::Tensor sketched_conv2d_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const std::vector<long int>&, const std::vector<long int>&, const std::vector<long int>&, const std::optional<at::Tensor>&)’:\n/kaggle/working/Panther/pawX/conv2d.cpp:35:28: warning: unused variable ‘C’ [-Wunused-variable]\n   35 |     int64_t B = x.size(0), C = x.size(1), H = x.size(2), W = x.size(3);\n      |                            ^\n/kaggle/working/Panther/pawX/conv2d.cpp: In function ‘at::Tensor sketched_conv2d_memory_efficient(const at::Tensor&, const at::Tensor&, const at::Tensor&, const std::vector<long int>&, const std::vector<long int>&, const std::vector<long int>&, const std::optional<at::Tensor>&, int64_t)’:\n/kaggle/working/Panther/pawX/conv2d.cpp:160:28: warning: unused variable ‘C’ [-Wunused-variable]\n  160 |     int64_t B = x.size(0), C = x.size(1), H = x.size(2), W = x.size(3);\n      |                            ^\n[3/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/attention.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/attention.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/attention.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n/kaggle/working/Panther/pawX/attention.cpp: In function ‘std::vector<at::Tensor> causal_numerator_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&)’:\n/kaggle/working/Panther/pawX/attention.cpp:128:9: warning: unused variable ‘B’ [-Wunused-variable]\n  128 |     int B = qs.size(0);\n      |         ^\n/kaggle/working/Panther/pawX/attention.cpp:130:9: warning: unused variable ‘H’ [-Wunused-variable]\n  130 |     int H = qs.size(2);\n      |         ^\n/kaggle/working/Panther/pawX/attention.cpp:131:9: warning: unused variable ‘M’ [-Wunused-variable]\n  131 |     int M = qs.size(3);\n      |         ^\n[4/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/bindings.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/bindings.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/bindings.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\nIn file included from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/Exceptions.h:12,\n                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/python.h:11,\n                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:9,\n                 from /kaggle/working/Panther/pawX/attention.h:3,\n                 from /kaggle/working/Panther/pawX/bindings.cpp:1:\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘class pybind11::class_<DistributionFamily>’:\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:2216:7:   required from ‘class pybind11::enum_<DistributionFamily>’\n/kaggle/working/Panther/pawX/bindings.cpp:31:60:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1539:7: warning: ‘pybind11::class_<DistributionFamily>’ declared with greater visibility than its base ‘pybind11::detail::generic_type’ [-Wattributes]\n 1539 | class class_ : public detail::generic_type {\n      |       ^~~~~~\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘class pybind11::class_<Axis>’:\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:2216:7:   required from ‘class pybind11::enum_<Axis>’\n/kaggle/working/Panther/pawX/bindings.cpp:35:32:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1539:7: warning: ‘pybind11::class_<Axis>’ declared with greater visibility than its base ‘pybind11::detail::generic_type’ [-Wattributes]\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘class pybind11::class_<torch::nn::Module, std::shared_ptr<torch::nn::Module> >’:\n/kaggle/working/Panther/pawX/bindings.cpp:124:104:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1539:7: warning: ‘pybind11::class_<torch::nn::Module, std::shared_ptr<torch::nn::Module> >’ declared with greater visibility than its base ‘pybind11::detail::generic_type’ [-Wattributes]\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘class pybind11::class_<sinSRPEImpl, torch::nn::Module, std::shared_ptr<sinSRPEImpl> >’:\n/kaggle/working/Panther/pawX/bindings.cpp:128:73:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1539:7: warning: ‘pybind11::class_<sinSRPEImpl, torch::nn::Module, std::shared_ptr<sinSRPEImpl> >’ declared with greater visibility than its base ‘pybind11::detail::generic_type’ [-Wattributes]\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘pybind11::class_< <template-parameter-1-1>, <template-parameter-1-2> >::class_(pybind11::handle, const char*, const Extra& ...) [with Extra = {pybind11::module_local}; type_ = torch::nn::Module; options = {std::shared_ptr<torch::nn::Module>}]’:\n/kaggle/working/Panther/pawX/bindings.cpp:124:104:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1599:28: warning: ‘pybind11::class_<torch::nn::Module, std::shared_ptr<torch::nn::Module> >::class_<pybind11::module_local>(pybind11::handle, const char*, const pybind11::module_local&)::<lambda(pybind11::detail::internals&)>’ declared with greater visibility than the type of its field ‘pybind11::class_<torch::nn::Module, std::shared_ptr<torch::nn::Module> >::class_<pybind11::module_local>(pybind11::handle, const char*, const pybind11::module_local&)::<lambda(pybind11::detail::internals&)>::<record capture>’ [-Wattributes]\n 1599 |             with_internals([&](internals &internals) {\n      |                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~\n 1600 |                 auto &instances = record.module_local ? get_local_internals().registered_types_cpp\n      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n 1601 |                                                       : internals.registered_types_cpp;\n      |                                                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n 1602 |                 instances[std::type_index(typeid(type_alias))]\n      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n 1603 |                     = instances[std::type_index(typeid(type))];\n      |                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n 1604 |             });\n      |             ~               \n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘pybind11::class_< <template-parameter-1-1>, <template-parameter-1-2> >::class_(pybind11::handle, const char*, const Extra& ...) [with Extra = {}; type_ = sinSRPEImpl; options = {torch::nn::Module, std::shared_ptr<sinSRPEImpl>}]’:\n/kaggle/working/Panther/pawX/bindings.cpp:128:73:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1599:28: warning: ‘pybind11::class_<sinSRPEImpl, torch::nn::Module, std::shared_ptr<sinSRPEImpl> >::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>’ declared with greater visibility than the type of its field ‘pybind11::class_<sinSRPEImpl, torch::nn::Module, std::shared_ptr<sinSRPEImpl> >::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>::<record capture>’ [-Wattributes]\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘pybind11::class_< <template-parameter-1-1>, <template-parameter-1-2> >::class_(pybind11::handle, const char*, const Extra& ...) [with Extra = {}; type_ = DistributionFamily; options = {}]’:\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:2232:67:   required from ‘pybind11::enum_<Type>::enum_(const pybind11::handle&, const char*, const Extra& ...) [with Extra = {}; Type = DistributionFamily]’\n/kaggle/working/Panther/pawX/bindings.cpp:31:60:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1599:28: warning: ‘pybind11::class_<DistributionFamily>::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>’ declared with greater visibility than the type of its field ‘pybind11::class_<DistributionFamily>::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>::<record capture>’ [-Wattributes]\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h: In instantiation of ‘pybind11::class_< <template-parameter-1-1>, <template-parameter-1-2> >::class_(pybind11::handle, const char*, const Extra& ...) [with Extra = {}; type_ = Axis; options = {}]’:\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:2232:67:   required from ‘pybind11::enum_<Type>::enum_(const pybind11::handle&, const char*, const Extra& ...) [with Extra = {}; Type = Axis]’\n/kaggle/working/Panther/pawX/bindings.cpp:35:32:   required from here\n/usr/local/lib/python3.11/dist-packages/torch/include/pybind11/pybind11.h:1599:28: warning: ‘pybind11::class_<Axis>::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>’ declared with greater visibility than the type of its field ‘pybind11::class_<Axis>::class_<>(pybind11::handle, const char*)::<lambda(pybind11::detail::internals&)>::<record capture>’ [-Wattributes]\n[5/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/cuda_tensor_accessor.o.d -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/cuda_tensor_accessor.cu -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/cuda_tensor_accessor.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 --ptxas-options=-v --resource-usage --ptxas-options=-O3 --expt-relaxed-constexpr -lcudart -ltorch -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\nptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n[6/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/linear.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/linear.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/linear.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n[7/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/conv_cuda.o.d -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/conv_cuda.cu -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 --ptxas-options=-v --resource-usage --ptxas-options=-O3 --expt-relaxed-constexpr -lcudart -ltorch -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\nptxas info    : 6 bytes gmem, 48 bytes cmem[4]\nptxas info    : Compiling entry function '_Z20sketched_conv_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEES6_S6_iiiiiiiiiiii' for 'sm_75'\nptxas info    : Function properties for _Z20sketched_conv_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEES6_S6_iiiiiiiiiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 64 registers, 520 bytes cmem[0]\nptxas info    : Compiling entry function '_Z20sketched_conv_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEES4_S4_iiiiiiiiiiii' for 'sm_75'\nptxas info    : Function properties for _Z20sketched_conv_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEES4_S4_iiiiiiiiiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 64 registers, 520 bytes cmem[0]\nptxas info    : Compiling entry function '_Z20sketched_conv_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEES4_S4_iiiiiiiiiiii' for 'sm_75'\nptxas info    : Function properties for _Z20sketched_conv_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEES4_S4_iiiiiiiiiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 64 registers, 520 bytes cmem[0]\n[8/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/rsvd.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/rsvd.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/rsvd.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n/kaggle/working/Panther/pawX/rsvd.cpp: In function ‘at::Tensor powerSketch(const at::Tensor&, int64_t, int64_t, int64_t)’:\n/kaggle/working/Panther/pawX/rsvd.cpp:37:10: warning: unused variable ‘m’ [-Wunused-variable]\n   37 |     auto m = A.size(0);\n      |          ^\n/kaggle/working/Panther/pawX/rsvd.cpp: In function ‘std::tuple<at::Tensor, at::Tensor> blockedQB(const at::Tensor&, int64_t, int64_t, double)’:\n/kaggle/working/Panther/pawX/rsvd.cpp:106:10: warning: unused variable ‘n’ [-Wunused-variable]\n  106 |     auto n = A.size(1);\n      |          ^\n[9/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/skops.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/skops.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/skops.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n[10/12] c++ -MMD -MF /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/spre.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/spre.cpp -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/spre.o -O2 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n[11/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/linear_tc.o.d -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/linear_tc.cu -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/linear_tc.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 --ptxas-options=-v --resource-usage --ptxas-options=-O3 --expt-relaxed-constexpr -lcudart -ltorch -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\nptxas info    : 6 bytes gmem, 48 bytes cmem[4]\nptxas info    : Compiling entry function '_Z30sklinear_backward_grad_S1_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES5_iiii' for 'sm_75'\nptxas info    : Function properties for _Z30sklinear_backward_grad_S1_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES5_iiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 30 registers, 16384 bytes smem, 520 bytes cmem[0]\nptxas info    : Compiling entry function '_Z30sklinear_backward_grad_S1_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES3_iiii' for 'sm_75'\nptxas info    : Function properties for _Z30sklinear_backward_grad_S1_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES3_iiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 36 registers, 16384 bytes smem, 520 bytes cmem[0]\nptxas info    : Compiling entry function '_Z37sklinear_backward_grad_S2_output_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li3EES2_IS3_Li2EES4_iiii' for 'sm_75'\nptxas info    : Function properties for _Z37sklinear_backward_grad_S2_output_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li3EES2_IS3_Li2EES4_iiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 28 registers, 16384 bytes smem, 520 bytes cmem[0]\nptxas info    : Compiling entry function '_Z37sklinear_backward_grad_S2_output_wmmaIfEv22FlexibleTensorAccessorIT_Li3EES0_IS1_Li2EES2_iiii' for 'sm_75'\nptxas info    : Function properties for _Z37sklinear_backward_grad_S2_output_wmmaIfEv22FlexibleTensorAccessorIT_Li3EES0_IS1_Li2EES2_iiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 34 registers, 16384 bytes smem, 520 bytes cmem[0]\nptxas info    : Compiling entry function '_Z37sklinear_backward_grad_S2_interm_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES2_IS3_Li4EEiiii' for 'sm_75'\nptxas info    : Function properties for _Z37sklinear_backward_grad_S2_interm_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES2_IS3_Li4EEiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 35 registers, 16384 bytes smem, 536 bytes cmem[0]\nptxas info    : Compiling entry function '_Z37sklinear_backward_grad_S2_interm_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES0_IS1_Li4EEiiii' for 'sm_75'\nptxas info    : Function properties for _Z37sklinear_backward_grad_S2_interm_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES0_IS1_Li4EEiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 38 registers, 16384 bytes smem, 536 bytes cmem[0]\nptxas info    : Compiling entry function '_Z35sklinear_backward_intermediate_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES5_S2_IS3_Li5EEiiii' for 'sm_75'\nptxas info    : Function properties for _Z35sklinear_backward_intermediate_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES5_S2_IS3_Li5EEiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 44 registers, 24576 bytes smem, 608 bytes cmem[0]\nptxas info    : Compiling entry function '_Z35sklinear_backward_intermediate_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES3_S0_IS1_Li5EEiiii' for 'sm_75'\nptxas info    : Function properties for _Z35sklinear_backward_intermediate_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES3_S0_IS1_Li5EEiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 52 registers, 24576 bytes smem, 608 bytes cmem[0]\nptxas info    : Compiling entry function '_Z28sklinear_forward_output_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li4EES2_IS3_Li3EES5_S2_IS3_Li1EEbS2_IS3_Li2EEiiii' for 'sm_75'\nptxas info    : Function properties for _Z28sklinear_forward_output_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li4EES2_IS3_Li3EES5_S2_IS3_Li1EEbS2_IS3_Li2EEiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 52 registers, 624 bytes cmem[0]\nptxas info    : Compiling entry function '_Z28sklinear_forward_output_wmmaIfEv22FlexibleTensorAccessorIT_Li4EES0_IS1_Li3EES3_S0_IS1_Li1EEbS0_IS1_Li2EEiiii' for 'sm_75'\nptxas info    : Function properties for _Z28sklinear_forward_output_wmmaIfEv22FlexibleTensorAccessorIT_Li4EES0_IS1_Li3EES3_S0_IS1_Li1EEbS0_IS1_Li2EEiiii\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 42 registers, 624 bytes cmem[0]\nptxas info    : Compiling entry function '_Z34sklinear_forward_intermediate_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES5_S2_IS3_Li5EEiiiif' for 'sm_75'\nptxas info    : Function properties for _Z34sklinear_forward_intermediate_wmmaIN3c104HalfEEv22FlexibleTensorAccessorIT_Li2EES2_IS3_Li3EES5_S2_IS3_Li5EEiiiif\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 44 registers, 24576 bytes smem, 612 bytes cmem[0]\nptxas info    : Compiling entry function '_Z34sklinear_forward_intermediate_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES3_S0_IS1_Li5EEiiiif' for 'sm_75'\nptxas info    : Function properties for _Z34sklinear_forward_intermediate_wmmaIfEv22FlexibleTensorAccessorIT_Li2EES0_IS1_Li3EES3_S0_IS1_Li5EEiiiif\n    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info    : Used 52 registers, 24576 bytes smem, 612 bytes cmem[0]\n[12/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/timing.o.d -I/usr/include/x86_64-linux-gnu -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/Panther/pawX/timing.cu -o /kaggle/working/Panther/pawX/build/temp.linux-x86_64-cpython-311/timing.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 --ptxas-options=-v --resource-usage --ptxas-options=-O3 --expt-relaxed-constexpr -lcudart -ltorch -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=pawX -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\nptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/pawX-0.0.0-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n\u001b[0mObtaining file:///kaggle/working/Panther/pawX\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nInstalling collected packages: pawX\n  Attempting uninstall: pawX\n    Found existing installation: pawX 0.0.0\n    Uninstalling pawX-0.0.0:\n      Successfully uninstalled pawX-0.0.0\n  Running setup.py develop for pawX\nSuccessfully installed pawX-0.0.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nimport triton\nprint(triton.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:57:32.161791Z","iopub.execute_input":"2025-06-01T20:57:32.162556Z","iopub.status.idle":"2025-06-01T20:57:34.921030Z","shell.execute_reply.started":"2025-06-01T20:57:32.162518Z","shell.execute_reply":"2025-06-01T20:57:34.920344Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124\n3.2.0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/Panther\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:57:34.921801Z","iopub.execute_input":"2025-06-01T20:57:34.922135Z","iopub.status.idle":"2025-06-01T20:57:34.926412Z","shell.execute_reply.started":"2025-06-01T20:57:34.922106Z","shell.execute_reply":"2025-06-01T20:57:34.925649Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:57:34.927442Z","iopub.execute_input":"2025-06-01T20:57:34.927687Z","iopub.status.idle":"2025-06-01T20:57:35.069036Z","shell.execute_reply.started":"2025-06-01T20:57:34.927658Z","shell.execute_reply":"2025-06-01T20:57:35.068244Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Panther\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install botorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:57:35.070069Z","iopub.execute_input":"2025-06-01T20:57:35.070359Z","iopub.status.idle":"2025-06-01T20:57:41.749373Z","shell.execute_reply.started":"2025-06-01T20:57:35.070330Z","shell.execute_reply":"2025-06-01T20:57:41.748041Z"}},"outputs":[{"name":"stdout","text":"Collecting botorch\n  Downloading botorch-0.14.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.13.2)\nCollecting pyre_extensions (from botorch)\n  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\nCollecting gpytorch==1.14 (from botorch)\n  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\nCollecting linear_operator==0.6 (from botorch)\n  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.6.0+cu124)\nCollecting pyro-ppl>=1.8.4 (from botorch)\n  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.15.2)\nRequirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\nRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.6.0)\nCollecting jaxtyping (from gpytorch==1.14->botorch)\n  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.2.2)\nRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\nCollecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\nRequirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyre_extensions->botorch) (0.9.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2.4.1)\nCollecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch==1.14->botorch)\n  Downloading wadler_lindig-0.1.6-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyre_extensions->botorch) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.7->pyro-ppl>=1.8.4->botorch) (2024.2.0)\nDownloading botorch-0.14.0-py3-none-any.whl (738 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.3/738.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\nDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\nDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wadler_lindig-0.1.6-py3-none-any.whl (20 kB)\nInstalling collected packages: pyro-api, wadler-lindig, pyre_extensions, jaxtyping, linear_operator, pyro-ppl, gpytorch, botorch\nSuccessfully installed botorch-0.14.0 gpytorch-1.14 jaxtyping-0.3.2 linear_operator-0.6 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 wadler-lindig-0.1.6\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import copy\nimport os\nimport random\n\nimport torch\nimport torch.nn as nn\n\nfrom panther.utils import *\nfrom panther.tuner import (\n    ConfigVisualizer,\n    EvolutionaryAlgorithm,\n    GridSearch,\n    Hyperband,\n    LayerConfig,\n    ModelVisualizer,\n    ParticleSwarmOptimization,\n    RandomSearch,\n    SearchAlgorithm,\n    SimulatedAnnealing,\n    SKAutoTuner,\n    TreeParzenEstimator,\n    TuningConfigs,\n)\n\n# For reproducibility\ntorch.manual_seed(0)\nrandom.seed(0)\n\n# 1. Define a simple PyTorch model\nimport torch.nn as nn\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Input: 3 channels, e.g., (batch_size, 3, 64, 64)\n\n        # We need out_channels > 1024 and < 7000\n        self.conv1 = nn.Conv2d(\n            in_channels=3, out_channels=2048, kernel_size=3, padding=1\n        )\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        # Output after pool1: (batch_size, 2048, 32, 32)\n\n        # Add another pooling layer to further reduce spatial dimensions\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        # Output after pool2: (batch_size, 2048, 16, 16)\n\n        self.flatten = nn.Flatten()\n        # Calculate new flattened size based on output of pool2\n        # (out_channels from conv1 * H_after_pool2 * W_after_pool2)\n        # 2048 * 16 * 16 = 524288\n        flattened_size = 2048 * 16 * 16\n\n        # One fully connected layer\n        # Input features must be new flattened_size (reduced)\n        # Output features needs to be > 1024 and < 7000 (maintained)\n        self.fc1 = nn.Linear(flattened_size, 4096)\n\n    def forward(self, x):\n        x = self.relu1(self.conv1(x))\n        x = self.pool1(x)\n        x = self.pool2(x) # Apply the second pooling layer\n        x = self.flatten(x)\n        x = self.fc1(x)\n        return x\n\n# 2. Define evaluation functions\ndef dummy_accuracy_eval_func(model: nn.Module) -> float:\n    \"\"\"\n    A dummy accuracy evaluation function.\n    In a real scenario, this would evaluate the model on a validation dataset.\n    This function gives slightly higher accuracy if layers are sketched.\n    \"\"\"\n    base_accuracy = 0.6\n    sketched_bonus = 0.0\n    num_sketched = 0\n    for module in model.modules():\n        if \"SK\" in type(module).__name__:  # Check if it's a sketched layer\n            sketched_bonus += 0.05\n            num_sketched += 1\n            # Example: Favor specific sketch parameters for variety in results\n            if hasattr(module, \"num_terms\") and hasattr(module, \"low_rank\"):\n                if module.num_terms > 15:  # Arbitrary condition for demo\n                    sketched_bonus += 0.02\n                if module.low_rank < 10:  # Arbitrary condition for demo\n                    sketched_bonus += 0.01\n\n    # Simulate some noise or dependency on parameters\n    if num_sketched > 0:\n        # Small random factor to make tuning non-deterministic if not for seed\n        return min(1.0, base_accuracy + sketched_bonus + random.uniform(-0.01, 0.01))\n    return base_accuracy + random.uniform(-0.01, 0.01)\n\n\ndef dummy_optimization_eval_func(model: nn.Module) -> float:\n    \"\"\"\n    A dummy optimization evaluation function (e.g., inference speed).\n    Higher is better. This function simulates that sketched layers are faster.\n    \"\"\"\n    simulated_latency = 0.05  # Base latency\n    for module in model.modules():\n        if isinstance(module, (nn.Linear, nn.Conv2d)):\n            params = sum(p.numel() for p in module.parameters())\n            if \"SK\" in type(module).__name__:  # Sketched layer\n                simulated_latency += 0.0000005 * params  # Sketched layers are faster\n            else:  # Original layer\n                simulated_latency += 0.0000025 * params\n\n    # Score is inverse of latency (higher score = faster)\n    return 1.0 / simulated_latency if simulated_latency > 0 else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:57:41.750967Z","iopub.execute_input":"2025-06-01T20:57:41.751359Z","iopub.status.idle":"2025-06-01T20:57:44.500767Z","shell.execute_reply.started":"2025-06-01T20:57:41.751313Z","shell.execute_reply":"2025-06-01T20:57:44.499848Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(\"SKAutoTuner Example Script\")\nprint(\"==========================\")\n\n# Create dummy input for model (batch_size=1, 3 channels, 32x32 image)\ndummy_input = torch.randn(1, 3, 32, 32)\n\n# --- Initial Model ---\noriginal_model = SimpleModel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:57:44.501775Z","iopub.execute_input":"2025-06-01T20:57:44.502177Z","iopub.status.idle":"2025-06-01T20:58:04.910649Z","shell.execute_reply.started":"2025-06-01T20:57:44.502149Z","shell.execute_reply":"2025-06-01T20:58:04.909956Z"}},"outputs":[{"name":"stdout","text":"SKAutoTuner Example Script\n==========================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(\"\\n--- Original Model Summary ---\")\n# To use print_model_summary, we need a tuner instance with the model\n# temp_tuner_orig = SKAutoTuner(original_model, TuningConfigs([]), lambda m: 0.0)\n# temp_tuner_orig.print_model_summary()\n\n# --- Configuration for Tuning ---\n# Define which layers to tune and with what parameters\n# Note: Keep parameter ranges small for quick example execution.\ntuning_configs = TuningConfigs(configs=[\n    LayerConfig(\n        layer_names=[\"fc1\"],\n        params={'num_terms': [1, 2, 3], 'low_rank': [32, 64, 128, 16]},\n        separate=True,  # Tune this layer group separately\n        copy_weights=True,\n    ),\n    # LayerConfig(\n    #     layer_names=[\"conv1\"],\n    #     params=\"auto\",\n    #     separate=True,  # Tune this layer group separately\n    #     copy_weights=True,\n    # )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:58:04.911480Z","iopub.execute_input":"2025-06-01T20:58:04.911721Z","iopub.status.idle":"2025-06-01T20:58:04.916975Z","shell.execute_reply.started":"2025-06-01T20:58:04.911704Z","shell.execute_reply":"2025-06-01T20:58:04.916226Z"}},"outputs":[{"name":"stdout","text":"\n--- Original Model Summary ---\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Create a copy of the model for the main tuning process\nmodel_for_tuning = copy.deepcopy(original_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:58:04.917894Z","iopub.execute_input":"2025-06-01T20:58:04.918629Z","iopub.status.idle":"2025-06-01T20:58:09.009322Z","shell.execute_reply.started":"2025-06-01T20:58:04.918609Z","shell.execute_reply":"2025-06-01T20:58:09.008576Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# --- Instantiate SKAutoTuner ---\nprint(\"\\n--- Initializing SKAutoTuner for Tuning ---\")\ntuner = SKAutoTuner(\n    model=model_for_tuning,\n    configs=tuning_configs,\n    accuracy_eval_func=dummy_accuracy_eval_func,\n    optmization_eval_func=dummy_optimization_eval_func,\n    accuracy_threshold=0.65,  # Aim for at least this accuracy\n    verbose=True,\n    num_runs_per_param=1,  # For faster example execution\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:58:09.010266Z","iopub.execute_input":"2025-06-01T20:58:09.010560Z","iopub.status.idle":"2025-06-01T20:58:09.016063Z","shell.execute_reply.started":"2025-06-01T20:58:09.010534Z","shell.execute_reply":"2025-06-01T20:58:09.015351Z"}},"outputs":[{"name":"stdout","text":"\n--- Initializing SKAutoTuner for Tuning ---\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(tuner.getConfigs())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:58:09.016844Z","iopub.execute_input":"2025-06-01T20:58:09.017187Z","iopub.status.idle":"2025-06-01T20:58:09.034120Z","shell.execute_reply.started":"2025-06-01T20:58:09.017090Z","shell.execute_reply":"2025-06-01T20:58:09.033472Z"}},"outputs":[{"name":"stdout","text":"TuningConfigs(configs=[LayerConfig(layer_names=['fc1'], params={'num_terms': [1, 2, 3], 'low_rank': [32, 64, 128, 16]}, separate=True, copy_weights=True)])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# --- 1. Tune the model ---\nprint(\"\\n--- Starting Tuning Process (tune) ---\")\ntuner.tune()\nprint(\"Tuning finished.\")\n\n# --- 2. Get Best Parameters ---\nprint(\"\\n--- Best Parameters Found (get_best_params) ---\")\nbest_params = tuner.get_best_params()\nfor layer_name, params_info in best_params.items():\n    print(f\"Layer: {layer_name}, Best Params: {params_info['params']}\")\n\n# --- 3. Get Results DataFrame ---\nprint(\"\\n--- Tuning Results DataFrame (get_results_dataframe) ---\")\n# This requires pandas to be installed.\ntry:\n    results_df = tuner.get_results_dataframe()\n    print(results_df.to_string())\nexcept ImportError:\n    print(\"Pandas not installed. Skipping get_results_dataframe().\")\nexcept Exception as e:\n    print(f\"Could not generate DataFrame: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T20:58:09.034938Z","iopub.execute_input":"2025-06-01T20:58:09.035155Z","iopub.status.idle":"2025-06-01T21:00:38.944863Z","shell.execute_reply.started":"2025-06-01T20:58:09.035139Z","shell.execute_reply":"2025-06-01T21:00:38.943972Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Tuning Process (tune) ---\nTuning layer: fc1\nTrying parameters: {'num_terms': 1, 'low_rank': 32}\nReplaced fc1 with sketched version using parameters: {'num_terms': 1, 'low_rank': 32}\nrun: 1/1 - accuracy_score: 0.656888437030501, speed_score: 5.171700455109639, final score: 5.171700455109639\nTried parameters: {'num_terms': 1, 'low_rank': 32}, accuracy_score: 0.656888437030501, speed_score: 5.171700455109639, final score: 5.171700455109639\nTrying parameters: {'num_terms': 1, 'low_rank': 64}\nReplaced fc1 with sketched version using parameters: {'num_terms': 1, 'low_rank': 64}\nrun: 1/1 - accuracy_score: 0.6551590880588061, speed_score: 5.171700455109639, final score: 5.171700455109639\nTried parameters: {'num_terms': 1, 'low_rank': 64}, accuracy_score: 0.6551590880588061, speed_score: 5.171700455109639, final score: 5.171700455109639\nTrying parameters: {'num_terms': 1, 'low_rank': 128}\nReplaced fc1 with sketched version using parameters: {'num_terms': 1, 'low_rank': 128}\nrun: 1/1 - accuracy_score: 0.648411431616617, speed_score: None, final score: -inf\nTried parameters: {'num_terms': 1, 'low_rank': 128}, accuracy_score: -inf, speed_score: -inf, final score: -inf\nTrying parameters: {'num_terms': 1, 'low_rank': 16}\nReplaced fc1 with sketched version using parameters: {'num_terms': 1, 'low_rank': 16}\nrun: 1/1 - accuracy_score: 0.6451783350058593, speed_score: None, final score: -inf\nTried parameters: {'num_terms': 1, 'low_rank': 16}, accuracy_score: -inf, speed_score: -inf, final score: -inf\nTrying parameters: {'num_terms': 2, 'low_rank': 32}\nReplaced fc1 with sketched version using parameters: {'num_terms': 2, 'low_rank': 32}\nrun: 1/1 - accuracy_score: 0.6502254944273722, speed_score: 5.171700455109639, final score: 5.171700455109639\nTried parameters: {'num_terms': 2, 'low_rank': 32}, accuracy_score: 0.6502254944273722, speed_score: 5.171700455109639, final score: 5.171700455109639\nTrying parameters: {'num_terms': 2, 'low_rank': 64}\nReplaced fc1 with sketched version using parameters: {'num_terms': 2, 'low_rank': 64}\nrun: 1/1 - accuracy_score: 0.6480986827490083, speed_score: None, final score: -inf\nTried parameters: {'num_terms': 2, 'low_rank': 64}, accuracy_score: -inf, speed_score: -inf, final score: -inf\nTrying parameters: {'num_terms': 2, 'low_rank': 128}\nReplaced fc1 with sketched version using parameters: {'num_terms': 2, 'low_rank': 128}\nrun: 1/1 - accuracy_score: 0.6556759717806955, speed_score: 5.171700455109639, final score: 5.171700455109639\nTried parameters: {'num_terms': 2, 'low_rank': 128}, accuracy_score: 0.6556759717806955, speed_score: 5.171700455109639, final score: 5.171700455109639\nTrying parameters: {'num_terms': 2, 'low_rank': 16}\nReplaced fc1 with sketched version using parameters: {'num_terms': 2, 'low_rank': 16}\nrun: 1/1 - accuracy_score: 0.6460662545215786, speed_score: None, final score: -inf\nTried parameters: {'num_terms': 2, 'low_rank': 16}, accuracy_score: -inf, speed_score: -inf, final score: -inf\nTrying parameters: {'num_terms': 3, 'low_rank': 32}\nReplaced fc1 with sketched version using parameters: {'num_terms': 3, 'low_rank': 32}\nrun: 1/1 - accuracy_score: 0.6495319390830472, speed_score: None, final score: -inf\nTried parameters: {'num_terms': 3, 'low_rank': 32}, accuracy_score: -inf, speed_score: -inf, final score: -inf\nTrying parameters: {'num_terms': 3, 'low_rank': 64}\nReplaced fc1 with sketched version using parameters: {'num_terms': 3, 'low_rank': 64}\nrun: 1/1 - accuracy_score: 0.6516676407891007, speed_score: 5.171700455109639, final score: 5.171700455109639\nTried parameters: {'num_terms': 3, 'low_rank': 64}, accuracy_score: 0.6516676407891007, speed_score: 5.171700455109639, final score: 5.171700455109639\n  Best parameters for fc1: {'num_terms': 1, 'low_rank': 32}, score: 5.171700455109639\nTuning finished.\n\n--- Best Parameters Found (get_best_params) ---\nLayer: fc1, Best Params: {'num_terms': 1, 'low_rank': 32}\n\n--- Tuning Results DataFrame (get_results_dataframe) ---\n  layer_name  num_terms  low_rank   score\n0        fc1          1        32  5.1717\n1        fc1          1        64  5.1717\n2        fc1          1       128    -inf\n3        fc1          1        16    -inf\n4        fc1          2        32  5.1717\n5        fc1          2        64    -inf\n6        fc1          2       128  5.1717\n7        fc1          2        16    -inf\n8        fc1          3        32    -inf\n9        fc1          3        64  5.1717\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"tuner.get_best_params()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T21:00:38.945826Z","iopub.execute_input":"2025-06-01T21:00:38.946084Z","iopub.status.idle":"2025-06-01T21:00:38.952407Z","shell.execute_reply.started":"2025-06-01T21:00:38.946057Z","shell.execute_reply":"2025-06-01T21:00:38.951536Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'fc1': {'params': {'num_terms': 1, 'low_rank': 32},\n  'copy_weights': True,\n  'best_layer': SKLinear()}}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# --- 4. Apply Best Parameters ---\nprint(\"\\n--- Applying Best Parameters to the Model (apply_best_params) ---\")\n# tuner.model is modified in-place by apply_best_params()\ntuned_model_explicit_return = tuner.apply_best_params()\nprint(\"Model summary before tuning:\")\nsummary = ModelVisualizer.get_model_summary_data(original_model, None)\nprint(summary)\nprint(\"Best parameters applied. Model summary after tuning:\")\nsummary = ModelVisualizer.get_model_summary_data(tuned_model_explicit_return, None)\nprint(summary)\n\n# --- 5. Visualize Tuning Results ---\nprint(\"\\n--- Visualizing Tuning Results (visualize_tuning_results) ---\")\n# This requires matplotlib and pandas.\n# Create a directory for plots if it doesn't exist.\nviz_dir = \"tuning_visualizations\"\nif not os.path.exists(viz_dir):\n    os.makedirs(viz_dir)\nviz_path = os.path.join(viz_dir, \"tuning_visualization.png\")\ntry:\n    tuner.visualize_tuning_results(save_path=viz_path, show_plot=False)\n    print(f\"Tuning visualization saved to {viz_path}\")\n    print(\"To view the plot, open the saved image file.\")\nexcept ImportError:\n    print(\n        \"Matplotlib or Pandas not installed. Skipping visualize_tuning_results().\"\n    )\nexcept Exception as e:\n    print(f\"Could not visualize results: {e}\")\n    if \"No variable parameters found to visualize\" in str(e):\n        print(\n            \"This can happen if all parameter combinations resulted in the same score or only one combination was tried.\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T21:00:38.953242Z","iopub.execute_input":"2025-06-01T21:00:38.953516Z","iopub.status.idle":"2025-06-01T21:00:39.754169Z","shell.execute_reply.started":"2025-06-01T21:00:38.953478Z","shell.execute_reply":"2025-06-01T21:00:39.752976Z"}},"outputs":[{"name":"stdout","text":"\n--- Applying Best Parameters to the Model (apply_best_params) ---\ndebug, data: {'params': {'num_terms': 1, 'low_rank': 32}, 'copy_weights': True, 'best_layer': SKLinear()}\nreplaced fc1 with SKLinear\nModel summary before tuning:\n{'total_params': 2147545088, 'sketched_layers': 0, 'layers': [{'name': 'conv1', 'type': 'Conv2d', 'params': 57344, 'is_sketched': False}, {'name': 'relu1', 'type': 'ReLU', 'params': 0, 'is_sketched': False}, {'name': 'pool1', 'type': 'MaxPool2d', 'params': 0, 'is_sketched': False}, {'name': 'pool2', 'type': 'MaxPool2d', 'params': 0, 'is_sketched': False}, {'name': 'flatten', 'type': 'Flatten', 'params': 0, 'is_sketched': False}, {'name': 'fc1', 'type': 'Linear', 'params': 2147487744, 'is_sketched': False}]}\nBest parameters applied. Model summary after tuning:\n{'total_params': 16969728, 'sketched_layers': 0, 'layers': [{'name': 'conv1', 'type': 'Conv2d', 'params': 57344, 'is_sketched': False}, {'name': 'relu1', 'type': 'ReLU', 'params': 0, 'is_sketched': False}, {'name': 'pool1', 'type': 'MaxPool2d', 'params': 0, 'is_sketched': False}, {'name': 'pool2', 'type': 'MaxPool2d', 'params': 0, 'is_sketched': False}, {'name': 'flatten', 'type': 'Flatten', 'params': 0, 'is_sketched': False}, {'name': 'fc1', 'type': 'SKLinear', 'params': 16912384, 'is_sketched': False}]}\n\n--- Visualizing Tuning Results (visualize_tuning_results) ---\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/Panther/panther/tuner/SkAutoTuner/SKAutoTuner.py:833: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n/kaggle/working/Panther/panther/tuner/SkAutoTuner/SKAutoTuner.py:837: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n","output_type":"stream"},{"name":"stdout","text":"Visualization saved to tuning_visualizations/tuning_visualization.png\nTuning visualization saved to tuning_visualizations/tuning_visualization.png\nTo view the plot, open the saved image file.\n\n--- Explicit call to get_model_summary (on tuned model) ---\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/649409123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# tuner.print_model_summary() was already called after apply_best_params,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# this shows how to get the raw dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel_summary_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total parameters in tuned model: {model_summary_dict['total_params']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of sketched layers: {model_summary_dict['sketched_layers']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'SKAutoTuner' object has no attribute 'get_model_summary'"],"ename":"AttributeError","evalue":"'SKAutoTuner' object has no attribute 'get_model_summary'","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"# --- 7. Get Model Summary (Explicitly from Tuned Model) ---\nprint(\"\\n--- Explicit call to get_model_summary (on tuned model) ---\")\n# tuner.print_model_summary() was already called after apply_best_params,\n# this shows how to get the raw dictionary.\n\nModelVisualizer.visualize_parameter_distribution(\n   model = tuned_model_explicit_return, is_sketched_func=None, save_path=\"/tmp/\", show_plot=True\n)\n\n# Ensure original_model is pristine.\nModelVisualizer.print_comparison_summary_text(original_model, tuned_model_explicit_return)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T21:04:00.920600Z","iopub.execute_input":"2025-06-01T21:04:00.921239Z","iopub.status.idle":"2025-06-01T21:04:01.155429Z","shell.execute_reply.started":"2025-06-01T21:04:00.921188Z","shell.execute_reply":"2025-06-01T21:04:01.154503Z"}},"outputs":[{"name":"stdout","text":"\n--- Explicit call to get_model_summary (on tuned model) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x700 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAArIAAAKyCAYAAAApeT2AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABvDUlEQVR4nO3dd3hUZf7+8Xsy6YWEFFrovQsiKBbARhFR14LYwO6usrq7P8t3dV3rFuvaC7qCBXRFrCigKCjSpPceQgklDdKTaef3BxIJBAghmWdmzvt1XVyQyWTmnhAOd558znMclmVZAgAAAIJMmOkAAAAAQG1QZAEAABCUKLIAAAAIShRZAAAABCWKLAAAAIISRRYAAABBiSILAACAoESRBQAAQFCiyAIAACAoUWQBBKwbb7xRrVu39stztW7dWjfeeGPl2xMmTJDD4dDixYv98vyDBg3SoEGD/PJch/L36wSAukSRhW0d/A/84K/o6Gh17NhRY8eO1d69e03Hq1fz5s3To48+qv379/vtOR999NEqn+/Y2Fi1bNlSI0aM0Pjx41VRUVEnz7N27Vo9+uijyszMrJPHq0uBnK2+3XjjjYqPjzcd46TdeOONVb6Oj/br0G+KANSfcNMBANMef/xxtWnTRuXl5fr555/1+uuv65tvvtHq1asVGxtrOl69mDdvnh577DHdeOONSkpK8utzv/7664qPj1dFRYWysrI0Y8YM3XzzzXrhhRc0depUtWjRovK+b731lnw+3wk9/tq1a/XYY49p0KBBJ7Sau2HDBoWF1e/39sfK9u2339brc6Nu3HHHHbrgggsq3966dav+/ve/6/bbb9c555xTeXu7du1MxANshyIL2xs2bJhOO+00SdKtt96qlJQUPf/88/riiy90zTXX1PpxfT6fXC6XoqOj6ypqwCstLT1u+b/yyiuVmppa+fbf//53TZw4UaNHj9ZVV12lBQsWVL4vIiKi3rJKkmVZKi8vV0xMjKKiour1uY4nMjLS6POjqvLyckVGRh7xzU3//v3Vv3//yrcXL16sv//97+rfv7+uv/56f8cEbI/RAuAw5513nqQDKy2S9Oyzz+rMM89USkqKYmJi1KdPH33yySdHfJzD4dDYsWM1ceJEdevWTVFRUZo+fXqtHmPy5Mnq2rWrYmJi1L9/f61atUqS9Oabb6p9+/aKjo7WoEGDqv0R9cKFCzV06FAlJiYqNjZWAwcO1Ny5cyvf/+ijj+q+++6TJLVp06byR6GHPtYHH3ygPn36KCYmRsnJyRo1apR27NhR5XkGDRqk7t27a8mSJRowYIBiY2P14IMPnsBn+jfXXXedbr31Vi1cuFDfffdd5e3Vzch+9NFH6tOnjxISEtSgQQP16NFDL774oqQD4yJXXXWVJOncc8+tfG2zZ8+WdGAO9uKLL9aMGTN02mmnKSYmRm+++Wbl+6r7cXBpaanuuOMOpaSkqEGDBho9erT27dtX5T4Oh0OPPvroER976GMeL1t1M7LZ2dm65ZZb1LhxY0VHR+uUU07Ru+++W+U+mZmZcjgcevbZZzVu3Di1a9dOUVFR6tu3rxYtWlTt57s6x3udY8aMUWpqqtxu9xEfO3jwYHXq1KnGz3U027Zt05133qlOnTopJiZGKSkpuuqqq6p8bWZkZMjhcOg///nPER8/b948ORwOffjhh5W3ZWVl6eabb1bjxo0VFRWlbt266Z133qnycbNnz5bD4dBHH32kv/3tb0pPT1dsbKwKCwtP+DXMmjVLDodDn3322RHvmzRpkhwOh+bPny/pt3GLjIwMDRkyRHFxcWrWrJkef/xxWZZV5WN9Pp9eeOEFdevWTdHR0WrcuLHuuOOOI74WAbthRRY4zJYtWyRJKSkpkqQXX3xRl1xyia677jq5XC599NFHuuqqqzR16lQNHz68ysf+8MMP+vjjjzV27FilpqZWlrATeYw5c+boyy+/1F133SVJ+te//qWLL75Y999/v1577TXdeeed2rdvn55++mndfPPN+uGHH6o8/7Bhw9SnTx898sgjCgsL0/jx43Xeeedpzpw56tevny6//HJt3LhRH374of7zn/9Uro6mpaVJkv7xj3/o4Ycf1siRI3XrrbcqJydHL7/8sgYMGKBly5ZVGUXIy8vTsGHDNGrUKF1//fVq3LhxrT/vN9xwg8aNG6dvv/1WF154YbX3+e6773TNNdfo/PPP11NPPSVJWrdunebOnat77rlHAwYM0N13362XXnpJDz74oLp06SJJlb9LB0YIrrnmGt1xxx267bbbjlvAxo4dq6SkJD366KPasGGDXn/9dW3btq2y/NRUTbIdqqysTIMGDdLmzZs1duxYtWnTRpMnT9aNN96o/fv365577qly/0mTJqmoqEh33HGHHA6Hnn76aV1++eXKyMio0cr28V7nDTfcoPfee08zZszQxRdfXPlxe/bs0Q8//KBHHnmkxp+Lo1m0aJHmzZunUaNGqXnz5srMzNTrr7+uQYMGae3atYqNjVXbtm111llnaeLEifrzn/9c5eMnTpyohIQEXXrppZKkvXv36owzzqj8BjEtLU3Tpk3TLbfcosLCQv3pT3+q8vFPPPGEIiMjde+996qioqJWq+SDBg1SixYtNHHiRP3ud787Il+7du2qrOh6vV4NHTpUZ5xxhp5++mlNnz5djzzyiDwejx5//PHK+91xxx2aMGGCbrrpJt19993aunWrXnnlFS1btkxz586t959eAAHLAmxq/PjxliRr5syZVk5OjrVjxw7ro48+slJSUqyYmBhr586dlmVZVmlpaZWPc7lcVvfu3a3zzjuvyu2SrLCwMGvNmjVHPNeJPEZUVJS1devWytvefPNNS5LVpEkTq7CwsPL2v/71r5akyvv6fD6rQ4cO1pAhQyyfz1fludu0aWNdeOGFlbc988wzVT72oMzMTMvpdFr/+Mc/qty+atUqKzw8vMrtAwcOtCRZb7zxxhGvtzqPPPKIJcnKycmp9v379u2zJFm/+93vKm8bM2aM1apVq8q377nnHqtBgwaWx+M56vNMnjzZkmTNmjXriPe1atXKkmRNnz692veNGTOm8u2DXx99+vSxXC5X5e1PP/20Jcn64osvKm+TZD3yyCPHfcxjZRs4cKA1cODAyrdfeOEFS5L1wQcfVN7mcrms/v37W/Hx8ZVfC1u3brUkWSkpKVZ+fn7lfb/44gtLkvXVV18d8VyHqunr9Hq9VvPmza2rr766ysc///zzlsPhsDIyMo75PGPGjLHi4uKOeZ/D/51YlmXNnz/fkmS99957lbcd/Dexbt26yttcLpeVmppa5fN9yy23WE2bNrVyc3OrPOaoUaOsxMTEyuebNWuWJclq27ZttRmOZdGiRZYka/z48ZW3/fWvf7WioqKs/fv3V96WnZ1thYeHV/k6GTNmjCXJ+uMf/1h5m8/ns4YPH25FRkZW/luZM2eOJcmaOHFileeePn16tbcDdsJoAWzvggsuUFpamlq0aKFRo0YpPj5en332mdLT0yVJMTExlffdt2+fCgoKdM4552jp0qVHPNbAgQPVtWvXI24/kcc4//zzq/w4/fTTT5ckXXHFFUpISDji9oyMDEnS8uXLtWnTJl177bXKy8tTbm6ucnNzVVJSovPPP18//fTTcU+c+vTTT+Xz+TRy5MjKj8/NzVWTJk3UoUMHzZo1q8r9o6KidNNNNx3zMWvq4BntRUVFR71PUlKSSkpKqowfnKg2bdpoyJAhNb7/7bffXmW16w9/+IPCw8P1zTff1DpDTXzzzTdq0qRJlTntiIgI3X333SouLtaPP/5Y5f5XX321GjZsWPn2wROPDn59HM/xXmdYWJiuu+46ffnll1X+jiZOnKgzzzxTbdq0OfEXeZhD/5243W7l5eWpffv2SkpKqvJvZeTIkYqOjtbEiRMrb5sxY4Zyc3Mr51Qty9KUKVM0YsQIWZZV5et5yJAhKigoOOLf35gxY6pkqK3Ro0eroqKiyvjQ//73P3k8nmrnaMeOHVv554Orxy6XSzNnzpQkTZ48WYmJibrwwgurvI4+ffooPj7+iH+XgJ0wWgDbe/XVV9WxY0eFh4ercePG6tSpU5UTPKZOnaonn3xSy5cvr7JFVHU/Vj7af+Yn8hgtW7as8nZiYqIkVTmb/9DbD87Ibdq0SdKB/4yPpqCgoErZOdymTZtkWZY6dOhQ7fsP//Flenp6nZ2kVFxcLElVyvrh7rzzTn388ccaNmyY0tPTNXjwYI0cOVJDhw6t8fOcaOE6/HMRHx+vpk2b1vsWWtu2bVOHDh2OONno4CjCtm3bqtx++NfNwb/nms5Q1uR1jh49Wk899ZQ+++wzjR49Whs2bNCSJUv0xhtv1Og5jqesrEz/+te/NH78eGVlZVWZEy0oKKj8c1JSkkaMGKFJkybpiSeekHSgUKenp1fOuOfk5Gj//v0aN26cxo0bV+3zZWdnV3m7Lsq4JHXu3Fl9+/bVxIkTdcstt1TmO+OMM9S+ffsq9w0LC1Pbtm2r3NaxY0dJqvzcb9q0SQUFBWrUqFG1z3f46wDshCIL2+vXr1/lrgWHmzNnji655BINGDBAr732mpo2baqIiAiNHz9ekyZNOuL+1a3mnOhjOJ3OarMc7faD/9kfXG195pln1KtXr2rve7x9PH0+nxwOh6ZNm1bt8x3+8XWxenXQ6tWrJemI/+gP1ahRIy1fvlwzZszQtGnTNG3aNI0fP16jR48+4iSoo6nLzMfj9Xr99lzH+/qoC127dlWfPn30wQcfaPTo0frggw8UGRmpkSNH1snj//GPf9T48eP1pz/9Sf3791diYqIcDodGjRp1xE8TRo8ercmTJ2vevHnq0aOHvvzyS915552Vxf/g/a+//vqjfnPXs2fPKm/X5dfG6NGjdc8992jnzp2qqKjQggUL9Morr9TqsXw+nxo1alRlBfpQB+fbATuiyALHMGXKFEVHR2vGjBlVtmcaP368Xx+jJg7uW9mgQYMq+1xW52gnKbVr106WZalNmzaVq0L+8v7770vScX/sHxkZqREjRmjEiBHy+Xy688479eabb+rhhx9W+/btT+gErJrYtGmTzj333Mq3i4uLtXv3bl100UWVtzVs2PCIi0u4XC7t3r27ym0nkq1Vq1ZauXKlfD5flVXZ9evXV76/LtXkdUoHCtpf/vIX7d69W5MmTdLw4cOPucp/Ij755BONGTNGzz33XOVt5eXl1V64Y+jQoUpLS9PEiRN1+umnq7S0VDfccEPl+9PS0pSQkCCv13vcfw/1YdSoUfrLX/6iDz/8UGVlZYqIiNDVV199xP18Pp8yMjKq/HvbuHGjJFWOGLVr104zZ87UWWed5ddvxIBgwIwscAxOp1MOh6PKylpmZqY+//xzvz5GTfTp00ft2rXTs88+W/lj+kPl5ORU/jkuLk6SjigIl19+uZxOpx577LEjVvIsy1JeXl6dZj5o0qRJevvtt9W/f3+df/75R73f4c8fFhZWuap2cGTjaK+ttsaNG1dly6nXX39dHo9Hw4YNq7ytXbt2+umnn474uMNXZE8k20UXXaQ9e/bof//7X+VtHo9HL7/8suLj4zVw4MDavJyjqsnrlKRrrrlGDodD99xzjzIyMup071Sn03nE193LL79c7cp2eHi4rrnmGn388ceaMGGCevToUWWF1el06oorrtCUKVMqV/sPdei/h/qQmpqqYcOG6YMPPtDEiRM1dOjQKvsnH+rQlVrLsvTKK68oIiKi8t/CyJEj5fV6K8coDuXxePx6hT4g0LAiCxzD8OHD9fzzz2vo0KG69tprlZ2drVdffVXt27fXypUr/fYYNREWFqa3335bw4YNU7du3XTTTTcpPT1dWVlZmjVrlho0aKCvvvpK0oHSK0kPPfSQRo0apYiICI0YMULt2rXTk08+qb/+9a/KzMzUZZddpoSEBG3dulWfffaZbr/9dt17770nlfOTTz5RfHy8XC5X5ZW95s6dq1NOOUWTJ08+5sfeeuutys/P13nnnafmzZtr27Ztevnll9WrV6/K2dFevXrJ6XTqqaeeUkFBgaKionTeeecddb7weFwul84//3yNHDlSGzZs0Guvvaazzz5bl1xySZVcv//973XFFVfowgsv1IoVKzRjxowjisuJZLv99tv15ptv6sYbb9SSJUvUunVrffLJJ5o7d65eeOGFY84S19frlA6sdA4dOlSTJ09WUlLSEdvHHYvb7daTTz55xO3Jycm68847dfHFF+v9999XYmKiunbtqvnz52vmzJmVW+EdbvTo0XrppZc0a9asyu3YDvXvf/9bs2bN0umnn67bbrtNXbt2VX5+vpYuXaqZM2cqPz+/xtlrY/To0bryyislqdoSKknR0dGaPn26xowZo9NPP13Tpk3T119/rQcffLByZGDgwIG644479K9//UvLly/X4MGDFRERoU2bNmny5Ml68cUXK58HsB1DuyUAxh3cdmjRokXHvN9///tfq0OHDlZUVJTVuXNna/z48ZVbSR1KknXXXXfV+WMc3F7pmWeeqXL7wS2DJk+eXOX2ZcuWWZdffrmVkpJiRUVFWa1atbJGjhxpff/991Xu98QTT1jp6elWWFjYEVtxTZkyxTr77LOtuLg4Ky4uzurcubN11113WRs2bKi8z8CBA61u3bod83N3qIOv9+Cv6Ohoq3nz5tbFF19svfPOO1Z5efkRH3P49luffPKJNXjwYKtRo0ZWZGSk1bJlS+uOO+6wdu/eXeXj3nrrLatt27aW0+msst1Vq1atrOHDh1eb72jbb/3444/W7bffbjVs2NCKj4+3rrvuOisvL6/Kx3q9XuuBBx6wUlNTrdjYWGvIkCHW5s2bj3jMY2U7fPsty7KsvXv3WjfddJOVmppqRUZGWj169KiyzZNlHf3rw7KOvi3YoU7kdR708ccfW5Ks22+//ZiPfaiDW01V96tdu3aWZR3Ygu3g642Pj7eGDBlirV+/vtrP40HdunWzwsLCKrfLO9zevXutu+66y2rRooUVERFhNWnSxDr//POtcePGVd7naP+WaqK67bcOqqiosBo2bGglJiZaZWVl1X5O4uLirC1btliDBw+2YmNjrcaNG1uPPPKI5fV6j7j/uHHjrD59+lgxMTFWQkKC1aNHD+v++++3du3adcK5gVDhsKw6PBMAAFCvJkyYoD/96U9+/XHy999/r7Fjx2r16tVyOp364osvdNlll+mnn36q3ObLhDPOOEN79+5V27Zt9f333xvLcTQej0fNmjXTiBEj9N///veI999444365JNPqh0FAlAzzMgCgJ/t2LFDN998s5o1a6bIyEi1atVK99xzzxEzwK1bt9YLL7xgJuQh7r//fv3tb3+r3BnhrbfeUtu2bXX22WfX6OM//fRTDR48WCkpKXI4HFq+fPkR9/nLX/6i5OTkyqtiHWry5MkaMWLEER9z9dVXKzMzs07ndOvS559/rpycHI0ePdp0FCBkMSMLAH6UkZGh/v37q2PHjvrwww/Vpk0brVmzRvfdd5+mTZumBQsWKDk52e+53G53tZc5/fnnn7VlyxZdccUV+uijj7Ry5Up9/fXXevHFF4+6C4PL5VJ+fr6aNGkiSSopKdHZZ5+tkSNH6rbbbjvi/l999ZUmTZqkb7/9Vps2bdLNN9+sIUOGKDU1VQUFBXrooYcqLw4gHdiqbcmSJRo/frzCwsKqXDY5ECxcuFArV67UE088od69e9f5iXkADmF6tgEA7GTo0KFW8+bNj7gU6u7du63Y2Fjr97//vWVZv10C+NBflnVgpjUxMdGaPn261blzZysuLs4aMmTIEXOSb731ltW5c2crKirK6tSpk/Xqq69Wvu/gXO1HH31kDRgwwIqKiqp2xtOyLOuuu+6yrrzySsuyDszcxsfHW7fccovldruPuO/ixYutsWPHWikpKdYLL7xwxPsPPu+yZcuq3P7UU09VufRto0aNrF9++cWyLMu6/fbbreeff77K/R955BHL4XBYnTt3toYNG2Zdf/311WY3ZcyYMZbT6bT69OljrVq16pj3O95lewEcG0UWAPwkLy/Pcjgc1j//+c9q33/bbbdZDRs2tHw+n5WXl2c1b97cevzxx63du3dXntA2fvx4KyIiwrrgggusRYsWWUuWLLG6dOliXXvttZWP88EHH1hNmza1pkyZYmVkZFhTpkyxkpOTrQkTJliW9VuhbN26deV9jnbCUM+ePa1///vfR31Nu3btsp5++mmrW7duVmRkpPW73/3O+uyzzyyXy3XEfY9WZKdPn261a9fOys/PtxYvXmwlJCRY+fn51pw5c6zTTjvN8ng8R33+119/vcoJgQDshdECAPCTg5cAPrhV2OG6dOmiffv2KScnR40aNZLT6VRCQkLlj+gPcrvdeuONNyovgjF27Fg9/vjjle9/5JFH9Nxzz+nyyy+XdODSq2vXrtWbb75Z5SpXf/rTnyrvczTbtm1Ts2bNqtzmcrn02Wef6d1339V3332n0047TXfddZdGjRpVq4sjDBkyRNdff7369u2rmJgYvfvuu4qLi9Mf/vAHTZgwQa+//rpefvllpaamaty4cerWrVvlxzZr1kw7duw44sIRAOyBIgsAfmad5GYxsbGxlSVWkpo2bars7GxJB+ZRt2zZoltuuaXKPKrH41FiYmKVxznapZkPVVZWpujo6Cq3zZs3T6NGjVKLFi30ww8/1MnOBY8++qgeffTRyrcfe+wxXXDBBYqIiNCTTz6pVatWaerUqRo9erSWLFlSeb+YmBj5fD5VVFRw1SvAhvj2FQD85OAldNetW1ft+9etW6eGDRtWboR/NIeflOVwOCrL8cGtnN566y0tX7688tfq1au1YMGCKh938Epjx5Kamqp9+/ZVua1fv35666231KpVK5133nkaNmyYJk2apNLS0uM+Xk2sX79eH3zwgZ544gnNnj1bAwYMUFpamkaOHKmlS5eqqKio8r75+fmKi4ujxAI2RZEFAD9JSUnRhRdeqNdee01lZWVV3rdnzx5NnDhRV199deVuAJGRkdVenvVYGjdurGbNmikjI0Pt27ev8qtNmzYnnLl3795au3ZtldtiY2N16623as6cOVq/fr369u2rhx56SE2aNNFNN92kH374QT6f74SfSzqwWn3HHXfo+eefV3x8vLxeb+Wlcw/+fujnZPXq1erdu3etngtA8KPIAoAfvfLKK6qoqNCQIUP0008/aceOHZo+fbouvPBCpaen6x//+EflfVu3bq2ffvpJWVlZys3NrfFzPPbYY/rXv/6ll156SRs3btSqVas0fvx4Pf/88yecd8iQIfr555+P+v527drp8ccfV0ZGhr788ktZlqVLL71Ur776auV98vPztXz58spCvGHDBi1fvlx79uw54vHefvttpaWlVe4be9ZZZ+mHH37QggUL9J///Eddu3atst3WnDlzNHjw4BN+XQBChNFTzQDAhjIzM60xY8ZYjRs3tiIiIqwWLVpYf/zjH63c3Nwq95s/f77Vs2dPKyoq6ojttw712WefHXG544kTJ1q9evWyIiMjrYYNG1oDBgywPv30U8uyjr57QHXy8vKs6Ohoa/369TV+fcXFxdb27dsr3z54GdzDfx1++dw9e/ZYrVq1srKysqrc/thjj1nJyclW586drYULF1bevnPnTisiIsLasWNHjbMBCC1cohYAcEz33XefCgsL9eabb5qOUsUDDzygffv2ady4caajADCE0QIAwDE99NBDatWqVa3nXutLo0aN9MQTT5iOAcAgVmQBAAAQlFiRBQAAQFCiyAIAACAoUWQBAAAQlCiyAAAACEoUWQAAAAQliiwAAACCEkUWAAAAQYkiCwAAgKBEkQUAAEBQosgCAAAgKFFkAQAAEJQosgAAAAhKFFkAAAAEJYosAAAAghJFFgAAAEGJIgsAAICgRJEFAABAUKLIAgAAIChRZAEAABCUKLIAAAAIShRZAAAABKVw0wEAIBAUlrtVVO5RSYVHxRUelVZ4D/zuOnibV6WuQ97n8qi0wqMSl1cuj0+WZclnSb5ffz/wtqVvI++X5JAcDsnhlMKcUli4no37s5aXpikqPExREWGKdIYpKtypyPAwxUQ6lRgTocSYCCXFRigpJlJJsb+9nRAdYfrTBQABgSILIGRZlqW8EpeyCyuUXVSu7KIK5RRVaG9h+RG3VXh89RMien21N29OyNfPOY5aPWR4mONA0Y2NUFJMhJJiIyt/b5oYrWZJMUpvGKP0pBilxkfK4ajd8wBAoKPIAghalmVpT2G5tuaUKCO3RFtzS7Q9v1TZhQcKam5xhdxey3TMapV5az/Z5fEdKOh5Ja7j3jcqPOxAsU2KUbOkaKUnxSq94YE/N0+KVdOkaEU4mTIDEJwosgAC3r4SV2VR3ZpbrK25JcrIKdG2vFKVub2m49VKuc/pl+ep8Ph+/byVVPv+MIfUKCFabVLj1KlJgjo0jlenxgnq0DhBiTGMMAAIbBRZAAGjqNyt1VmFWp1VoHV7CpWRU6LMvBLtL3WbjlbnKnyBsQrqs6Q9heXaU1iu+Rl5Vd7XpEF0ZbHt2PhAye3YOEFxUfzXASAwcDQCYERBqVurdxVodVaBVmUd+H1bfqmswJwEqHMnM1rgLwcL7pxNuZW3ORxSs8QYdWpyoNx2T2+gU1s2VLOkGINJAdgVRRZAvdtf6tKqQwrr6qxCbc8vNR3LqLIAWZE9UZYlZe0vU9b+Mv2wPrvy9iYNotW7ZdKvvxqqR3qioiP8Mz4BwL4clmWX9Q8A/rI1t0QLMvK0ICNPS7bt0859ZaYjGZMZfW21t/f1TVCOK9LPafwnwulQl6YHVmt7t0zSqS0bqkVyrOlYAEIMRRbASTu0uC7MyNeewnLTkQLG0YpsN8/7KvHYa8UyNT5KvVok6dRWSerfNkU9myfJGcbWYABqjyIL4IRl5BRrQUb+geK6NU97CytMRwpYRyuy7So+kNcKzvGCupIYE6Ez26XonA5pOqdDKiu2AE4YRRbAce0pKNesDdmav4XieqKqK7KWw6k2Ze8bSBPYWqfE6pwOaTq7Q6rObJfCFcwAHBdFFsARLMvS6qxCzVy3VzPX7dWaXYWmIwWtaotseLTaFL9jIE3wCA9zqFeLJJ3dIVXndEhTrxaMIQA4EkUWgCSp3O3VvC25mrkuWz+sy2bOtY5UW2Qj49WmcJyBNMGrQXS4zmqfqsHdGuv8Lo3VgNVaAGL7LcDWcooq9MP6vZq5Lls/b8oN2qtkBRvLGbq7FdSXwnKPpq3eo2mr9yjSGaYz26foou5NdWHXxmoYx+cTsCtWZAGb2bS3SN+u3avv1u7Vip37bXMBAlOqW5H1xjVSu7wX/B8mBIWHOXR622QN7d5UQ7s1UVpClOlIAPyIIgvYwJ6Ccn2xPEufL9+ldbuZd/Wn6oqsJyFd7XOeMZAmtIU5pNNaJWto9yYa1qOJmiZytTEg1FFkgRBVWO7WtFW79fmyXVq4NU8+/qUbUV2RdSe2Voe9/zSQxj4cDumU5kka1r2JhvdsquYN2doLCEUUWSCEVHi8mrU+R58vy9IPG7Ll8vhMR7K96oqsq2EHddz9mIE09uRwSGe2S9FVfVpoaPcmXDoXCCGc7AUEOcuytCAjX18sz9I3q3arsNxjOhKOw+fg0OtPliXN3ZynuZvzlPBFuEac0kxX9Wmu3i0bmo4G4CRxNAWC1JacYn28eIe+Wr5LuwrYKiuY+MLYOsqUonKPJi3crkkLt6tDo3hddVpz/a53c04SA4IUowVAEHF5fJq+Zo8mLdymBRn5puOgBqobLShOO1Xdd9xrIA2qEx7m0KBOjTTytOY6r3MjhTvtfelgIJiwIgsEgczcEn34y3Z9smSn8kpcpuPgJPnCOPQGEo/PqryKXWp8pC7rla6r+7ZQh8YJpqMBOA5WZIEA5f31P9f352/T3C257PcapKpbkd3X5Cz1zrzLQBqciDPaJuvGM1vrwq5NuDwuEKBYFgACzL4Slz5ctF0TF2xX1v4y03FQDzjZKzgsyMjXgox8pSfF6Ib+rTSqbwslxXIVMSCQsCILBIhVOws0YV6mpq7cpQq2zQoZ1a3IZjc7X/0ybjGQBicjOiJMl/VK101ntVGnJowdAIGAZQHAsFnrs/X67C36JZOTt+zCy4psUCp3+/TRoh36aNEOndMhVbee01YDO6aZjgXYGkdTwACvz9LXq3br9dlbuGSsDXkoskFvzqZczdmUq06NE3TL2W10ae9migrnQguAvzFaAPhRhcerT5bs1LifMrQtr9R0HPhBdaMFmc0v1aDNVxtIg/qSGh+lMf1bafSZrZUYwz7BgL+wLAD4QXGFRx8s2KZ3ft6q7KIK03FgGCuyoSe3uELPfbdR4+Zk6Kaz2uiWs9tQaAE/4GgK1KO84gqNn5up9+ZnculYVPJy6A1ZReUevfT9Jo2fu1U3ndlat5zdVomxFFqgvnA0BepB1v4yvfVThv63aIfK3F7TcRBg3GKWMtQVlXv00g+bNX5upsac2Vq3ntOGrbuAekCRBerQnoJyvfj9Jk1evEMeH+PnqJ6HQ69tFFV49MqszZowL1NjzmylW89uq4ZxFFqgrnA0BepAQalbr83erHfnZ6rczR6wODYPK7K2U1zh0auztmjC3EyNPrO1bjunrZIptMBJo8gCJ6HM5dU7c7fqzR+3MAOLGnOLmUm7KnF59frsLXpvXqZu6N9atw+g0AIngyIL1ILH69OHi3bo5e83sQsBThgzsihxefXGj1v0wYJt+v3Atrr1nLaKjuDrAjhRFFngBFiWpa9W7tbz325QJvvAopbcHHrxq+IKj579dqMmLdyu+4Z20mW90uVwOEzHAoIGR1Oghn7cmKNnZqzX6iyuxIWT47bCTEdAgNlVUK4//2+Fxs/N1N+Gd1W/NsmmIwFBgSILHMfyHfv11LT1mp+RZzoKQoSL0QIcxcqdBRr55nwN6dZYfx3WRa1T40xHAgIaRRY4ipyiCv1r2jp9tixLXMgZdcltcejFsc1Ys1c/rM/WDWe01j3nd+CiCsBRcDQFDuP1WXp3Xqb+M3OjitiJAPWgwmJFFsfn9lp6Z+5Wfbpsp/54XgeN7t9KEU7GUoBDUWSBQ/yyNV9//2K11u8pMh0FIczFiixOwP5St56Yulbvz8/U/w3rrKHdm5qOBAQMjqaApOzCcv3zm3X6fPku01FgAy5O9kItZOaV6vcfLNU5HVL1j8t6qGVKrOlIgHEcTWFrHq9Pb/2UofOe+5ESC7+p8LGGgNqbsylXg1/4Ua/O2iy3lysJwt44msK25m3J1SNfrNGm7GLTUWAzLtYQcJLK3T49M2ODvly+S/+8vLv6tGK7LtgTRRa2s6egXE9+vVZTV+42HQU2VeGjyKJubNhbpCvfmK9r+rXUA0M7KzGG3Q1gLxRZ2IZlHdiN4JkZG1Ti8pqOAxtjtAB1ybKkSQu367u1e/XwxV11ySnNTEcC/IZlAdjCtrwSjRq3QI9+tZYSC+MqONkL9SCnqEJ3f7hMY975RTvyuYQ27IGjKUKaZVkaP3erhr4wRwu35puOA0iSyn3sI4v68+PGHA3+z096ffYWeTgZDCGOIouQtS2vRFePW6DHvlqrMjersAgczMiivpW5vXpq+npd/PLPWrlzv+k4QL3haIqQY1mW3vn5wCrsL6zCIgCVeVmRhX+s31Oky1+bpxdnbpLXx7W2EXo44wAhJTO3RPd/slK/ZFJgEbjKWZGFH3l8lv4zc6Nmb8zWf0b2UuvUONORgDrD0RQhweez9PacDA198SdKLAIeM7IwYdn2/bropTmauHCb6ShAnWFFFkFva26J7v9khRZl7jMdBagRVmRhSqnLq4c+W63v12XrqSt6Ki0hynQk4KRwNEVQ++iX7broxTmUWASVMi+HXpj1w/psDXnhJ01fvcd0FOCkcDRFUCoqd+uPHy7T/326ih0JEHTKGC1AAMgvcen3HyzRvZNXqLjCYzoOUCsUWQSdlTv36+KXf9ZXK3aZjgLUSqnXYToCUOmTJTs17MWftIjzCxCEKLIIKm/PydCVr8/XtjyuWoPgxWgBAs2O/DJd/eZ8PTV9vdxcRAFBhJO9EBT2lbh07+QV+n59tukowEmxHGHycolaBCCfJb0+e4sWbc3Xq9edqsYNok1HAo6LoykC3i9b83XRS3MosQgNzkjTCYBjWrxtn4a/NEfztuSajgIcF0UWAcvns/TS95t0zVsLtLug3HQcoG6E8YMwBL7cYpdu+O8vem32ZlkWVwRD4OKIioCUXViuP/1vueZtyTMdBahTVliE6QhAjXh9lp6evkFLt+3TcyN7KTGGr10EHlZkEXB+3pSri16aQ4lFSLKclAEEl5nrsjXi5Z+1ZleB6SjAESiyCChvz8nQmPG/KLfYZToKUC9YkUUw2p5fqstfm6ePF+0wHQWogiKLgFDh8ereySv05Nfr5PUxj4XQRZFFsKrw+HT/lJW6/5MVKudCNAgQFFkYl11YrlHjFuiTJTtNRwHqneXg1AQEt48X79QVr8/TdvbzRgCgyMKoFTv265JX5mrZ9v2mowB+4WNFFiFgza5CXfzyHM3ewLaIMIsiC2M+W7ZTI9+crz2FbK0F+/Cx/RZCRGG5R7e8u1jvz880HQU2xhEVfufzWfr39PUa91OG6SiA3/kcrMgidHh9lh7+Yo0yckv08PCuCgtzmI4Em6HIwq8Kyty6+8Nl+nFjjukogBGsyCIUjZ+bqe15pXrpmt6Ki+JrHP7DaAH8ZktOsX736lxKLGzNx8leCFHfr8/WVW/M1+6CMtNRYCMUWfjFjxtzdNmrc5WRW2I6CmCUl9EChLC1uwt12atztTqLiyfAPyiyqHefLNmpWyYsUlG5x3QUwDivw2k6AlCv9hZWaOSb8/Xtmj2mo8AGKLKoV6/P3qJ7J6+Qh4scAJJYkYU9lLq8+v0HS/QWJ/WinlFkUS8sy9LjX63VU9PXm44CBBQvM7KwCZ8l/eObdXrws1XyeH2m4yBEUWRR51wen+7+aLnembvVdBQg4HjYLAY2M2nhdt00YZGKyt2moyAEUWRRp4orPLp5wiJ9tWKX6ShAQGJFFnY0Z1Ourn1rofaVuExHQYihyKLO5BRVaNS4+fp5c67pKEDA8oiTvWBPq7IKNPLN+drL1RxRhyiyqBOZuSW64vV5Wp1VaDoKENAYLYCdbcou1pVvzNP2vFLTURAiKLI4aat2Fhw4MOVzYAKOhxVZ2N2O/DJd9eY8bdpbZDoKQgBFFidlzqYcjRo3X7nFzD0BNeFm+y2gcq/ZlTv3m46CIEeRRa1NW7VbN09YpBKX13QUIGi4LVZkAUnaV+rWdW8t1MKMPNNREMQosqiVL1fs0h8/XCa3lwsdACfCzYwsUKmowqMx43/RrPXZpqMgSFFkccI+XbpTf/7fcq7WBdSCmxlZoIpyt0+3v79YU1eybSNOHEUWJ+TjxTt07+QV8lJigVphtAA4kttr6e4Pl+mjX7abjoIgQ5FFjU1auF0PTFkpOixQe4wWANXzWdL/fbpK//2Zq0Ki5iiyqJH3F2zTQ5+vkkWJBU6Ky+KwCxzLE1PXagKXOEcNcUTFcU1cuE1//2I1JRaoAy6LFVngeB79aq0+WLDNdAwEAYosjunDX7brb59TYoG64mJGFqiRh79Yrf8tYmYWx0aRxVF9vGiHHvyMcQKgLlFkgZqxLOmvn67SlCU7TUdBAKPIolqfLNmp//t0JSUWqGMVPoosUFM+S7rvkxX6YnmW6SgIUBRZHOHLFbt0/ycr2J0AqAcV7CMLnBCfJf2/j1fo2zV7TEdBAKLIooofN+bo/328nBIL1BMXK7LACfP4LI39cJl+3pRrOgoCDEUWlZbv2K8/fLCEy84C9ajcx2EXqA2Xx6fb3lusxZn5pqMggHBEhSRpS06xbp6wSKUur+koQEir4GQvoNbK3F7dNGGRVmcVmI6CAEGRhfYUlGv0f39RfonLdBQg5HGyF3Byiso9Gv3OL9q0t8h0FAQAiqzNFZS6NfqdhcraX2Y6CmALjBYAJy+/xKUx7/yivYXlpqPAMI6oNlbu9urmdxdp495i01EA2yj3ctgF6sKugnLdNH6RSio8pqPAII6oNuXx+nTnxKVasm2f6SiArZQzIwvUmbW7C3XnxKXyeH2mo8AQiqwNWZalB6as0g/rs01HAWyHFVmgbv24MUcPf7HadAwYwhHVhv49bb2mLOWSf4AJZZzsBdS5D3/ZoVdnbTYdAwZQZG3mrZ8y9OZPGaZjALbFiixQP579doM+X8albO2GI6qNTF+9W/+cts50DMDWyti1AKgXliXd/8lKzd+SZzoK/Igjqk2s3VWov3y8QhYX7QKMKmVFFqg3Lq9Pd7y/mD1mbYQjqg3kFlfotvcWc9UuIACUUWSBelVY7tGN4xcpu4g9Zu2AI2qIc3l8+v37S7jgARAALEeYPBaHXaC+Ze0v0y0TFqvUxR6zoY4jaoj72+ertJi9YoHAEBZhOgFgG6uyCjR20jL5fMzUhTKKbAh7e06GPl7MNltAwHBSZAF/+mF9tp77boPpGKhHFNkQNXtDtv41bb3pGAAOYbEiC/jda7O3aPrqPaZjoJ5QZEPQlpxi/fHDZfLy4xQgoFhh4aYjALZjWdK9k1doS06x6SioBxTZEFNQ6tat7y5WUTkD7kCgsZyRpiMAtlRc4dHt7y1WcQX/N4YaimwI8fosjf1wqbbmlpiOAqAaloMVWcCULTkl+n8fL5fFhuohhaNqCHli6lrN2ZRrOgYQsoqWTlXBwk/lLdmnyEZtlHzBHYpq1qna+5ZumKeCBR8raV+h3D6pQ3KY7jm/UGrx230KFn6qwl+mSJIST79CDfpdXvm+il0blP/ta2oy+nk5wpz1+roAu5ixZq9em71Fd53b3nQU1BFWZEPEF8uzNGFepukYQMgqWfeT8n94W0lnXaOmN76oyEZtlP3x3+Ut2V/t/cNi4pXYf6Tm3xKnlb+P1029InTbR9tUlrFEkuTK3qqCnycq9ZL7lTriPu2f84FcOZmSJMvnVd6MV5U85C5KLFDHnvt2g37amGM6BuoIRTYEZOQU68FPV5mOAYS0wkWfK+GUIYrveaEiU1seKJkRUSpe9V21949u2VOxHc9UlzSn2iWH6Z4zotS9WZwqdq6VJLnzdioirbViWp2imNa9FJHWWu68A9vlFS6cougW3RTVtKPfXh9gFz5LuvujZdqRX2o6CuoARTbIlbu9umvSMpVw+Vmg3lhet1x7Niu6Va/K2xyOMEW37qWKrONvc2dZlr7P8GhTdpmiWnSXJEWmtZZnX5Y8hdnyFGTLk5+lyNRWcu/breJVM5V0zg319XIA29tf6tbvP1iicjf/dwY7ZmSD3BNT12rd7kLTMYCQ5i0tlCyfnHFJVW53xiZVrqJWx1dRovjnC1XhlZwO6blruuiZ9N6SpIjUFkoaMFp7//ewJClp4BhFpLbQ3o8eUsNBN6ls61IVzJ0khYUr+YLbFf1rAQZQN9bsKtSDn67S81f3Mh0FJ4EiG8SmrtyliQu3m44B4CgckTFa/vt4FbsOrMg+OGWTYi5bqeiWPSVJCb0vUkLviyrvX7zqezkiYxSV3llZb/1eTUc/L29RnnK/fFrpd/xXjnAuqADUpU+XZemUFkkac2Zr01FQS4wWBKlteSX66xTmYgF/cMY2kBxhR5zY5S3dL2dcw6N+nMMRpvbJYerVxKn/d2aURpzaVAXzJ1d7X29pgQrmTlLyBb9Xxa6NikhupojkdEW36inL65F7X1ZdviQAv/rH1+u0OqvAdAzUEkU2CFV4vLpr0lIVsbEz4BcOZ4Qim7RX+bYVlbdZlk/lmSsUld65xo/jtRyyvO5q37fvh7eV0PcyhTdIlSyvLO8hs3s+r+Tz1To/gKNzeX2656NlKuNck6BEkQ1C//x6nVZnMRcL+FODvpepaMUMFa/6Xu7cHcqf8Zosd7nie1wgScqd+pz2/Tih8v4F8z9W2dZlytjn07ocr56bV6FPFuxQXLdzj3jssq3L5M7PUsKpwyVJkU06ypO/U2VbFqto+XQpzKnw5HS/vE7AjrbklOiJr9eajoFaYEY2yExbtVvvzt9mOgZgO3FdBshbWqD9P3/w6wUR2qrRyMcrRws8hTmS47e1AZ+7QvnfvaZuRcWKCZc6pzr14q399XTDIVUe1+euUP7MN5R2yQNy/Prx4Q1S1fCCO5Q77QU5nBFKGf5nhUVE+e/FAjY0aeF2DeqYpsHdmpiOghPgsLhWW9DYkV+qi16ao6JyRgqAYJEZfe1vf25+iQZtHmUwDYBjSY6L1PR7zlGjBtGmo6CGGC0IEi6PT2MnLaXEAkHM62DXASCQ5Ze49P8mrxBrfMGDIhsknpmxXit2clYlEMw84nKzQKCbsylX//15q+kYqCGKbBBYlJnPPyogBFBkgeDw9PQNWrOLxaNgQJENcGUur+6bvEI+fsoBBD2Pg/NrgWBwYEuu5VzCNghQZAPcU9PXKzOv1HQMAHXAY1FkgWCxObtYT0xlS65AR5ENYPO35Ond+ZmmYwCoI252PASCysSF2/Xd2r2mY+AYKLIBqqTCo/unrBAnTgKhw82MLBB0HpiyUrnFFaZj4CgosgHqn9+s0478MtMxANQhVmSB4JNf4tKjX64xHQNHQZENQD9vytWkX7abjgGgjrksVmSBYDR15W7NZMQgIFFkA0xRuVsPTFnJSAEQgliRBYLXw1+sVlG523QMHIYiG2CenLpOWfsZKQBCkdvikAsEq90F5Xpq+nrTMXAYjqoBZNaGbP1v8Q7TMQDUExfbbwFBbeLC7VqUmW86Bg5BkQ0QBWVu/XXKKtMxANQjZmSB4GZZ0v9NWakKDxdKCBQU2QDxr2/WaU9huekYAOpRBaMFQNDbklOiV37YbDoGfsVRNQAs3b6PkQLABioYLQBCwhs/btH6PYWmY0AUWeO8PksPf76aXQoAG3CxIguEBLfX0gNTVsnn4z9v0ziqGvbBgm1as4vv6gA7qPCxIguEihU79uuduVtNx7A9iqxBucUVeu7bDaZjAPCTCh+HXCCUPP/dRu3ILzUdw9Y4qhr0z2/WqbDcYzoGAD/hZC8gtJS6vHro89WmY9gaR1VDftmar0+XZpmOAcCPGC0AQs9PG3O4fK1BFFkDPF6f/v4F38EBdlPGaAEQkv7xzTq5PD7TMWyJo6oBE+Zlav2eItMxAPhZhY8LIgChaGtuiSbM48QvEyiyfpZdWK4XZm4yHQOAAeWsyAIh6+XvNyu3uMJ0DNvhqOpnT369TsUVnOAF2FE5K7JAyCqq8LATkQEUWT+atyVXX67YZToGAENKvRxygVD2v0U7tGZXgekYtsJR1U+8PkuPfLHGdAwABpVTZIGQ5rOkx75aazqGrXBU9ZOPF+/Qpuxi0zEAGMSMLBD6ftmar69X7jYdwzY4qvpBudurF2ZuNB0DgGGMFgD28M9v1qnc7TUdwxY4qvrBf3/eqr2FnMkI2F0ZJ3sBtpC1v0xvz8kwHcMWKLL1bF+JS2/8uMV0DACGWY4wuX0O0zEA+Mlrs7dob2G56RghjyJbz16ZtVlF5Wy3BdheWITpBAD8qNTl1VPT1puOEfIosvVo575Svb9gm+kYAAKBM9x0AgB+9tnyLK3fU2g6RkijyNaj57/dyLWXAUiSrLBI0xEA+JllSf/5jpO96xNFtp6s212oz5dnmY4BIFCEsSIL2NGMNXu1OouLJNQXimw9eWr6evks0ykABAqLGVnAtp5nVbbeUGTrwfwteZq9Icd0DAABxEeRBWzrh/XZWrp9n+kYIYkiWw/+PZ2zFAFUZTFaANja89+yKlsfKLJ17OuVu7Vix37TMQAEGFZkAXv7eXOuFmbkmY4RciiydciyLC5FC6BaloMVWcDunmNWts5RZOvQjDV7tSm72HQMAAHIy4osYHu/bM3Xz5tyTccIKRTZOvTa7M2mIwAIUD5WZAFIeu67DaYjhBSKbB35aWOOVu5knzgA1WNGFoAkLdu+X7PWZ5uOETIosnXk1VmsxgI4Oi8rsgB+xb6ydYciWwcWZ+Zr4dZ80zEABDBGCwActCqrQN+u2WM6RkigyNYBVmMBHA8rsgAO9caPW0xHCAkU2ZO0dlehZnEVLwDH4RFFFsBvlm7fryXb+GnuyaLInqRX2akAQA2wIgvgcG/9tNV0hKBHkT0JGTnFmrZqt+kYAIIAK7IADvft2j3alldiOkZQo8iehNdnb5HPMp0CQDDwsCIL4DA+S3p7DquyJ4MiW0u79pfp8+VZpmMACBJeOU1HABCAPlmyU/tKXKZjBC2KbC2N+ylDbi/LsQBqxs1oAYBqlLm9+mDBNtMxghZFthYKytz636IdpmMACCLMyAI4mnfnb1OFx2s6RlCiyNbCx4t2qMzNFxyAmnMzWgDgKHKLK/TZUsYVa4Mie4J8PkvvLcg0HQNAkGG0AMCxvP3zVlkWI4sniiJ7gmau26sd+WWmYwAIMqzIAjiWzdnF+mF9tukYQYcie4LenZ9pOgKAIOS2WJEFcGxvzckwHSHoUGRPwKa9RZq7Oc90DABBiBVZAMezICNfq7MKTMcIKhTZE8BqLIDaclkUWQDH9/58tuI6ERTZGiqu8HBGIYBaczFaAKAGvlq5S0XlbtMxggZFtoY+W5alEhdbbgGoHZfF4RbA8ZW6vPpsGQtnNcWRtYYmctUNACeBFVkANTVp4XbTEYIGRbYGFmfma/2eItMxAASxClZkAdTQ+j1FWrJtn+kYQYEjaw1wDWQAJ4uTvQCciIkL6R41QZE9jvwSl75Zvcd0DABBrsJHkQVQc1+v3K2CMk76Oh6K7HF8unSnXB6f6RgAglw5RRbACajw+PTlil2mYwQ8iuxxfMqWWwDqAKMFAE7Ux4t2mI4Q8Ciyx7BhT5HW7i40HQNACCj3cbgFcGJWZRVoHT3kmDiyHgP7uAGoK4wWAKiN/7Eqe0wU2aPw+Sx9sZwiC6BusCILoDa+WJ7FuTrHwJH1KBZk5Gl3QbnpGABCBLsWAKiNfaVufbuW3ZOOhiJ7FIwVAKhLZazIAqilz+kkR8WRtRrlbq+msXcsgDpU5mVFFkDt/LQxV4Xl7ClbHYpsNb5du1fFFR7TMQCEkApWZAHUksvr07dr9pqOEZA4slbjs6U7TUcAEGLKvBxuAdTe1JVcHKE6HFkPk1tcoTmbck3HABBiSlmRBXAS5m7O1f5Sl+kYAYcj62G+WrFLHp9lOgaAEMOKLICT4fZamrGG83cOx5H1MOxWAKCuWXLIxYosgJM0deVu0xECDkfWQ2TkFGvlzgLTMQCEGmeE6QQAQsD8LXnKL2G84FAU2UNMZ8keQH2gyAKoAx6fpWmrWZU9FEX2EN+tZWsLAHXPCqPIAqgbU1dQZA9Fkf1VdlG5lu/YbzoGgFBEkQVQR37JzFdOUYXpGAGDIvur79dly2KzAgD1gBVZAHXFy3hBFRTZXzFWAKC+WGHhpiMACCGMF/yGIiup1OXR3M1cBAFA/fCxIgugDi3elq/swnLTMQICRVbSTxtzVeHxmY4BIET5WJEFUId8ljR7Q47pGAGBIivGCgDUL2ZkAdS12RuzTUcICLYvsl6fpR/WU2QB1B+fgxVZAHVrzqZcebz8NNn2RXZxZr72lbpNxwAQwrwOVmQB1K2ico+WsW0oRZaxAgD1jRlZAPVh9gbGC2xfZGeuo8gCqF8+UWQB1D1O+LJ5kd20t0iZeaWmYwAIcV5O9gJQD9buLlR2kb234bJ1kf1hPUvyAOqfV07TEQCEIMuSfrT5qqyti+zcLXmmIwCwAQ8rsgDqyeyNFFlbcnt9WpyZbzoGABvwMiMLoJ78vClXXp9lOoYxti2yK3fuV6nLazoGABvwso8sgHpSUObWsu37TMcwxrZFdt5mxgoA+IebGVkA9cjOuxfYtsjOz6DIAvAPRgsA1Cc7X67WlkW2wuPVkm32XYYH4F8eiiyAerRmV6HyS1ymYxhhyyK7dNt+VXi4PjEA/2C0AEB9sizZdoHOlkWWsQIA/uQR228BqF923YnJlkV2AfvHAvAjtz0PtQD8aBFF1h7KXF4t37HfdAwANuJiRhZAPVudVahyt/22FbVdkV28LV8uL/OxAPzHbTEjC6B+ubw+rdxZYDqG39muyM5nrACAn7lZkQXgB4u32W+8wHZFdh5FFoCfuViRBeAHizPtt3OBrYpsudur1Vn2W3YHYBajBQD8Ycm2fbIsy3QMv7JVkV2zq1Aen73+ggGYx4osAH8oKHNrU3ax6Rh+Zasiu2rnftMRANgQRRaAv9htGy5bFdmVjBUAMKCCIgvAT5bYbE7WVkV2lQ23pQBgXoWPIgvAPxbZbOcC2xTZUpdHW3LsNTcCIDC4RJEF4B878su0t7DcdAy/sU2RXZ1VKM7zAmBCudc2h1oAAWDZ9v2mI/iNbY6uKznRC4AhFRYXRADgP+t2F5qO4Dc2KrLMxwIwo8Jnm0MtgACwfg9FNuSsYscCAIaUc7IXAD9at7vIdAS/sUWRLSx3KzOvxHQMADZVzoosAD/asa9UxRUe0zH8whZH19U7C2SzK7YBCCAUWQD+ZFnSBpuMF9ji6LqC+VgABpUxWgDAz9baZLzAFkV2VdZ+0xEA2BjbbwHwt/U22bnAFkfX9Tb5rgRAYOJkLwD+ZpctuEK+yLq9Pm3PLzUdA4CNlTEjC8DPNuwpkmWDE4RC/ui6La9UHi7pBcCgMq/DdAQANlPi8tpiIS/ki+yWnGLTEQDYXJmX0QIA/meH/WRDvshm5LB/LABzLDm4shcAI+wwJxvyR9cMVmQBmOSMMJ0AgE3Z4VK1oV9kc1mRBWBQGEUWgBmb9ob+Yl7IF1lmZAGYZLEiC8CQnfvK5AvxE95Dusjml7i0v9RtOgYAOwsLN50AgE25vD7tKSw3HaNehXSRZT4WgGlWWKTpCABsLNS34ArxIst8LACzLFZkARhEkQ1izMcCMM1HkQVg0E6KbPDawoosAMMsdi0AYBArskEsI5cVWQBm+RwUWQDmUGSDlGVZ2hHif3kAAh+jBQBM2rGvzHSEehWyRTa32CW3N7T3TgMQ+HwOiiwAc3KKKlTu9pqOUW9CtsjuDfF90wAEBy8zsgAMC+XxAoosANQjVmQBmBbKo5YhXGQrTEcAAHlFkQVgFiuyQSjUL8kGIDh4OdkLgGEU2SCUTZEFEABYkQVgWlYI71wQskWWFVkAgcDDPrIADMsrcZmOUG9CtsgyIwsgEHjlNB0BgM3lU2SDD7sWAAgEHnYtAGBYXnHoLu6FZJF1eXzaVxq6330ACB4eZmQBGFZY7pHb6zMdo16EZJHdW1gui4t6AQgAFFkAgWBfiI4XhGSRzS5irABAYPA4mJEFYF6onvAVkkV2T0HozoIACC5uixVZAOaF6glfIVlkc1iRBRAg3OxaACAAsCIbRArLPaYjAIAkiiyAwJAfojsXhGSRLa6gyAIIDIwWAAgErMgGkSJWZAEECBcrsgACAEU2iLAiCyBQuFiRBRAA8ospskGjuNxtOgIASJLcFiuyAMxj14IgwoosgEDhskLyMAsgyOSH6BVPQ/IIW1zhNR0BACRJLq7sBSAAlLlCsxuFaJFltABAYKjwMVoAwLxyN0U2aBSzawGAAOFiRhZAAKjw+ExHqBchWWRLGC0AECAqmJEFEABYkQ0S5W6vXN7Q/K4DQPBhtABAIPD4LHl9lukYdS7kiiw7FgAIJOUUWQABIhRXZUOvyDIfCyCAsCILIFCE4pxs6BVZVmQBBBCKLIBAwYpsEGA+FkAgKfeF3GEWQJBiRTYI+EJwkBlA8Cpn+y0AAYIV2SDgocgCCCBlnpA7zAIIUqzIBgFWZAEEknL2kQUQICpYkQ18rMgCCCRl3pA7zAIIUuWsyAY+r0WRBRA4yti1AECAYEU2CDBaACCQlLMiCyBA+EJwsS/kjrD0WACBpMzrMB0BACRJDkfoHY9CrsiG3l8RgGDGJWoBBIpQ7EihV2RD8W8JAADgJIWFYEkKuSILAACAI4WFYOsLuZcUgt9sAAAAnDRmZIOAIyQnQAAAAE4OowUAAAAISuFhFNmAF+EMuZcEAABw0kKxI4XcK4qJZKsbAACAw0U4WZENeLEUWQAAgCNEhodc7aPIAgAA2EEkowWBj9ECAACAIzEjGwRiI8NNRwAAAAg4jBYEgdgIVmQBAAAOFx2CHSnkimxYmEPRESH3sgAAAE5Kg+jQ+6l1SDY+xgsAAAB+ExvpVDgzssEhJgSXzgEAAGorMSbCdIR6EZJFli24AAAAftMgmiIbNCiyAAAAv2FFNogwIwsAAPCbBhTZ4MGKLAAAwG8axITmIl9IFtn4ENxeAgAAoLYYLQgiKXFRpiMAAAAEDE72CiJpCRRZAACAg1iRDSKp8ZGmIwAAAAQMimwQYUUWAADgN+xaEEQosgAAAL9hRTaIUGQBAAB+kxRLkQ0aKXFRCnOYTgEAABAYGjeINh2hXoRkkXWGOZTMFlwAAACKi3QyWhBs2LkAAABAapoUYzpCvQnZIsucLAAAgNQ0MTTHCiSKLAAAQEhLZ0U2+FBkAQAApKaJFNmgkxZPkQUAAGiaxGhB0GkUottMAAAAnAhGC4JQi4ah+5cGAABQU5zsFYTapMaZjgAAAGBcM1Zkg09SbGTIbv4LAABQE8lxkYqOcJqOUW9CtshKUmtWZQEAgI2F8liBFOpFNiXWdAQAAABjQnnrLSnkiywrsgAAwL6ahfDWW1KoF9lUVmQBAIB9hfrJ76FdZFmRBQAANtaxcYLpCPWKIgsAABCiOjSKNx2hXoV0kW0YxxZcAADAnhJjIkL+SqchXWQldi4AAAD21D7EV2MlOxTZEB9yBgAAqE6ojxVINiiyrZiTBQAANsSKbAhoy4osAACwoQ4hvmOBZIMi26lJ6P8lAgAAHI7RghDQoVG8IsND/mUCAABUio8KV7Ok0L48rWSDIhvuDFMnGyytAwAAHNTOBquxkg2KrCR1T29gOgIAAIDf2GGsQLJJke3aLNF0BAAAAL/p2JgiGzK6NWNFFgAA2EeHRvYYq7RFke3atIGcYQ7TMQAAAPyim03GKm1RZKMjnOwnCwAAbCE9KUaNEqJNx/ALWxRZifECAABgD71aJJmO4Dc2KrKc8AUAAEIfRTYE2WVWBAAA2FuvlkmmI/iNfYpsU1ZkAQBAaAsPc6hHun06j22KbGJshJo3DP1LtQEAAPvq1CRB0RFO0zH8xjZFVpK6MycLAABCmJ3mYyWbFdk+rRqajgAAAFBvKLIh7PS2yaYjAAAA1JveNjrRS7JZke3WLFHxUeGmYwAAANS5hKhwtUuLNx3Dr2xVZJ1hDsYLAABASOrZIlEOh8N0DL+yVZGVpH5tGC8AAAChx27zsZINi+wZzMkCAIAQ1KuF/X7qbLsi27N5kqIjbPeyAQBACAtzSP1a22+xznaNLsIZplNb2u87FgAAELp6pCcqMTbCdAy/s12RlZiTBQAAoeWs9qmmIxhhyyJ7epsU0xEAAADqzNkUWfvo3TJJkU5bvnQAABBioiPC1Ke1PccmbdnmoiOcOqVFoukYAAAAJ61v62RFhTtNxzDClkVWYk4WAACEBruOFUg2LrJntGVOFgAABD+7nugl2bjI9muTrNhIey7DAwCA0JASF6luzRqYjmGMbYtsVLhTZ7az73cwAAAg+PVvlyKHw2E6hjG2LbKSdH6XRqYjAAAA1Jqd52MlmxfZ8zpTZAEAQPA6uwNF1rYaN4i29VwJAAAIXq1TYtW8YazpGEbZushK0vmsygIAgCBk99VYiSKr87o0Nh0BAADghF3YtYnpCMbZvsie0jxRqfFRpmMAAADUWIPocJ3Zjj3xbV9kHQ6HBnVKMx0DAACgxs7v0lgRTtvXOIqsxJwsAAAILkO6MRopUWQlSed0TFMk39UAAIAgEBPh1MCOLMJJFFlJUnxUuPq1STYdAwAA4LgGdExVTKTTdIyAQJH9FRdHAAAAwWBod3YrOIgi+6sLuzJrAgAAAluE06HzOtNZDqLI/qpFcqx6tUgyHQMAAOCozmibosSYCNMxAgZF9hCX9mpmOgIAAMBRMVZQFUX2EMN7NpUzzGE6BgAAwBHCHNJgruZVBUX2EI0SotW/LVfJAAAAgadPq4ZKS+BqpIeiyB7mEsYLAABAABrSjdXYw1FkDzO0exNFhvNpAQAAgSPMIQ3r0dR0jIBDYztMg+gIndspzXQMAACASv3bpSg9KcZ0jIBDka3Gpb3STUcAAACodMWpzU1HCEgU2Wqc17mREqLCTccAAABQfFS4hnVnrKA6FNlqREc4dWE3rpoBAADMu6hHE8VEOk3HCEgU2aNgvAAAAASCK/u0MB0hYFFkj+Ls9qlKjY80HQMAANhYq5RY9WuTbDpGwKLIHoUzzKHhbHMBAAAM4iSvY6PIHgNL+QAAwBSHQ7r8VEYdj4Uieww9mieqe3oD0zEAAIANndEmRc0bxpqOEdAossdxTb+WpiMAAAAburIPYwXHQ5E9jkt7pSuWLS8AAIAfxUeF6yLO1TkuiuxxxEeFa0TPZqZjAAAAGxnWnb1ja4IiWwOj+nHSFwAA8J+rTqN71ARFtgZ6t2yoLk056QsAANS/To0T2Du2hiiyNXTDGa1MRwAAADZwQ386R01RZGvost7NlBAdbjoGAAAIYQnR4ewdewIosjUUGxnO1TUAAEC9urJPc8VGsnBWUxTZE3BD/1ZyOEynAAAAocjhkEb3b206RlChyJ6AdmnxOrNdiukYAAAgBJ3dPlVtUuNMxwgqFNkTdMMZrU1HAAAAIeims1qbjhB0KLIn6MKujdUiOcZ0DAAAEELapsXp3E6NTMcIOhTZE+QMc+i2c9qajgEAAELITWe1kYMTcU4YRbYWRp7WQilxkaZjAACAEJAUG6Er2RmpViiytRAd4dSYM1ubjgEAAELANf1aKibSaTpGUKLI1tLo/q0UyxcdAAA4CRFOh8aw5VatUWRrKSk2Ulf3bWE6BgAACGIX9WiqJonRpmMELYrsSbj1nLYKD2MwGwAAnDiHQ/rDoHamYwQ1iuxJSE+K0SWnNDMdAwAABKHBXRurc5MGpmMENYrsSbpjYDsuWwsAAE7YH8/rYDpC0KPInqROTRLYwBgAAJyQ8zs3Uvf0RNMxgh5Ftg78fiDzLQAAoObuPp/V2LpAka0D/dok69SWSaZjAACAIDCgY5pOaZFkOkZIoMjWEVZlAQBATdzDamydocjWkQu7NlaXppx5CAAAju6s9inq06qh6RghgyJbRxwOh+4d3NF0DAAAEMDYqaBuUWTr0PldGvNdFgAAqFa/Nsk6o22K6RghhSJbx+4b0sl0BAAAEICYja17FNk6dkbbFA3omGY6BgAACCB9WjXUWe1TTccIORTZenD/kE5c7QsAAFRi39j6QZGtB93TEzWsexPTMQAAQAA4s12KBvLT2npBka0nf7mwk5xhLMsCAGBnDof04EVdTMcIWRTZetK+Ubwu751uOgYAADDod73S1T090XSMkEWRrUd/urCjIsP5FAMAYEdR4WG6l92M6hUtqx6lJ8Xo2n4tTccAAAAG3Hx2GzVLijEdI6RRZOvZ2PPaKy7SaToGAADwo5S4SN05qJ3pGCGPIlvPUuOjdPPZbUzHAAAAfnT3+R2UEB1hOkbIo8j6we8HtlPjBlGmYwAAAD9omxqn605ntNAfKLJ+EBcVztYbAADYxAPDOivcScXyBz7LfnJpr3T1a51sOgYAAKhH/Vona0g3LorkLxRZP3r0km5cJAEAgBDlcEgPDucnsP5EkfWjrs0asB0XAAAhaniPpurVIsl0DFuhyPrZ/xvcUQ1jOYsRAIBQEhPh1P8N62w6hu1QZP0sKTaSq3wAABBi7rmgg5o3jDUdw3YosgZc07eluqc3MB0DAADUgU6NE3Qre8YbQZE1ICzMoccu6SYH530BABDUHA7pH7/rznZbhvBZN6RPq2T9rle66RgAAOAkXH1aC53G9prGUGQN+r+LOis+Ktx0DAAAUAspcZGc4GUYRdagRgnRuvv89qZjAACAWnjwoi5Kio00HcPWKLKG3XRWG3VpyolfAAAEkzPaJuuKPs1Nx7A9iqxhEc4wPXNlT4VzxS8AAIJCpDNM//hdD9MxIIpsQOienqjbB7Q1HQMAANTAHQPbql1avOkYEEU2YNxzQQd1aMQ/CgAAAlmrlFjddS7ntwQKimyAiAp36ukre4oJAwAAAtcTl3ZXdITTdAz8iiIbQHq3bKibz+LKIAAABKLLejXTgI5ppmPgEBTZAHPvkE5qkxpnOgYAADhEkwbReuzS7qZj4DAU2QATHeHUU1f05PK1AAAECIdDeuaqnkqMiTAdBYehyAagfm2SdcMZrUzHAAAAkm44o5XO6cBIQSCiyAaoB4Z2VvOGMaZjAABga21T4/TXYV1Mx8BRUGQDVFxUuJ66oqfpGAAA2JYzzKHnRp6imEh2KQhUFNkAdlb7VI3q28J0DAAAbOnOQe3Uu2VD0zFwDBTZAPe3i7uqdUqs6RgAANhK9/QGuvv8DqZj4DgosgEuPipcL13TWxFOtjEAAMAfosLD9J+RvRThpCYFOv6GgkDP5km6b0gn0zEAALCFewd3UofGCaZjoAbCTQdAzdx2TlvN3ZynHzfmmI4ChCRfRan2z/lApZvmy1daoMhGbdXwgtsV1bSjJMlbsk/7Zk9QeeYy+cpLFNWim5IvuEMRyelHfcw9k/5PFTtWH3F7TNvT1OiqRyVJBQs/VeEvUyRJiadfoQb9Lq+8X8WuDcr/9jU1Gf28HGGcbAL4w+ltknXL2VxlM1g4LMuyTIdAzeQWV2jYi3OUU1RhOgoQcnK+eErunG1KHnKnnPHJKlkzS4WLvlCzW1+TMz5Fez64V46wcDU87xaFRcaqcNHnKtu6RM1ueV1hkdHVPqa3rEjyeg55u1C7x/9RKcPuVnyPC+TK3qo979+rtCv/LlmWcqY8riajn1dkWmtZPq92v/tnpQwdW1mmAdSv+KhwTf/TOWrekHNTggWjBUEkNT5Kz488hat+AXXM565Q6Ya5Sjr3JkW36K6Ihs2UdPZ1imjYVEXLpsmzb5dcuzYoefCdimraUREpzZU85E5ZHpdK1v141Md1xiTIGd+w8ld55nI5IqIU2+lsSZI7b6ci0lorptUpimndSxFpreXO2ylJKlw4RdEtulFiAT/6x++6U2KDDEU2yJzTIU13DGhnOgYQWnxeyfLJ4ax6+UlHeJQqdq6R5XX/+nbkb+9zhMnhjFDFzrU1fprild8qrsuAyhXcyLTW8uzLkqcwW56CbHnysxSZ2krufbtVvGqmks65oQ5eHICauP6Mlrq019FHhRCYKLJB6N7BHdWrRZLpGEDICIuKVVSzziqY95E8RXmyfF4Vr5mlil3r5S3Zp4jk5nI2SNP+H9+Vt7xYltetggWfyFuUK29xfo2eo2LXBrlztym+5+DK2yJSWyhpwGjt/d/D2vvxw0oaOEYRqS2UP+MVNRx0k8q2LtWu/96pXePvVnk1s7YA6kaP9EQ9fHFX0zFQC8zIBqkd+aW66KU5Kir3HP/OAI7LvW+38qa9eODkLEeYIpu0U0TDdFXs2az0295QxZ7Nypv2otzZWyVHmKJb95IcDsmSGo987LiPnzf9FVXsWq9mN79yzPsVr/pepZvmK2XIXcp66/dqOvp5eYvylDv1WaXf8V85wiOO+fEATkyD6HB9ffc5apHMSEEwYteCINUiOVb//F0P/fHDZaajACEhomFTNbn23/K5yuVzlSo8Plk5XzyliKQmkqSoJu3V7KaX5asokeX1yBmbqN3v/UWRTY6/YbrPVa6SdT8p6Zzrjnk/b2mBCuZOUuNrn1LFro2KSG6miOR0RSSny/J65N6Xpci01nXxcgHowPeiz4/sRYkNYowWBLERpzTT1adxCVugLoVFRis8Plne8mKVbV2qmA5nVH1/VJycsYly52fJtWezYjucftzHLN3wsyyvW3Hdzj3m/fb98LYS+l6m8AapkuWV5fX+9k6fV/L5avWaAFTv9gFtdUHXxqZj4CSwIhvkHr2km5Zu36dN2cWmowBBrSxjiSQpPDldnn27tW/2O4pIbq74HhdIkkrW/yxnbAM5GzSSOydT+TPHKbbDGYppc2rlY+ROfU7OhBQ1HHhjlccuXvmtYjucIWdMg6M//9ZlcudnKWX4nyVJkU06ypO/U2VbFstTlCuFORV+jD1rAZyYfq2Tdd9gLjYU7CiyQS4m0qlxo0/Tpa/8rELmZYFa81WUav9P78pTlCtndIJiO52ppAGj5XAeOEx6i/O174e35S3ZL2d8Q8V3O0+JZ42q8hiewhzJUfUHXe68narYuVaNRj5x9Od2Vyh/5htKu+QBOX79+PAGqWp4wR3KnfaCHM4IpQz/s8Iiour4VQP2lBofpVeu7a1wLkEb9DjZK0T8uDFHN43/RT7+NgEAOKowh/TBLafrzPappqOgDvCtSIgY2DFN9w/tbDoGAAAB7c8XdKTEhhCKbAj5/cB2GnFKM9MxAAAISAM7pmnsee1Nx0AdosiGmKev6KmuTY9+QgkAAHbUvGGMXri6lxxc5z2kUGRDzIGTv/ooJS7y+HcGAMAGEqLC9c6NfdWQ/xtDDkU2BDVvGKtXrztV4WF81wkAsDdnmEMvX9tbHRsnmI6CekCRDVFntE3hutEAANt7eHgXDerUyHQM1BOKbAgbc2ZrjTytuekYAAAYMbp/K914VhvTMVCPKLIh7onLuqtXiyTTMQAA8KsBHdP0yIhupmOgnlFkQ1xUuFNv3tBHjRtwRSAAgD10aBSvV67tLSfnioQ8iqwNNG4QrQk39VNCFFckBgCEtuS4SL1zY181iI4wHQV+QJG1iS5NG+jN0X0UyXWlAQAhKjI8TONu6KMWybGmo8BPaDU2cma7VD078hSxFzQAIBT9+/IeOq11sukY8COKrM1cckozPTisi+kYAADUqbvObafLT2WnHruhyNrQbQPa6paz2Y4EABAaRpzSTPcO7mQ6BgygyNrU34Z30cU9m5qOAQDASRnUKU3PjzxFDubmbIkia1MOh0PPj+yl/m1TTEcBAKBW+rZuqDeu76MITmS2Lf7mbSwyPExvju6jzk24/jQAILh0bdpA/72xr6IjnKajwCCKrM01iI7Quzf3U3pSjOkoAADUSJvUOL13Sz/2igVFFgcvmNBXiTEcEAAAga1pYrQ+uPV0pcZzxUpQZPGrDo0T9N8xpyk2kh/RAAACU3JcpN6/5XR+iohKFFlUOq11st4efZqiwvmyAAAEloSocL17Uz+1bxRvOgoCCI0FVZzZPlVv3sClbAEAgSMqPExvjTlNPZonmo6CAENbwREGdWqkV687VRFO9uQDAJgVHubQq9eeqjPYLhLVoMiiWhd2bawXru4tZxhlFgBghsMhPXNVT13QtbHpKAhQFFkc1fCeTfXcVaeILgsA8Lcwh/TUFT31u97NTUdBAAs3HQCB7bLe6bJk6f99vEI+y3QaAIAdhDmkZ648RVf0ocTi2CiyOK6D3w1TZgEA9c0Z5tCzV7ESi5qhyKJGKLMAgPrmDHPo+ZGn6NJe6aajIEhQZFFjlFkAQH1xhjn0n6t76ZJTmpmOgiBCkcUJOVhm75u8Uh7aLACgDkQ6w/TSNb00tHtT01EQZByWZdFGcMK+W7tXYyctVYXHZzoKACCIRYWH6Y0b+ujcTo1MR0EQosii1hZm5OnWdxerqMJjOgoAIAjFRTr11pjTdGa7VNNREKQosjgpa3YVaMw7i5RbXGE6CgAgiCREh2vCTf3Up1VD01EQxCiyOGmZuSW6/r8LtXNfmekoAIAg0DA2Qu/fcrq6pyeajoIgR5FFndhbWK7R//1FG/YWmY4CAAhgLZJjNOGmfmqXFm86CkIARRZ1pqDUrZsm/KKl2/ebjgIACEA90hP1zo19lZYQZToKQgRFFnWqzOXVHyYu0ewNOaajAAACyKBOaXrtulMVG8nOn6g7FFnUObfXp//38Qp9uWKX6SgAgAAwqm8LPXlZd4U7w0xHQYihyKJeWJalR79co3fnbzMdBQBg0J8v6Kh7LuhgOgZCFEUW9erVWZv17LcbxFcZANhLeJhD/7q8h646rYXpKAhhFFnUu+mr9+gvHy9XqctrOgoAwA/io8L12nWnakDHNNNREOIosvCL1VkFuu29xdpdUG46CgCgHjVKiNI7N/Zlj1j4BUUWfpNdVK7b31ui5Tv2m44CAKgH7RvFa8JNfdW8YazpKLAJiiz8qtzt1f2frGRHAwAIMWe3T9Wr156qxNgI01FgIxRZGPHy95v0/MyNnAQGACHgjgFtdf/QznKGOUxHgc1QZGHMtFW79ZePV6jMzUlgABCMYiKceurKnrrklGamo8CmKLIwanVWgW59d7H2FHISGAAEkxbJMRp3w2nq0rSB6SiwMYosjMsuLNdt7y3Wip0FpqMAAGrgnA6pevma3kqKjTQdBTZHkUVAKHd79ddPV+mzZVmmowAAjoF5WAQSiiwCyke/bNcjX65RhcdnOgoA4BAxEU49fWVPjWAeFgGEIouAs3ZXoe6atFRbc0tMRwEASGqZHKs3b+jDPCwCDkUWAam4wqP/m7JSU1fuNh0FAGyNeVgEMoosAtr78zP1xNfr5GLUAAD8yhnm0F3nttc953dgHhYBiyKLgLc6q0B3Tlyq7fmlpqMAgC00S4zWC6N6q1+bZNNRgGOiyCIoFJa7df/klZq+Zo/pKAAQ0oZ1b6J/X96TS80iKFBkEVTGz92qf32zXi4vowYAUJdiIpx6ZERXjerX0nQUoMYosgg6y3fs19hJS7VzX5npKAAQEro2baCXrumt9o3iTUcBTghFFkGpsNytR79co0+XcgEFAKgth0O66cw2emBYJ0WFO03HAU4YRRZBbcaaPXros1XKLXaZjgIAQSU1PlLPXHWKzu3UyHQUoNYosgh6+SUuPfTZKk1bzYlgAFATAzqm6bmrTlFaQpTpKMBJocgiZHy+LEuPfLlGBWVu01EAICBFhYfpviGddMvZbeRwsDcsgh9FFiFlb2G5HpiyUrM35JiOAgABpV+bZD11RU+1SY0zHQWoMxRZhKQPf9muJ6euVYnLazoKABgVHxWuB4Z11vWnt2QVFiGHIouQtSO/VPdOXqGFW/NNRwEAIwZ1StM/ftdD6UkxpqMA9YIii5BmWZbemZupZ2asV7mbiygAsIeGsRF6+OKuuvzU5qajAPWKIgtbyMwt0cNfrNacTbmmowBAvRreo6keu7SbUuPZkQChjyILW5m6cpeemLpWewsrTEcBgDrVKCFKT1zWXUO6NTEdBfAbiixsp7jCo+e/3ah352fK6+PLH0DwG3lacz00vKsSYyJMRwH8iiIL21qzq0B/+3y1lm3fbzoKANRKu7Q4PXZJd53dIdV0FMAIiixszbIsfbRoh56avl77S7mQAoDgkBAdrnvO76AxZ7ZWhDPMdBzAGIosoAOXuf3XN+v0ydKd4l8EgEAV5pBGntZC9w7pxMlcgCiyQBWLMvP1t89Wa8PeItNRAKCKPq0a6tER3dSjeaLpKEDAoMgCh/F4fRo/N1Mv/bBJReUe03EA2FyTBtH6v2GddVnvdNNRgIBDkQWOYl+JS6/M2qz352+Ty8vFFAD4V2R4mG47p43uOre9YiPDTccBAhJFFjiOHfmlembGBn21chfzswD84sKujfXw8K5qmRJrOgoQ0CiyQA2t2lmgf01bp3lb8kxHARCiOjdJ0EPDu+icDmmmowBBgSILnKBZG7L11LT1Wr+HE8IA1I22qXH684UddXHPpnI4HKbjAEGDIgvUgs9n6ZOlO/Wf7zZqd0G56TgAglR6UozuuaCDrji1uZxhFFjgRFFkgZNQ7vbqvz9v1Rs/bmGHAwA11ighSmPPa69RfVsqMpwLGgC1RZEF6sC+Epfe+HGLPliwTSUur+k4AAJUw9gI/WFQO43u31rREU7TcYCgR5EF6tC+EpfembtVE+ZlskILoFJCVLhuPaetbjmnjeKj2EoLqCsUWaAeFJa79d68TL0zN1P5JS7TcQAYEhPh1I1ntdYdA9oqKTbSdBwg5FBkgXpU6vJo4oLtemtOhrKLKkzHAeAniTERuv6MlrrxzDZKS4gyHQcIWRRZwA/K3V59vHiH3vwxQ1n7y0zHAVBP0pNidPPZbTSqbwvFMUIA1DuKLOBHbq9Pny7dqddnb1FmXqnpOADqSJemDXTHgLa6uGdThTvZhQDwF4osYIDXZ2nqyl1648cMrdtdaDoOgFo6p0Oqbh/QlitxAYZQZAHD5m/J0/i5WzVz3V75+NcIBLzwMIeG92yq2we0VbdmiabjALZGkQUCxI78Uk2Yl6mPF+1QUQVbdwGBJjbSqav7ttAtZ7dR84axpuMAEEUWCDglFR59smSn3pufqS05JabjALbXNjVO157eUlf1aaHE2AjTcQAcgiILBLB5m3P13vxtmrlurzzMHQB+Ex7m0IVdG+v6M1rpzHYpcjgcpiMBqAZFFggCewrKNWnhNn24aIdy2I8WqDdNE6N1Tb+WGtW3hRo1iDYdB8BxUGSBIOL2+jRz7V5NWbpTszfksEoL1IHwMIfO79JIo/q21MCOaQoLY/UVCBYUWSBI5RVX6Ivlu/Tpsp1ancUWXsCJapMap5GntdCVfZpz9S0gSFFkgRCwcW+Rpizdqc+XZWlvIaMHwNE0iA7XkG5NdEWf5jqjbYrpOABOEkUWCCE+n6WfN+dqytKd+nbNXpW5vaYjAcbFRjp1QZfGGnFKMw3smKbIcK68BYQKiiwQooorPPpm1W5NWbJTv2Tmi3/psJPI8DAN6pimEac00wVdGism0mk6EoB6QJEFbGDnvlJNX71H367dqyXb9snLSWIIQeFhDp3VPlUjTmmmId0aKyGaPV+BUEeRBWwmv8SlmWv36tu1ezRnU64qPD7TkYBaC3NI/doka8QpzTSse1Mlx0WajgTAjyiygI2Vujz6aWOOZqzZqx/WZ6ugzG06EnBc8VHhOqt9is7r3EjndmrEfq+AjVFkAUiSPF6fFm7N17drDowg7C4oNx0JqNQuLU7ndmqk8zo3Ut82yYpwcsIWAIosgKNYuXO/Zq7L1rzNuVq+Yz8XX4BfRYWHqX+7lMry2iI51nQkAAGIIgvguEoqPPpla77mbs7V3C15Wr+nkF0QUOfSk2IOjAt0TtOZ7VIVHcFOAwCOjSIL4ITll7g0f0ue5m7J1bzNucrMKzUdCUGoecMY9WudrL5tktWvTbLapcWbjgQgyFBkAZy0rP1lmrc5V/O25Gnu5lxlF3F1MVTlcEgdGyWob5uG6tv6QHFtmhhjOhaAIEeRBVDnMnNLtGLnfq3YUaAVO/drza4ClbvZ5stOIpwOdU9PPLDi2jpZp7VuqKRYtsYCULcosgDqncfr04a9RVq5s0ArduzXip0F2ri3iAszhAiHQ2qdEqcuTRPUrVmierdMUu8WDbmaFoB6R5EFYESZy6s1uwq0/Ndiu3Lnfm1j1jbgRUeEqVPjBHVt1kBdmzZQ12YN1LlJA8VFhZuOBsCGKLIAAkZxhUdbsou1ObtYm3OKD/w5p1jb80rZ/suA1PhIdfm1rHZteuBX27R4OcMcpqMBgCSKLIAg4Pb6tC2v5EDB/fXXlpwSbckpVqnLazpeUEuNj1KrlFi1So5Vy5TYA39OiVOr5FilxEeZjgcAx0SRBRC0LMvSroJybcst0a6Ccu0pKNPugnLtKSjXnsIDv+eXumy9560zzKFmSdFqlRx3oKgm/1pUU2LVMjmWkQAAQY0iCyCkVXi82ltQod0FZdpTWP5b0S0o196ichWWuVVY7lFRuTtodlaIjghTSlyUUhOilBoXqZT4SKXGRyklPkqplX8+8HtybKTCGAUAEKIosgDwK7fXp8Iyt4rKPSoq96iw3K2i8gNF99Dbi8rdqvD45PH55PFa8vgsub0H/uz1WfL+eli1LEsHD7CWJVmSwsMciolwKjrCqeiIMMVEOBUT6ay87bc/hx14+9fb4qLClRIXqZT4KMWzigoAkiiyAAAACFJhpgMAAAAAtUGRBQAAQFCiyAIAACAoUWQBAAAQlCiyAAAACEoUWQAAAAQliiwAAACCEkUWAAAAQYkiCwAAgKBEkQUAAEBQosgCAAAgKFFkAQAAEJQosgAAAAhKFFkAAAAEJYosAAAAghJFFgAAAEGJIgsAAICgRJEFAABAUKLIAgAAIChRZAEAABCUKLIAAAAIShRZAEFv9uzZcjgc2r9/v+koAAA/osgCqHc5OTn6wx/+oJYtWyoqKkpNmjTRkCFDNHfuXElS69at9cILL1Te37Is3XvvvWrQoIFmz55d7X0OdeaZZ2r37t1KTEys51cCAAgk4aYDAAh9V1xxhVwul9599121bdtWe/fu1ffff6+8vLwj7uv1enXbbbdp6tSpmjVrlvr06XPcx4+MjFSTJk3qI/oJcblcioyMNB0DAGyDFVkA9Wr//v2aM2eOnnrqKZ177rlq1aqV+vXrp7/+9a+65JJLqty3oqJCV111lWbOnKk5c+bUqMRKR44WTJgwQUlJSZoxY4a6dOmi+Ph4DR06VLt3767ycW+//ba6dOmi6Ohode7cWa+99lqV9z/wwAPq2LGjYmNj1bZtWz388MNyu92V73/00UfVq1cvvf3222rTpo2io6Nr8RkCANQWK7IA6lV8fLzi4+P1+eef64wzzlBUVFS19ysuLtbw4cO1c+dOzZ07Vy1atDip5y0tLdWzzz6r999/X2FhYbr++ut17733auLEiZKkiRMn6u9//7teeeUV9e7dW8uWLdNtt92muLg4jRkzRpKUkJCgCRMmqFmzZlq1apVuu+02JSQk6P777698ns2bN2vKlCn69NNP5XQ6TyozAODEUGQB1Kvw8HBNmDBBt912m9544w2deuqpGjhwoEaNGqWePXtW3u+JJ55QQkKC1q1bp7S0tJN+XrfbrTfeeEPt2rWTJI0dO1aPP/545fsfeeQRPffcc7r88sslSW3atNHatWv15ptvVhbZv/3tb5X3b926te6991599NFHVYqsy+XSe++9VyeZAQAnhtECAPXuiiuu0K5du/Tll19q6NChmj17tk499VRNmDCh8j6DBw9WSUmJ/vnPf9bJc8bGxlaWWElq2rSpsrOzJUklJSXasmWLbrnllsoV4/j4eD355JPasmVL5cf873//01lnnaUmTZooPj5ef/vb37R9+/Yqz9OqVStKLAAYQpEF4BfR0dG68MIL9fDDD2vevHm68cYb9cgjj1S+//zzz9cXX3yhN954Q/fcc89JP19ERESVtx0OhyzLknRgjEGS3nrrLS1fvrzy1+rVq7VgwQJJ0vz583Xdddfpoosu0tSpU7Vs2TI99NBDcrlcVR43Li7upLMCAGqH0QIARnTt2lWff/55ldsGDx6sr776Spdccoksy9JLL71UL8/duHFjNWvWTBkZGbruuuuqvc+8efPUqlUrPfTQQ5W3bdu2rV7yAABqhyILoF7l5eXpqquu0s0336yePXsqISFBixcv1tNPP61LL730iPtfcMEFmjp1qkaMGCGfz6dXXnml8n1ZWVlavnx5lfu3atWqVrkee+wx3X333UpMTNTQoUNVUVGhxYsXa9++ffrLX/6iDh06aPv27froo4/Ut29fff311/rss89q9VwAgPpBkQVQr+Lj43X66afrP//5j7Zs2SK3260WLVrotttu04MPPljtx5x33nn6+uuvdfHFF8uyrMoy++yzz+rZZ5+tct/3339fzZs3P+Fct956q2JjY/XMM8/ovvvuU1xcnHr06KE//elPkqRLLrlEf/7znzV27FhVVFRo+PDhevjhh/Xoo4+e8HMBAOqHwzo4NAYAAAAEEU72AgAAQFCiyAIAACAoUWQBAAAQlCiyAAAACEoUWQAAAAQliiwAAACCEkUWAAAAQYkiCwAAgKBEkQUAAEBQosgCAAAgKFFkAQAAEJQosgAAAAhK/x+n/1j0KxBD7AAAAABJRU5ErkJggg==\n"},"metadata":{}},{"name":"stdout","text":"================================================================================\nModel Comparison Summary: Original Model vs Tuned Model\n--------------------------------------------------------------------------------\nOriginal Model parameters: 2,147,545,088\nTuned Model parameters:    16,969,728\nParameter reduction:       2,130,575,360 (99.21%)\n--------------------------------------------------------------------------------\nLayer Differences:\nLayer Name                          Original Model Type  Tuned Model Type     Original Model Params Tuned Model Params Param Diff     \n--------------------------------------------------------------------------------------------------------------------------------------\nfc1                                 Linear               SKLinear             2,147,487,744   16,912,384      2,130,575,360  \n================================================================================\n","output_type":"stream"}],"execution_count":24}]}